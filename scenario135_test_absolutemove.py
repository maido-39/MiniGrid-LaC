"""
ì‹œë‚˜ë¦¬ì˜¤ 2 ì‹¤í—˜ í™˜ê²½ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (ì ˆëŒ€ ì¢Œí‘œ ì´ë™ ë²„ì „ - í´ë˜ìŠ¤ ê¸°ë°˜)

ì‹œë‚˜ë¦¬ì˜¤ 2: íŒŒë€ ê¸°ë‘¥ìœ¼ë¡œ ê°€ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ëŒê³ , í…Œì´ë¸” ì˜†ì— ë©ˆì¶”ì‹œì˜¤


> ì—¬ê¸° ì´ì œ json ì—ì„œ ë¶ˆëŸ¬ì™€ì ¸ì„œ, ë§µ ë°”ê¾¸ë ¤ë©´ json íŒŒì¼ë§Œ ë°”ê¾¸ë©´ ë¨ !!!
í™˜ê²½ êµ¬ì„±: (ì—…ë°ì´íŠ¸í•„ìš”)
- ë²½: ê²€ì€ìƒ‰ (ì™¸ë²½)
- íŒŒë€ ê¸°ë‘¥: íŒŒë€ìƒ‰ 2x2 Grid (í†µê³¼ë¶ˆê°€, ìƒ‰ìƒì´ ìˆëŠ” ë²½)
- í…Œì´ë¸”: ë³´ë¼ìƒ‰ 1x3 Grid (í†µê³¼ë¶ˆê°€, ìƒ‰ìƒì´ ìˆëŠ” ë²½)
- ì‹œì‘ì : (1, 8)
- ì¢…ë£Œì : (8, 1)

ë ˆì´ì•„ì›ƒ (14x14): `example_map.json` ì—ì„œ ì •ì˜, emoji_map_loader.py ì—ì„œ ë¡œë“œë¨
â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸ğŸŸ¦ğŸŸ¦ğŸŸ¦â¬œï¸â¬œï¸â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸ğŸŸ¦ğŸŸ¦ğŸŸ¦â¬œï¸â¬œï¸â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬œğŸŸ¦ğŸŸ¦ğŸŸ¦â¬œï¸â¬œï¸â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›
â¬›ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬›
â¬›â¬›â¬›â¬›â¬›â¬›â¬œï¸â¬œï¸â¬œï¸â¬›â¬›â¬›â¬›â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›â¬œï¸ğŸŸ¥â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸ğŸŸ©ğŸŸ©ğŸŸ©â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›

ì‚¬ìš©ë²•:
    python scenario2_test_absolutemove.py [json_map_path]
    ì˜ˆ: python scenario2_test_absolutemove.py example_map.json
"""
## Import common libraries
from typing import Union  # Unionì€ visualize_grid_cliì—ì„œ ì‚¬ìš©
import numpy as np
import cv2
import json
import csv
from datetime import datetime
from pathlib import Path
from PIL import Image

# Import MiniGrid and VLM related classes
from minigrid import register_minigrid_envs
from minigrid_customenv_emoji import MiniGridEmojiWrapper
from emoji_map_loader import load_emoji_map_from_json
from vlm_wrapper import ChatGPT4oVLMWrapper
from vlm_postprocessor import VLMResponsePostProcessor

# MiniGrid í™˜ê²½ ë“±ë¡
register_minigrid_envs()

# VLM ì„¤ì •
VLM_MODEL = "gpt-4o"
VLM_TEMPERATURE = 0.0
VLM_MAX_TOKENS = 1000

# Mission/Task ì„¤ì •
DEFAULT_MISSION = "Go to the blue pillar, turn right, then stop next to the table."


class PromptOrganizer:
    """í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤ (ì ˆëŒ€ ì¢Œí‘œ ë²„ì „)"""
    
    def __init__(self):
        self.grounding = ""
        self.previous_action = ""
        self.task_process = {"goal": "", "status": ""}  # status: pending | in_progress | completed | blocked
    
    def get_system_prompt(self, wrapper=None, last_action_result=None) -> str:
        """ì „ì²´ System Prompt ìƒì„± (ì ˆëŒ€ ì¢Œí‘œ ë²„ì „)"""
        ## Prompt ì˜¤ë¥˜ í•¸ë“¤ë§ìš©ì„
        # Grounding ë‚´ìš© (í•­ìƒ í‘œì‹œ, ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
        grounding_content = self.grounding if self.grounding else ""
        
        # Previous Action (í•­ìƒ í‘œì‹œ, ë¹„ì–´ìˆìœ¼ë©´ "None")
        previous_action = self.previous_action if self.previous_action else "None"
        
        # Task Process (í•­ìƒ í‘œì‹œ, ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ê°’)
        task_goal = self.task_process.get("goal", "") if self.task_process.get("goal") else "None"
        task_status = self.task_process.get("status", "") if self.task_process.get("status") else "None"
        task_process_str = f"Goal: {task_goal}, Status: {task_status}"
        
        # Last Action Result (ì‹¤íŒ¨ ì •ë³´)
        if last_action_result and last_action_result.get("action"):
            action_result = last_action_result.get("action", "None")
            result_status = "success" if last_action_result.get("success", True) else "failed"
            failure_reason = last_action_result.get("failure_reason", "")
            position_changed = "yes" if last_action_result.get("position_changed", True) else "no"
            last_action_str = f"Action: {action_result}, Result: {result_status}"
            if not last_action_result.get("success", True):
                last_action_str += f", Failure Reason: {failure_reason}"
            last_action_str += f", Position Changed: {position_changed}"
        else:
            last_action_str = "None"
        
        
        ## ì‹¤ì œ ì ìš© Prompt ì‹œì‘ (ì ˆëŒ€ ì¢Œí‘œ ë²„ì „)
        return f"""You are a robot operating in a grid-based environment.

## Coordinate System (ABSOLUTE)
- Top=North, Bottom=South, Left=West, Right=East
- Use absolute directions: up/down/left/right (or north/south/east/west)

## Action Space
- "move up"/"up"/"north"/"n": Move North
- "move down"/"down"/"south"/"s": Move South
- "move left"/"left"/"west"/"w": Move West
- "move right"/"right"/"east"/"e": Move East
- "pickup", "drop", "toggle"

## CRITICAL Movement Constraints
- The robot CANNOT enter or move into colored blocks (blue, purple, green) or walls(brick) .
- Attempting to move into a colored block or wall ALWAYS fails.
- Do NOT propose actions that move into colored blocks or walls.
- Check the image to identify impassable cells before selecting actions.

## Loop Prevention (CRITICAL)
- If the same action is attempted twice consecutively AND the robot's position does not change, that action becomes INVALID and must not be selected again.
- Always check the "Last Action Result" section below to avoid repeating failed actions.

Before selecting actions:
1. Check "Last Action Result" - if previous action failed, do NOT repeat it.
2. Check if current subtask is completed (robot adjacent to target = completed).
3. Check action feasibility (target cell must be passable, NOT a colored block or wall).
4. Apply applicable grounding knowledge if situation matches.
5. Select feasible action using absolute directions.



## Grounding Knowledge (Experience from Past Failures) - CRITICAL
This section contains lessons learned from human feedback after failures.
**IMPORTANT**: When the current situation matches the conditions described in a grounding rule, you MUST apply that rule when selecting actions.
- Review each grounding rule before selecting actions.
- If a grounding rule applies to the current situation, prioritize actions that follow the rule.
- These rules help avoid repeating past mistakes.
- Match the situation carefully: only apply rules when the conditions are similar.
{grounding_content}

## Last Action Result (Authoritative - Ground Truth)
This information is FACT and MUST be trusted. Do NOT infer or reinterpret.
- Last Action: {last_action_str}
- If result is "failed", the action did not execute successfully and position did not change.
- If position_changed is "no", the robot is blocked and that direction is INVALID.

## Memory (State Continuity)
- Previous Action: {previous_action}
- Task Process: {task_process_str}

## Response Format (STRICT)
Respond in valid JSON:

```json
{{
  "action": ["<action1>", "<action2>", "<action3>"],
  "reasoning": "<why the first action is correct. MUST include: (1) last action result check (if failed, explain why not repeating), (2) task completion check, (3) action feasibility (target cell is passable), (4) loop prevention check, (5) grounding rule applied if any.>",
  "grounding": "<update grounding only if new failure feedback is detected>",
  "memory": {{
    "spatial_description": "<environment described using absolute coordinates (North/South/East/West)>",
    "task_process": {{
      "goal": "<what subtask this step was addressing>",
      "status": "<pending | in_progress | completed | blocked>",
      "blocked_reason": "<optional: reason if status is blocked>"
    }},
    "previous_action": "<set to the first selected action>",
    "last_action_result": {{
      "action": "<last attempted action>",
      "success": true | false,
      "failure_reason": "<if failed: blocked_by_obstacle | wall | unknown>",
      "position_changed": true | false
    }}
  }}
}}
```

Important:
* EXACTLY 3 actions must be provided. Only the first action will be executed.
* Actions must come from the defined action space (absolute directions: up/down/left/right/pickup/drop/toggle).
* Check task completion and action feasibility before selecting actions.
* Apply applicable grounding knowledge.
* Complete the mission specified by the user.
"""
    
    def get_feedback_system_prompt(self) -> str:
        """Feedback ìƒì„±ìš© System Prompt (ì ˆëŒ€ ì¢Œí‘œ ë²„ì „)"""
        return """You are a feedback-to-knowledge converter for a robot navigation system.

Your task is to convert human feedback into a single-line behavioral heuristic.

## Context
You will receive:
- The previous action taken by the robot
- The current user feedback describing a mistake

## Your Task
Generate ONE concise sentence that:
- Describes the situation (implicit condition)
- States the correct behavior to follow next time

## Constraints
- Use absolute direction terms (North/South/East/West or up/down/left/right)
- Do NOT reference specific map positions or episode details
- Keep it general and reusable
- Exactly one sentence

## Response Format
```json
{
  "knowledge": "<single-line heuristic>"
}
```
"""
    
    def update_grounding(self, new_grounding: str):
        """Grounding ì§€ì‹ ëˆ„ì  ì—…ë°ì´íŠ¸"""
        if new_grounding and new_grounding.strip():
            if self.grounding:
                self.grounding = f"{self.grounding}\n\n{new_grounding.strip()}"
            else:
                self.grounding = new_grounding.strip()
    
    def get_user_prompt(self, default_prompt: str = None) -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì…ë ¥ ë°›ê¸°"""
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ê²°ì • (default_promptê°€ ì—†ìœ¼ë©´ DEFAULT_MISSION ì‚¬ìš©)
        actual_default = default_prompt if default_prompt else DEFAULT_MISSION
        
        if default_prompt:
            print(f"Task Hint: {default_prompt}")
        print(f"ëª…ë ¹ì„ ì…ë ¥í•˜ì„¸ìš” (Enter: {actual_default}):")
        user_input = input("> ").strip()
        
        if not user_input:
            if default_prompt:
                return f"Task: {default_prompt}\n\nBased on the current image, choose the next action to complete this task. Use absolute directions (up/down/left/right)."
            return f"Based on the current image, choose the next action to complete the mission: {DEFAULT_MISSION}. Use absolute directions (up/down/left/right)."
        
        return user_input


class VLMProcessor:
    """VLM ìš”ì²­ ë° íŒŒì‹± ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, model: str = VLM_MODEL, temperature: float = VLM_TEMPERATURE, max_tokens: int = VLM_MAX_TOKENS):
        self.vlm = ChatGPT4oVLMWrapper(
            model=model,
            temperature=temperature,
            max_tokens=max_tokens
        )
        self.postprocessor_action = VLMResponsePostProcessor(required_fields=["action", "reasoning", "grounding", "memory"])
        self.postprocessor_feedback = VLMResponsePostProcessor(required_fields=["knowledge"])
    
    def requester(self, image: np.ndarray, system_prompt: str, user_prompt: str) -> str:
        """VLMì— ìš”ì²­ ì „ì†¡ (ê¸°ë³¸ ë©”ì„œë“œ)"""
        try:
            response = self.vlm.generate(
                image=image,
                system_prompt=system_prompt,
                user_prompt=user_prompt
            )
            return response
        except Exception as e:
            print(f"VLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def parser_action(self, raw_response: str) -> dict:
        """Action ìƒì„± ì‘ë‹µ íŒŒì‹±"""
        try:
            parsed = self.postprocessor_action.process(raw_response, strict=True)
            return parsed
        except ValueError as e:
            print(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "action": ["0"],  # ê¸°ë³¸ê°’: move up
                "reasoning": "Parsing failed",
                "grounding": "",
                "memory": {
                    "spatial_description": "",
                    "task_process": {"goal": "", "status": ""},
                    "previous_action": ""
                }
            }
    
    def parser_feedback(self, raw_response: str) -> dict:
        """Feedback ìƒì„± ì‘ë‹µ íŒŒì‹±"""
        try:
            parsed = self.postprocessor_feedback.process(raw_response, strict=True)
            return parsed
        except ValueError as e:
            print(f"Feedback ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {"knowledge": ""}


class Visualizer:
    """ì‹œê°í™” í´ë˜ìŠ¤"""
    
    def __init__(self, window_name: str = "Scenario 2: VLM Control (Absolute)"):
        self.window_name = window_name
    
    def visualize_grid_cli(self, wrapper: MiniGridEmojiWrapper, state: dict):
        """CLIì—ì„œ ê·¸ë¦¬ë“œë¥¼ í…ìŠ¤íŠ¸ë¡œ ì‹œê°í™”"""
        env = wrapper.env
        size = wrapper.size
        
        agent_pos = state['agent_pos']
        if isinstance(agent_pos, np.ndarray):
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        else:
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        
        agent_dir = state['agent_dir']
        direction_symbols = {0: '>', 1: 'v', 2: '<', 3: '^'}
        agent_symbol = direction_symbols.get(agent_dir, 'A')
        
        grid_chars = []
        for y in range(size):
            row = []
            for x in range(size):
                cell = env.grid.get(x, y)
                
                if x == agent_x and y == agent_y:
                    row.append(agent_symbol)
                elif cell is not None and cell.type == 'wall':
                    if hasattr(cell, 'color'):
                        if cell.color == 'blue':
                            row.append('ğŸŸ¦')
                        elif cell.color == 'purple':
                            row.append('ğŸŸª')
                        elif cell.color == 'red':
                            row.append('ğŸŸ¥')
                        elif cell.color == 'green':
                            row.append('ğŸŸ©')
                        elif cell.color == 'yellow':
                            row.append('ğŸŸ¨')
                        else:
                            row.append('â¬›')
                    else:
                        row.append('â¬›')
                elif cell is not None and cell.type == 'goal':
                    row.append('ğŸŸ©')
                elif cell is not None:
                    if hasattr(cell, 'color'):
                        if cell.color == 'blue':
                            row.append('ğŸŸ¦')
                        elif cell.color == 'purple':
                            row.append('ğŸŸª')
                        else:
                            row.append('ğŸŸ¨')
                    else:
                        row.append('ğŸŸ¨')
                else:
                    row.append('â¬œï¸')
            grid_chars.append(row)
        
        print("\n" + "=" * 60)
        print("Current Grid State:")
        print("=" * 60)
        for y in range(size):
            print(''.join(grid_chars[y]))
        print("=" * 60)
        print(f"Agent Position: ({agent_x}, {agent_y}), Direction: {agent_dir} ({agent_symbol})")
        print("=" * 60 + "\n")

    def display_image(self, img: np.ndarray):
        """OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í‘œì‹œ"""
        if img is not None:
            try:
                img_bgr = cv2.cvtColor(img.copy(), cv2.COLOR_RGB2BGR)
                
                height, width = img_bgr.shape[:2]
                max_size = 800
                if height < max_size and width < max_size:
                    scale = min(max_size // height, max_size // width, 4)
                    if scale > 1:
                        new_width = width * scale
                        new_height = height * scale
                        img_bgr = cv2.resize(img_bgr, (new_width, new_height), interpolation=cv2.INTER_NEAREST)
                
                cv2.imshow(self.window_name, img_bgr)
                cv2.waitKey(1)
            except Exception as e:
                print(f"ì´ë¯¸ì§€ í‘œì‹œ ì˜¤ë¥˜: {e}")
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        cv2.destroyAllWindows()


class UserInteraction:
    """ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í´ë˜ìŠ¤"""
    
    def get_input(self, prompt: str = "> ") -> str:
        """ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°"""
        return input(prompt).strip()




class Scenario2Experiment:
    """ì‹œë‚˜ë¦¬ì˜¤ 2 ì‹¤í—˜ ë©”ì¸ í´ë˜ìŠ¤ (Runner) - ì ˆëŒ€ ì¢Œí‘œ ë²„ì „"""
    
    def __init__(self, log_dir: Path = None, json_map_path: str = "scenario135_example_map.json"):
        """
        Args:
            log_dir: ë¡œê·¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
            json_map_path: JSON ë§µ íŒŒì¼ ê²½ë¡œ
        """
        self.wrapper = None
        self.json_map_path = json_map_path
        self.prompt_organizer = PromptOrganizer()
        self.vlm_processor = VLMProcessor()
        self.visualizer = Visualizer()
        self.user_interaction = UserInteraction()
        
        if log_dir is None:
            map_name = Path(json_map_path).stem
            log_dir = Path("logs") / f"scenario2_absolute_{map_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.log_dir = log_dir
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        self.step = 0
        self.done = False
        self.state = None
        self.image = None
        self.user_prompt = ""
        self.vlm_response_raw = ""
        self.vlm_response_parsed = {}
        self.action_index = 0  # ê¸°ë³¸ê°’: move up
        self.action_name = "move up"
        self.reward = 0.0
        
        # Last action result tracking
        self.last_action_result = {
            "action": "",
            "success": True,
            "failure_reason": "",
            "position_changed": True
        }
        self.previous_position = None
        
        self.csv_file = None
        self.csv_writer = None
        self._init_csv_logging()
    
    def _evaluate_feedback(self, user_prompt: str) -> bool:
        """í”¼ë“œë°± í‰ê°€ (ë‚´ë¶€ ë©”ì„œë“œ)"""
        feedback_keywords = [
            "wrong", "incorrect", "that's wrong", "no", "not that", "don't", 
            "shouldn't", "error", "mistake", "why did you", "why didn't you",
            "what are you doing", "where are you going", "not feasible", 
            "cannot", "should not",
            "feedback :"
        ]
        
        user_lower = user_prompt.lower()
        for keyword in feedback_keywords:
            if keyword in user_lower:
                return True
        
        return False
    
    def vlm_gen_action(self, image: np.ndarray, system_prompt: str, user_prompt: str) -> dict:
        """Action ìƒì„±ìš© VLM í˜¸ì¶œ"""
        print("\n[3] VLMì— Action ìƒì„± ìš”ì²­ ì „ì†¡ ì¤‘...")
        raw_response = self.vlm_processor.requester(
            image=image,
            system_prompt=system_prompt,
            user_prompt=user_prompt
        )
        
        if not raw_response:
            print("VLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return {}
        
        print("VLM ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
        print("[4] ì‘ë‹µ íŒŒì‹± ì¤‘...")
        parsed = self.vlm_processor.parser_action(raw_response)
        return parsed
    
    def vlm_gen_feedback(self, system_prompt: str, user_feedback: str) -> str:
        """Feedback ìƒì„±ìš© VLM í˜¸ì¶œ"""
        print("\n[3-F] VLMì— Feedback ë¶„ì„ ìš”ì²­ ì „ì†¡ ì¤‘...")
        
        feedback_system_prompt = self.prompt_organizer.get_feedback_system_prompt()
        
        feedback_user_prompt = f"""## System Prompt Used
{system_prompt}

## User Feedback
feedback : {user_feedback}

Please analyze the feedback and generate concise knowledge to improve future actions.
"""
        
        raw_response = self.vlm_processor.requester(
            image=None,
            system_prompt=feedback_system_prompt,
            user_prompt=feedback_user_prompt
        )
        
        if not raw_response:
            print("Feedback VLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return ""
        
        print("Feedback VLM ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
        print("[4-F] Feedback ì‘ë‹µ íŒŒì‹± ì¤‘...")
        parsed = self.vlm_processor.parser_feedback(raw_response)
        knowledge = parsed.get('knowledge', '')
        
        if knowledge:
            print(f"\n[4-F-1] ìƒì„±ëœ Knowledge: {knowledge}")
            self.prompt_organizer.update_grounding(knowledge)
            print("\n[4-F-2] Grounding ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            print("=" * 80)
            print("ì—…ë°ì´íŠ¸ëœ Grounding ë‚´ìš©:")
            print("-" * 80)
            print(knowledge)
            print("-" * 80)
            print("\nì „ì²´ Grounding ì •ë³´:")
            print("=" * 80)
            if self.prompt_organizer.grounding:
                print(self.prompt_organizer.grounding)
            else:
                print("(ì—†ìŒ)")
            print("=" * 80)
        
        return knowledge
    
    def _init_csv_logging(self):
        """CSV ë¡œê¹… ì´ˆê¸°í™”"""
        csv_path = self.log_dir / "experiment_log.csv"
        file_exists = csv_path.exists()
        
        self.csv_file = open(csv_path, 'a', newline='', encoding='utf-8')
        self.csv_writer = csv.writer(self.csv_file)
        
        if not file_exists:
            self.csv_writer.writerow([
                "step", "timestamp", "agent_x", "agent_y", "agent_dir",
                "action_index", "action_name", "user_prompt",
                "vlm_action_chunk", "vlm_reasoning", "vlm_grounding",
                "memory_spatial_description", "memory_task_goal", "memory_task_status", "memory_task_blocked_reason", "memory_previous_action",
                "last_action_result_action", "last_action_result_success", "last_action_result_failure_reason", "last_action_result_position_changed",
                "reward", "done", "image_path"
            ])
    
    def _log_step(self):
        """í˜„ì¬ ìŠ¤í… ë¡œê¹…"""
        timestamp = datetime.now().isoformat()
        
        agent_pos = self.state['agent_pos']
        if isinstance(agent_pos, np.ndarray):
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        else:
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        
        image_path = f"step_{self.step:04d}.png"
        
        # Memory íŒŒì‹±
        memory = self.vlm_response_parsed.get('memory', {})
        if isinstance(memory, str):
            try:
                memory = json.loads(memory)
            except Exception:
                memory = {"spatial_description": "", "task_process": {"goal": "", "status": ""}, "previous_action": ""}
        elif not isinstance(memory, dict):
            memory = {"spatial_description": "", "task_process": {"goal": "", "status": ""}, "previous_action": ""}
        
        # task_process íŒŒì‹±
        task_process = memory.get('task_process', {})
        if not isinstance(task_process, dict):
            task_process = {"goal": "", "status": "", "blocked_reason": ""}
        
        action_chunk = self.vlm_response_parsed.get('action', [])
        if isinstance(action_chunk, str):
            try:
                action_chunk = json.loads(action_chunk)
            except Exception:
                action_chunk = [action_chunk] if action_chunk else []
        if not isinstance(action_chunk, list):
            action_chunk = [str(action_chunk)]
        
        # last_action_result ê°€ì ¸ì˜¤ê¸°
        last_action_result = self.last_action_result if hasattr(self, 'last_action_result') else {
            "action": "",
            "success": True,
            "failure_reason": "",
            "position_changed": True
        }
        
        self.csv_writer.writerow([
            self.step,
            timestamp,
            agent_x,
            agent_y,
            int(self.state['agent_dir']),
            self.action_index,
            self.action_name,
            self.user_prompt,
            json.dumps(action_chunk, ensure_ascii=False),
            self.vlm_response_parsed.get('reasoning', ''),
            self.vlm_response_parsed.get('grounding', ''),
            memory.get('spatial_description', ''),
            task_process.get('goal', ''),
            task_process.get('status', ''),
            task_process.get('blocked_reason', ''),
            memory.get('previous_action', ''),
            last_action_result.get('action', ''),
            bool(last_action_result.get('success', True)),
            last_action_result.get('failure_reason', ''),
            bool(last_action_result.get('position_changed', True)),
            float(self.reward),
            bool(self.done),
            image_path
        ])
        self.csv_file.flush()
        
        json_path = self.log_dir / "experiment_log.json"
        json_data = {
            "step": self.step,
            "timestamp": timestamp,
            "state": {
                "agent_pos": [agent_x, agent_y],
                "agent_dir": int(self.state['agent_dir']),
                "mission": str(self.state.get('mission', ''))
            },
            "action": {
                "index": self.action_index,
                "name": self.action_name
            },
            "user_prompt": self.user_prompt,
            "vlm_response": self.vlm_response_parsed,
            "memory": memory,
            "grounding": self.prompt_organizer.grounding,
            "last_action_result": last_action_result,
            "reward": float(self.reward),
            "done": bool(self.done),
            "image_path": image_path
        }
        
        all_data = []
        if json_path.exists():
            with open(json_path, 'r', encoding='utf-8') as f:
                try:
                    all_data = json.load(f)
                    if not isinstance(all_data, list):
                        all_data = [all_data]
                except json.JSONDecodeError:
                    all_data = []
        
        all_data.append(json_data)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, indent=2, ensure_ascii=False)
        
        image_path_full = self.log_dir / image_path
        img_pil = Image.fromarray(self.image)
        img_pil.save(image_path_full)
    
    def initialize(self):
        """ì‹¤í—˜ ì´ˆê¸°í™”"""
        print("=" * 60)
        print("ì‹œë‚˜ë¦¬ì˜¤ 2: VLM ì œì–´ ì‹¤í—˜ (ì ˆëŒ€ ì¢Œí‘œ ì´ë™ ë²„ì „)")
        print("=" * 60)
        print(f"\nMission: {DEFAULT_MISSION}")
        print("\nì•¡ì…˜ ê³µê°„: ìƒ/í•˜/ì¢Œ/ìš°ë¡œ ì§ì ‘ ì´ë™ ê°€ëŠ¥ (ì ˆëŒ€ ì¢Œí‘œ)")
        print(f"\në¡œê·¸ ë””ë ‰í† ë¦¬: {self.log_dir}")
        
        print("\n[1] í™˜ê²½ ìƒì„± ì¤‘...")
        print(f"  ë§µ íŒŒì¼: {self.json_map_path}")
        self.wrapper = load_emoji_map_from_json(self.json_map_path)
        self.wrapper.reset()
        
        self.state = self.wrapper.get_state()
        print(f"ì—ì´ì „íŠ¸ ì‹œì‘ ìœ„ì¹˜: {self.state['agent_pos']}")
        print(f"ì—ì´ì „íŠ¸ ë°©í–¥: {self.state['agent_dir']}")
        
        # ì´ˆê¸° ìœ„ì¹˜ ì €ì¥
        initial_pos = tuple(self.state['agent_pos'])
        if isinstance(initial_pos, np.ndarray):
            initial_pos = (int(initial_pos[0]), int(initial_pos[1]))
        self.previous_position = initial_pos
        
        # ì´ˆê¸° last_action_result ì„¤ì •
        self.last_action_result = {
            "action": "",
            "success": True,
            "failure_reason": "",
            "position_changed": True
        }
        
        # ì•¡ì…˜ ê³µê°„ ì •ë³´ ì¶œë ¥
        action_space = self.wrapper.get_absolute_action_space()
        print(f"\nì ˆëŒ€ ë°©í–¥ ì•¡ì…˜ ê³µê°„:")
        print(f"  - ì‚¬ìš© ê°€ëŠ¥í•œ ì•¡ì…˜: {action_space['actions']}")
        
        print("\n[2] VLM ì´ˆê¸°í™” ì™„ë£Œ")
        print("\n" + "=" * 60)
        print("ì‹¤í—˜ ì‹œì‘")
        print("=" * 60)
    
    def run_step(self):
        """í•œ ìŠ¤í… ì‹¤í–‰"""
        self.step += 1
        print("\n" + "=" * 80)
        print(f"STEP {self.step}")
        print("=" * 80)
        
        self.image = self.wrapper.get_image()
        self.state = self.wrapper.get_state()
        heading = self.wrapper.get_heading()
        heading_desc = self.wrapper.get_heading_description()
        print(f"ìœ„ì¹˜: {self.state['agent_pos']}, ë°©í–¥: {self.state['agent_dir']} ({heading})")
        print(f"í˜„ì¬ Heading: {heading_desc}")
        
        self.visualizer.visualize_grid_cli(self.wrapper, self.state)
        self.visualizer.display_image(self.image)
        
        default_prompt = f"Mission: {DEFAULT_MISSION}"
        self.user_prompt = self.prompt_organizer.get_user_prompt(default_prompt)
        
        # Feedback í‰ê°€
        has_feedback = self._evaluate_feedback(self.user_prompt)
        
        if has_feedback:
            # Feedback ì²˜ë¦¬: "feedback : "ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
            if self.user_prompt.lower().startswith("feedback :"):
                feedback_text = self.user_prompt[10:].strip()  # "feedback : " ì œê±°
            else:
                feedback_text = self.user_prompt
            
            # Feedback ìƒì„± VLM í˜¸ì¶œ
            system_prompt = self.prompt_organizer.get_system_prompt(self.wrapper)
            self.vlm_gen_feedback(system_prompt, feedback_text)
            
            # Feedback ì²˜ë¦¬ í›„ ì¼ë°˜ action ìƒì„±ìœ¼ë¡œ ì§„í–‰í•˜ì§€ ì•Šê³  ìŠ¤í‚µ
            print("\n[4-1] í”¼ë“œë°± ì²˜ë¦¬ ì™„ë£Œ. ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            return True
        
        # ì¼ë°˜ Action ìƒì„±
        system_prompt = self.prompt_organizer.get_system_prompt(self.wrapper, self.last_action_result)
        self.vlm_response_parsed = self.vlm_gen_action(
            image=self.image,
            system_prompt=system_prompt,
            user_prompt=self.user_prompt
        )
        
        if not self.vlm_response_parsed:
            return False
        
        # Action chunkì—ì„œ ì²« ë²ˆì§¸ ì•¡ì…˜ë§Œ ì¶”ì¶œ
        action_chunk = self.vlm_response_parsed.get('action', [])
        if isinstance(action_chunk, str):
            try:
                action_chunk = json.loads(action_chunk)
            except Exception:
                action_chunk = [action_chunk] if action_chunk else []
        if not isinstance(action_chunk, list):
            action_chunk = [str(action_chunk)]
        
        if len(action_chunk) == 0:
            action_str = '0'  # ê¸°ë³¸ê°’: move up
        else:
            action_str = str(action_chunk[0])
        
        # Memory íŒŒì‹±
        memory = self.vlm_response_parsed.get('memory', {})
        if isinstance(memory, str):
            try:
                memory = json.loads(memory)
            except Exception:
                memory = {}
        if not isinstance(memory, dict):
            memory = {}
        
        # task_process íŒŒì‹±
        task_process = memory.get('task_process', {})
        if not isinstance(task_process, dict):
            task_process = {"goal": "", "status": "", "blocked_reason": ""}
        
        # last_action_result íŒŒì‹± (VLM ì‘ë‹µì—ì„œ)
        vlm_last_action_result = memory.get('last_action_result', {})
        if not isinstance(vlm_last_action_result, dict):
            vlm_last_action_result = {}
        
        # Memory ì—…ë°ì´íŠ¸
        if isinstance(memory, dict):
            self.prompt_organizer.previous_action = memory.get('previous_action', action_str)
            self.prompt_organizer.task_process = {
                "goal": task_process.get('goal', ''),
                "status": task_process.get('status', ''),
                "blocked_reason": task_process.get('blocked_reason', '')
            }
            
            # VLMì´ blocked ìƒíƒœë¡œ ì„¤ì •í•œ ê²½ìš° ë°˜ì˜
            if task_process.get('status') == 'blocked':
                blocked_reason = task_process.get('blocked_reason', '')
                if blocked_reason:
                    print(f"\n[Memory] Task marked as blocked: {blocked_reason}")
        
        # Grounding ì—…ë°ì´íŠ¸ (ì‘ë‹µì—ì„œ ì˜¨ ê²½ìš°)
        grounding_update = self.vlm_response_parsed.get('grounding', '')
        grounding_updated = False
        if grounding_update and grounding_update.strip():
            self.prompt_organizer.update_grounding(grounding_update)
            grounding_updated = True
        
        # CLI ì¶œë ¥: Action, Reasoning, Memory, Grounding
        print("\n" + "=" * 80)
        print("[VLM ì‘ë‹µ ì •ë³´]")
        print("=" * 80)
        
        # Action Chunk ì¶œë ¥
        print("\n[Action Chunk]")
        print("-" * 80)
        if len(action_chunk) > 0:
            for i, action in enumerate(action_chunk, 1):
                marker = "â†’ ì‹¤í–‰" if i == 1 else "  ì˜ˆì¸¡"
                print(f"  {marker} [{i}] {action}")
        else:
            print("  (ì•¡ì…˜ ì—†ìŒ)")
        
        # Reasoning ì¶œë ¥
        reasoning = self.vlm_response_parsed.get('reasoning', '')
        print("\n[Reasoning]")
        print("-" * 80)
        if reasoning:
            print(f"  {reasoning}")
        else:
            print("  (ì—†ìŒ)")
        
        # Memory ì¶œë ¥
        print("\n[Memory]")
        print("-" * 80)
        spatial_desc = memory.get('spatial_description', '')
        task_goal = task_process.get('goal', '')
        task_status = task_process.get('status', '')
        prev_action = memory.get('previous_action', '')
        
        print("  Spatial Description:")
        if spatial_desc:
            print(f"    {spatial_desc}")
        else:
            print("    (ì—†ìŒ)")
        
        print("  Task Process:")
        if task_goal or task_status:
            print(f"    Goal: {task_goal if task_goal else '(ì—†ìŒ)'}")
            print(f"    Status: {task_status if task_status else '(ì—†ìŒ)'}")
        else:
            print("    (ì—†ìŒ)")
        
        print("  Previous Action:")
        if prev_action:
            print(f"    {prev_action}")
        else:
            print("    (ì—†ìŒ)")
        
        # Grounding ì¶œë ¥ (ì—…ë°ì´íŠ¸ëœ ê²½ìš°ë§Œ)
        if grounding_updated:
            print("\n[Grounding Update]")
            print("-" * 80)
            print(f"  {grounding_update}")
        
        print("=" * 80)
        
        print("\n[5] ì•¡ì…˜ ì‹¤í–‰ ì¤‘...")
        
        # í˜„ì¬ ìœ„ì¹˜ ì €ì¥ (ì•¡ì…˜ ì‹¤í–‰ ì „)
        current_pos_before = tuple(self.state['agent_pos'])
        if isinstance(current_pos_before, np.ndarray):
            current_pos_before = (int(current_pos_before[0]), int(current_pos_before[1]))
        
        try:
            self.action_index = self.wrapper.parse_absolute_action(action_str)
            action_space = self.wrapper.get_absolute_action_space()
            self.action_name = action_space['action_mapping'].get(self.action_index, f"action_{self.action_index}")
            print(f"ì‹¤í–‰í•  ì•¡ì…˜: {self.action_name} (ì¸ë±ìŠ¤: {self.action_index})")
            
            # use_absolute_movement=Trueì´ë¯€ë¡œ step()ì´ ì ˆëŒ€ ì›€ì§ì„ì„ ì²˜ë¦¬
            _, self.reward, terminated, truncated, _ = self.wrapper.step(self.action_index)
            self.done = terminated or truncated
            
            # ì•¡ì…˜ ì‹¤í–‰ í›„ ìœ„ì¹˜ í™•ì¸
            new_state = self.wrapper.get_state()
            current_pos_after = tuple(new_state['agent_pos'])
            if isinstance(current_pos_after, np.ndarray):
                current_pos_after = (int(current_pos_after[0]), int(current_pos_after[1]))
            
            # ìœ„ì¹˜ ë³€í™” í™•ì¸
            position_changed = (current_pos_before != current_pos_after)
            
            # ì•¡ì…˜ ê²°ê³¼ íŒë‹¨
            action_success = position_changed or self.reward > 0
            failure_reason = ""
            if not action_success:
                # ì‹¤íŒ¨ ì›ì¸ ì¶”ë¡  (ì´ë¯¸ì§€ì—ì„œ í™•ì¸ ê°€ëŠ¥í•œ ì •ë³´ ê¸°ë°˜)
                if not position_changed:
                    failure_reason = "blocked_by_obstacle"
                else:
                    failure_reason = "unknown"
            
            # Last action result ì—…ë°ì´íŠ¸
            self.last_action_result = {
                "action": self.action_name,
                "success": action_success,
                "failure_reason": failure_reason,
                "position_changed": position_changed
            }
            
            print(f"ë³´ìƒ: {self.reward}, ì¢…ë£Œ: {self.done}")
            print(f"ì•¡ì…˜ ê²°ê³¼: {'ì„±ê³µ' if action_success else 'ì‹¤íŒ¨'} (ìœ„ì¹˜ ë³€í™”: {'ì˜ˆ' if position_changed else 'ì•„ë‹ˆì˜¤'})")
            if not action_success:
                print(f"ì‹¤íŒ¨ ì›ì¸: {failure_reason}")
                
        except Exception as e:
            print(f"ì•¡ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            self.action_index = 0
            self.action_name = "move up"
            try:
                _, self.reward, terminated, truncated, _ = self.wrapper.step(0)
                self.done = terminated or truncated
            except:
                pass
            
            # ì˜ˆì™¸ ë°œìƒ ì‹œì—ë„ last_action_result ì—…ë°ì´íŠ¸
            self.last_action_result = {
                "action": self.action_name,
                "success": False,
                "failure_reason": "exception",
                "position_changed": False
            }
        
        # Previous action ì—…ë°ì´íŠ¸ (ì‹¤ì œ ì‹¤í–‰ëœ ì•¡ì…˜)
        self.prompt_organizer.previous_action = self.action_name
        
        # new_stateëŠ” ì´ë¯¸ ìœ„ì—ì„œ ê°€ì ¸ì™”ìœ¼ë¯€ë¡œ ì¬ì‚¬ìš©
        if 'new_state' not in locals():
            new_state = self.wrapper.get_state()
        self.state = new_state
        self.visualizer.visualize_grid_cli(self.wrapper, new_state)
        updated_image = self.wrapper.get_image()
        self.image = updated_image
        self.visualizer.display_image(updated_image)
        
        self._log_step()
        
        return True
    
    def run(self):
        """ë©”ì¸ ë£¨í”„ ì‹¤í–‰"""
        self.initialize()
        
        while not self.done:
            if not self.run_step():
                break
            
            if self.done:
                print("\n" + "=" * 80)
                print("Goal ë„ì°©! ì¢…ë£Œ")
                print("=" * 80)
                break
            
            if self.step >= 100:
                print("\nìµœëŒ€ ìŠ¤í… ìˆ˜(100)ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                break
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.visualizer.cleanup()
        if self.wrapper:
            self.wrapper.close()
        if self.csv_file:
            self.csv_file.close()
        print(f"\nì‹¤í—˜ ì™„ë£Œ. ë¡œê·¸ëŠ” {self.log_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import sys
    
    # ëª…ë ¹ì¤„ ì¸ìë¡œ JSON ë§µ íŒŒì¼ ê²½ë¡œ ì§€ì •
    json_map_path = "scenario135_example_map.json"
    if len(sys.argv) > 1:
        if sys.argv[1] == "--help" or sys.argv[1] == "-h":
            print("ì‚¬ìš©ë²•:")
            print("  python scenario2_test_absolutemove.py [json_map_path]")
            print("  ì˜ˆ: python scenario2_test_absolutemove.py scenario135_example_map.json")
            return
        else:
            json_map_path = sys.argv[1]
    
    try:
        experiment = Scenario2Experiment(json_map_path=json_map_path)
        experiment.run()
    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

