# MiniGrid-LaC í”„ë¡œì íŠ¸ íƒ€ì„ë¼ì¸

ì´ ë¬¸ì„œëŠ” MiniGrid-LaC í”„ë¡œì íŠ¸ì˜ ì‹œì‘ë¶€í„° í˜„ì¬ê¹Œì§€ ì£¼ìš” ê¸°ëŠ¥ë“¤ì´ ì¶”ê°€ëœ íƒ€ì„ë¼ì¸ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ“… íƒ€ì„ë¼ì¸ ê°œìš”

í”„ë¡œì íŠ¸ëŠ” 2025ë…„ 1ì›”ë¶€í„° ì‹œì‘ë˜ì–´ í˜„ì¬ê¹Œì§€ ì§€ì†ì ìœ¼ë¡œ ë°œì „í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê° ê¸°ëŠ¥ì€ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì •ë¦¬ë˜ì–´ ìˆìœ¼ë©°, ì¤‘ìš”í•œ ê¸°ëŠ¥ì—ëŠ” ì‚¬ìš©ë²•ë„ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ—“ï¸ 2025ë…„ 1ì›” ì´ˆë°˜: í”„ë¡œì íŠ¸ ê¸°ì´ˆ êµ¬ì¶•

### 2025-01-07 ~ 2025-01-09: ê¸°ë³¸ í™˜ê²½ ë˜í¼ ë° í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ

**ê¸°ëŠ¥**: MiniGrid í™˜ê²½ ë˜í¼ í´ë˜ìŠ¤ ë° ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•

**ì£¼ìš” ë‚´ìš©**:
- CustomRoomWrapper í´ë˜ìŠ¤ êµ¬í˜„
- ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±
- í™˜ê²½ ìƒì„± ë° ì œì–´ ê¸°ë³¸ ê¸°ëŠ¥

**ì‚¬ìš©ë²•**:
```python
from utils.map_manager.minigrid_customenv_emoji import MiniGridEmojiWrapper

# í™˜ê²½ ìƒì„±
wrapper = MiniGridEmojiWrapper(size=10)
obs, info = wrapper.reset()
```

---

### 2025-01-11 ~ 2025-01-13: ì´ëª¨ì§€ ë§µ ì‹œìŠ¤í…œ

**ê¸°ëŠ¥**: ì´ëª¨ì§€ ê¸°ë°˜ ë§µ ìƒì„± ë° JSON ë§µ ë¡œë”

**ì£¼ìš” ë‚´ìš©**:
- ì´ëª¨ì§€ ê°ì²´ ë Œë”ë§ ì§€ì›
- JSON íŒŒì¼ì—ì„œ ë§µ ë¡œë“œ ê¸°ëŠ¥
- 18ê°€ì§€ ìƒ‰ìƒ íŒ”ë ˆíŠ¸ í™•ì¥ (ê¸°ì¡´ 6ê°œ â†’ 18ê°œ)
- ì´ëª¨ì§€ ë§µ ìƒì„±ê¸° í†µí•©

**ì‚¬ìš©ë²•**:
```python
from utils.map_manager.emoji_map_loader import load_emoji_map_from_json

# JSON íŒŒì¼ì—ì„œ ë§µ ë¡œë“œ
wrapper = load_emoji_map_from_json('config/example_map.json')
obs, info = wrapper.reset()
```

**JSON ë§µ íŒŒì¼ í˜•ì‹**:
```json
{
  "size": 10,
  "map": [
    "ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ¦ğŸŸ¦",
    "ğŸŸ¦ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ«ğŸŸ¦",
    ...
  ],
  "objects": {
    "ğŸŸ¦": {"type": "wall", "color": "blue"},
    "ğŸŸ«": {"type": "floor", "color": "brown"}
  }
}
```

**ê´€ë ¨ ë¬¸ì„œ**: [ì´ëª¨ì§€ ë§µ JSON ë¡œë” ê°€ì´ë“œ](./emoji-map-loader.md)

---

### 2025-01-12: ì ˆëŒ€ ì¢Œí‘œ ì´ë™ ì‹œìŠ¤í…œ

**ê¸°ëŠ¥**: ë¡œë´‡ ë°©í–¥ê³¼ ë¬´ê´€í•˜ê²Œ ìƒ/í•˜/ì¢Œ/ìš° ì§ì ‘ ì´ë™

**ì£¼ìš” ë‚´ìš©**:
- `step_absolute()` ë©”ì„œë“œ êµ¬í˜„
- ë°©í–¥ë³„ ì•¡ì…˜ íŒŒì‹± (north/south/west/east)
- ì¸ë±ìŠ¤ ê¸°ë°˜ ì•¡ì…˜ ì§€ì›

**ì‚¬ìš©ë²•**:
```python
# ì ˆëŒ€ ì¢Œí‘œ ì´ë™
obs, reward, done, truncated, info = wrapper.step_absolute('move up')
obs, reward, done, truncated, info = wrapper.step_absolute('move right')
obs, reward, done, truncated, info = wrapper.step_absolute(0)  # ì¸ë±ìŠ¤
obs, reward, done, truncated, info = wrapper.step_absolute('north')  # ë³„ì¹­
```

**ì§€ì›í•˜ëŠ” ì•¡ì…˜**:
- `'move up'`, `'north'`, `0` â†’ ìœ„ë¡œ ì´ë™
- `'move down'`, `'south'`, `1` â†’ ì•„ë˜ë¡œ ì´ë™
- `'move left'`, `'west'`, `2` â†’ ì™¼ìª½ìœ¼ë¡œ ì´ë™
- `'move right'`, `'east'`, `3` â†’ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™

**ê´€ë ¨ ë¬¸ì„œ**: [Wrapper API](./wrapper-api.md#ì ˆëŒ€-ì¢Œí‘œ-ì´ë™-absolute-movement)

---

## ğŸ—“ï¸ 2025ë…„ 1ì›” ì¤‘ë°˜: VLM í†µí•© ë° ëª¨ë“ˆí™”

### 2025-01-14: í”„ë¡œì íŠ¸ êµ¬ì¡° ëª¨ë“ˆí™”

**ê¸°ëŠ¥**: í”„ë¡œì íŠ¸ë¥¼ utils ê¸°ë°˜ ëª¨ë“ˆ êµ¬ì¡°ë¡œ ì¬êµ¬ì„±

**ì£¼ìš” ë‚´ìš©**:
- `utils/` ë””ë ‰í† ë¦¬ êµ¬ì¡° ì •ë¦½
- `map_manager/`, `vlm/`, `miscellaneous/`, `prompt_manager/` ëª¨ë“ˆ ë¶„ë¦¬
- `minigrid_lac.py` ë©”ì¸ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ ìƒì„±
- `PromptOrganizer` í´ë˜ìŠ¤ êµ¬í˜„

**ì‚¬ìš©ë²•**:
```python
from utils.miscellaneous.scenario_runner import ScenarioExperiment
from utils.miscellaneous.safe_minigrid_registration import safe_minigrid_reg

safe_minigrid_reg()
experiment = ScenarioExperiment(json_map_path="config/example_map.json")
experiment.run()
```

---

### 2025-01-19 ~ 2025-01-20: VLM í•¸ë“¤ëŸ¬ ì‹œìŠ¤í…œ

**ê¸°ëŠ¥**: ë‹¤ì–‘í•œ VLM ëª¨ë¸ ì§€ì›ì„ ìœ„í•œ í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤

**ì£¼ìš” ë‚´ìš©**:
- OpenAI GPT-4o í•¸ë“¤ëŸ¬
- Gemini API í•¸ë“¤ëŸ¬ ì¶”ê°€
- Qwen VLM í•¸ë“¤ëŸ¬
- Gemma í•¸ë“¤ëŸ¬
- VLMWrapper í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤

**ì‚¬ìš©ë²•**:
```python
from utils.vlm.vlm_wrapper import VLMWrapper

# VLM ë˜í¼ ìƒì„±
vlm = VLMWrapper(
    model="gpt-4o",  # ë˜ëŠ” "gemini-2.5-flash", "qwen2.5-vl-32b-instruct" ë“±
    temperature=0.5,
    max_tokens=3000
)

# VLM í˜¸ì¶œ
response = vlm.generate(
    image=image,
    system_prompt=system_prompt,
    user_prompt=user_prompt
)
```

**ì§€ì›í•˜ëŠ” ëª¨ë¸**:
- **OpenAI**: `gpt-4o`, `gpt-4o-mini`, `gpt-4-turbo`
- **Gemini**: `gemini-2.5-flash`, `gemini-2.5-pro`, `gemini-3.0-flash`
- **Qwen**: `qwen2.5-vl-32b-instruct`, `qwen2.5-vl-7b-instruct`
- **Gemma**: `google/gemma-2-9b-it`

**ê´€ë ¨ ë¬¸ì„œ**: [VLM í•¸ë“¤ëŸ¬ ì‹œìŠ¤í…œ ê°€ì´ë“œ](./vlm-handlers.md)

---

### 2025-01-20: Gemini Thinking ê¸°ëŠ¥ ì§€ì›

**ê¸°ëŠ¥**: Gemini 2.5/3 ì‹œë¦¬ì¦ˆì˜ Thinking ê¸°ëŠ¥ í†µí•©

**ì£¼ìš” ë‚´ìš©**:
- Thinking ëª¨ë“œ í™œì„±í™”
- ì¤‘ê°„ ì¶”ë¡  ê³¼ì • ì¶”ì¶œ
- ìµœì¢… ì‘ë‹µê³¼ Thinking ë¶„ë¦¬

**ì‚¬ìš©ë²•**:
```python
# global_variables.pyì—ì„œ ì„¤ì •
GEMINI_THINKING_ENABLED = True

# VLM í˜¸ì¶œ ì‹œ ìë™ìœ¼ë¡œ Thinking í¬í•¨
response = vlm.generate(...)
thinking = response.get('thinking', '')
final_response = response.get('content', '')
```

**ê´€ë ¨ ë¬¸ì„œ**: [Gemini Thinking ê¸°ëŠ¥ ê°€ì´ë“œ](./LLM-API/gemini-thinking.md)

---

## ğŸ—“ï¸ 2025ë…„ 1ì›” í›„ë°˜: ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€

### 2025-01-20: Entropy ë¶„ì„ ì‹œìŠ¤í…œ (Logprobs ê¸°ë°˜)

**ê¸°ëŠ¥**: VLMì˜ action ë¶ˆí™•ì‹¤ì„±ì„ ì •ëŸ‰í™”í•˜ëŠ” Entropy ê³„ì‚°

**ì£¼ìš” ë‚´ìš©**:
- Vertex AI Gemini logprobs ê¸°ëŠ¥ í™œìš©
- 3ê°€ì§€ ì¡°ê±´ìœ¼ë¡œ VLM í˜¸ì¶œ (H(X), H(X|S), H(X|L,S))
- Shannon Entropy ê³„ì‚°
- Trust ê°’ ê³„ì‚°

**ì‚¬ìš©ë²•**:
```bash
cd src
python scenario2_test_entropy_comparison.py config/example_map.json
```

**ì„¤ì •**:
```python
# global_variables.py
LOGPROBS_ENABLED = True
VLM_MODEL = "gemini-2.5-flash-vertex"  # Vertex AI ëª¨ë¸ í•„ìš”
```

**Entropy ê³„ì‚° ê³µì‹**:
```
H(X) â‰¥ H(X|S) â‰¥ H(X|L,S)
T = (H(X) - H(X|S)) / (H(X) - H(X|L,S))
```

**ê´€ë ¨ ë¬¸ì„œ**: [Entropy ë° Trust ê³„ì‚° ê°€ì´ë“œ](./entropy-trust-calculation.md)

---

### 2025-01-22: ë‹¤ì¤‘ ê°ì²´ ìš´ë°˜ ë° ì•¡ì…˜ ì‹¤íŒ¨ ê°ì§€

**ê¸°ëŠ¥**: ì—¬ëŸ¬ ê°ì²´ë¥¼ ë™ì‹œì— ìš´ë°˜í•˜ê³  ì•¡ì…˜ ì‹¤íŒ¨ë¥¼ ê°ì§€

**ì£¼ìš” ë‚´ìš©**:
- ë‹¤ì¤‘ ê°ì²´ pickup/drop ì§€ì›
- ì•¡ì…˜ ì‹¤íŒ¨ ìë™ ê°ì§€
- ì²´ìŠ¤íŒ ìŠ¤íƒ€ì¼ ì¢Œí‘œ ë ˆì´ë¸” ì¶”ê°€

**ì‚¬ìš©ë²•**:
```python
# ì—¬ëŸ¬ ê°ì²´ ìš´ë°˜
obs, reward, done, truncated, info = wrapper.step_absolute('pickup')
# info['carrying']ì— ìš´ë°˜ ì¤‘ì¸ ê°ì²´ ë¦¬ìŠ¤íŠ¸ í¬í•¨
```

---

### 2025-01-23: Grounding ì§€ì‹ ì‹œìŠ¤í…œ

**ê¸°ëŠ¥**: ì‚¬ìš©ì í”¼ë“œë°±ì„ í†µí•œ ì‹¤ìˆ˜ í•™ìŠµ ë° ëˆ„ì  ì‹œìŠ¤í…œ

**ì£¼ìš” ë‚´ìš©**:
- ì—í”¼ì†Œë“œë³„ í”¼ë“œë°± ìˆ˜ì§‘
- VLM ê¸°ë°˜ Grounding ìë™ ìƒì„±
- System Promptì— ìë™ í¬í•¨
- ì—¬ëŸ¬ Grounding íŒŒì¼ ë³‘í•© ì§€ì›

**ì‚¬ìš©ë²•**:
```python
# Stepë³„ í”¼ë“œë°± ì…ë ¥
# ì‹¤í—˜ ì¤‘ì— "feedback : spatial: kitchen is green" í˜•ì‹ìœ¼ë¡œ ì…ë ¥

# ì—í”¼ì†Œë“œ ì¢…ë£Œ ì‹œ ìë™ìœ¼ë¡œ Grounding ìƒì„±
# ë‹¤ìŒ ì—í”¼ì†Œë“œë¶€í„° ìë™ìœ¼ë¡œ System Promptì— í¬í•¨ë¨
```

**ì„¤ì •**:
```python
# global_variables.py
USE_NEW_GROUNDING_SYSTEM = True
GROUNDING_FILE_PATH = "logs/grounding/grounding_latest.json"
GROUNDING_MERGE_FORMAT = "txt"  # "txt" | "json" | "both"
```

**í”¼ë“œë°± í˜•ì‹**:
```
feedback : spatial: kitchen is green
feedback : procedural: always check door before entering
feedback : user_preference: prefer shortest path
```

**ê´€ë ¨ ë¬¸ì„œ**: [Grounding ì§€ì‹ ì‹œìŠ¤í…œ ê°€ì´ë“œ](./grounding-system.md)

---

### 2025-01-23: Entropy VLM í˜¸ì¶œ ë³‘ë ¬í™”

**ê¸°ëŠ¥**: 3ê°€ì§€ ì¡°ê±´ì˜ VLM í˜¸ì¶œì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ì—¬ ì†ë„ ê°œì„ 

**ì£¼ìš” ë‚´ìš©**:
- `concurrent.futures`ë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ ì²˜ë¦¬
- í”¼ë“œë°± UX ê°œì„ 
- ì—¬ëŸ¬ Grounding íŒŒì¼ ì§€ì› ê°•í™”

---

### 2025-01-25: ì—í”¼ì†Œë“œ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

**ê¸°ëŠ¥**: ì—í”¼ì†Œë“œ ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ë„êµ¬

**ì£¼ìš” ë‚´ìš©**:
- ì˜ì–´ ìº¡ì…˜ ì§€ì›
- Box plot ê°€ì´ë“œ
- í†µê³„ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

---

### 2025-01-27: Verbalized Entropy ì‹œìŠ¤í…œ

**ê¸°ëŠ¥**: VLMì´ ì§ì ‘ ì¶œë ¥í•˜ëŠ” í™•ë¥  ë¶„í¬ë¥¼ ì‚¬ìš©í•œ Entropy ê³„ì‚° (Tian et al. 2023 ê¸°ë°˜)

**ì£¼ìš” ë‚´ìš©**:
- Verbalized Confidence ë°©ì‹
- Step-wise í™•ë¥  ë¶„í¬ ì¶”ì¶œ
- ê°€ì¤‘ í‰ê·  Entropy ê³„ì‚° (50/30/20)
- JSON íŒŒì‹± ìë™ ì¬ì‹œë„

**ì‚¬ìš©ë²•**:
```bash
cd src
python scenario2_test_entropy_comparison_refined_entropy.py config/example_map.json
```

**ì„¤ì •**:
```python
# global_variables.py
USE_VERBALIZED_ENTROPY = True
LOGPROBS_ENABLED = False  # ìë™ìœ¼ë¡œ Falseë¡œ ì„¤ì •ë¨
VLM_MODEL = "gemini-2.5-flash"  # RLHF ëª¨ë¸ ê¶Œì¥
```

**VLM ì¶œë ¥ í˜•ì‹**:
```json
{
  "executability": 0.95,
  "step1": {"north": 0.65, "south": 0.15, "west": 0.12, "east": 0.08},
  "step2": {"north": 0.45, "south": 0.30, "west": 0.15, "east": 0.10},
  "step3": {"north": 0.40, "south": 0.35, "west": 0.15, "east": 0.10},
  "reasoning": "Brief explanation"
}
```

**Entropy ê³„ì‚°**:
```python
# Stepë³„ Entropy
H_step = -Î£ p_i Ã— logâ‚‚(p_i)

# ê°€ì¤‘ í‰ê·  Entropy
H_weighted = 0.5 Ã— H_step1 + 0.3 Ã— H_step2 + 0.2 Ã— H_step3
```

**ì¥ì **:
- RLHF ëª¨ë¸ì˜ êµì •ëœ í™•ë¥  ì‚¬ìš©
- logprobs ê¸°ëŠ¥ì´ ì—†ëŠ” ëª¨ë¸ì—ì„œë„ ì‚¬ìš© ê°€ëŠ¥
- ëª…ì‹œì  í™•ë¥  ì¶œë ¥ìœ¼ë¡œ í•´ì„ ìš©ì´

**ê´€ë ¨ ë¬¸ì„œ**: [Entropy ë° Trust ê³„ì‚° ê°€ì´ë“œ](./entropy-trust-calculation.md#verbalized-entropy-ë°©ì‹-tian-et-al-2023-ê¸°ë°˜-ì‹ ê·œ)

---

### 2025-01-27: Grounding íŒŒì¼ ë³‘í•© ê°œì„ 

**ê¸°ëŠ¥**: ì—¬ëŸ¬ Grounding íŒŒì¼(JSON/TXT) ìë™ ë³‘í•© ë° System Prompt í†µí•©

**ì£¼ìš” ë‚´ìš©**:
- JSON íŒŒì¼ ìë™ ë³‘í•© (stacked_grounding + final_grounding)
- TXT íŒŒì¼ í…ìŠ¤íŠ¸ ë³‘í•©
- í˜¼í•© íŒŒì¼ ì§€ì› (JSON + TXT)
- Markdown ë Œë”ë§ ìµœì í™”

**ì‚¬ìš©ë²•**:
```python
# global_variables.py
GROUNDING_FILE_PATH = "file1.json,file2.json,file3.txt"  # ì—¬ëŸ¬ íŒŒì¼ ì§€ì›
GROUNDING_MERGE_FORMAT = "txt"  # "txt" | "json" | "both"
```

**ë³‘í•© ë¡œì§**:
- **JSON íŒŒì¼**: stacked_grounding ë¦¬ìŠ¤íŠ¸ í•©ì¹˜ê¸° + final_grounding content ë³‘í•©
- **TXT íŒŒì¼**: í…ìŠ¤íŠ¸ë¥¼ `"\n\n---\n\n"`ë¡œ ë³‘í•©
- **í˜¼í•©**: JSON Markdown + TXT í…ìŠ¤íŠ¸ ë³‘í•©

**ê´€ë ¨ ë¬¸ì„œ**: [Grounding ì§€ì‹ ì‹œìŠ¤í…œ ê°€ì´ë“œ](./grounding-system.md#ì—¬ëŸ¬-íŒŒì¼-ë³‘í•©-ê¸°ëŠ¥-ì‹ ê·œ)

---

## ğŸ“Š ê¸°ëŠ¥ë³„ ìš”ì•½

### í•µì‹¬ ê¸°ëŠ¥

1. **ì´ëª¨ì§€ ë§µ ì‹œìŠ¤í…œ** (2025-01-11)
   - JSON íŒŒì¼ë¡œ ë§µ ì •ì˜
   - 18ê°€ì§€ ìƒ‰ìƒ íŒ”ë ˆíŠ¸
   - ì´ëª¨ì§€ ê°ì²´ ë Œë”ë§

2. **ì ˆëŒ€ ì¢Œí‘œ ì´ë™** (2025-01-12)
   - ë°©í–¥ ë¬´ê´€ ì´ë™
   - ë‹¤ì–‘í•œ ì•¡ì…˜ í‘œí˜„ ì§€ì›

3. **VLM í†µí•©** (2025-01-19)
   - ë‹¤ì¤‘ VLM ëª¨ë¸ ì§€ì›
   - í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤
   - Gemini Thinking ê¸°ëŠ¥

4. **Grounding ì‹œìŠ¤í…œ** (2025-01-23)
   - í”¼ë“œë°± ê¸°ë°˜ í•™ìŠµ
   - ìë™ Grounding ìƒì„±
   - íŒŒì¼ ë³‘í•© ì§€ì›

5. **Entropy ë¶„ì„** (2025-01-20, 2025-01-27)
   - Logprobs ê¸°ë°˜ (2025-01-20)
   - Verbalized Entropy (2025-01-27)
   - Trust ê°’ ê³„ì‚°

### ì§€ì› ê¸°ëŠ¥

- **Episode ê´€ë¦¬**: ì—í”¼ì†Œë“œë³„ ë¡œê¹… ë° Grounding ìƒì„±
- **ë‹¤ì¤‘ ê°ì²´ ìš´ë°˜**: ì—¬ëŸ¬ ê°ì²´ ë™ì‹œ ìš´ë°˜
- **ì•¡ì…˜ ì‹¤íŒ¨ ê°ì§€**: ìë™ ì‹¤íŒ¨ ê°ì§€ ë° í”¼ë“œë°±
- **ë³‘ë ¬ ì²˜ë¦¬**: Entropy VLM í˜¸ì¶œ ë³‘ë ¬í™”
- **ë¶„ì„ ë„êµ¬**: ì—í”¼ì†Œë“œ ë¶„ì„ ë° ì‹œê°í™”

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

### 1. ê¸°ë³¸ ì‹¤í—˜ ì‹¤í–‰

```bash
cd src
python minigrid_lac.py config/example_map.json
```

### 2. Entropy ë¶„ì„ ì‹¤í—˜

```bash
# Logprobs ê¸°ë°˜
python scenario2_test_entropy_comparison.py config/example_map.json

# Verbalized Entropy ê¸°ë°˜
python scenario2_test_entropy_comparison_refined_entropy.py config/example_map.json
```

### 3. ì„¤ì • ë³€ê²½

`src/utils/miscellaneous/global_variables.py`ì—ì„œ ì„¤ì • ë³€ê²½:

```python
# VLM ì„¤ì •
VLM_MODEL = "gemini-2.5-flash"
VLM_TEMPERATURE = 0.5
VLM_MAX_TOKENS = 3000

# Entropy ì„¤ì •
LOGPROBS_ENABLED = True
USE_VERBALIZED_ENTROPY = True

# Grounding ì„¤ì •
USE_NEW_GROUNDING_SYSTEM = True
GROUNDING_FILE_PATH = "logs/grounding/grounding_latest.json"
```

---

## ğŸ“š ê´€ë ¨ ë¬¸ì„œ

- [README.md](../README.md) - í”„ë¡œì íŠ¸ ì „ì²´ ê°œìš”
- [Wrapper API](./wrapper-api.md) - í™˜ê²½ ë˜í¼ API
- [VLM í•¸ë“¤ëŸ¬ ê°€ì´ë“œ](./vlm-handlers.md) - VLM ëª¨ë¸ ì‚¬ìš©ë²•
- [Grounding ì‹œìŠ¤í…œ](./grounding-system.md) - Grounding ì§€ì‹ ì‹œìŠ¤í…œ
- [Entropy ê³„ì‚° ê°€ì´ë“œ](./entropy-trust-calculation.md) - Entropy ë° Trust ê³„ì‚°

---

**ì‘ì„±ì¼**: 2026-01-27  
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2026-01-27
