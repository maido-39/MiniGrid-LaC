"""
VLMì„ ì‚¬ìš©í•˜ì—¬ MiniGrid í™˜ê²½ì„ ì œì–´í•˜ëŠ” í´ë˜ìŠ¤

ì´ ëª¨ë“ˆì€ VLM(Vision Language Model)ì„ ì‚¬ìš©í•˜ì—¬ MiniGrid í™˜ê²½ì„ ì¡°ì‘í•˜ê¸° ìœ„í•œ
í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. í™˜ê²½ ìƒì„± ë° ê´€ë¦¬ëŠ” minigrid_customenv_emoji.pyì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- VLMì„ ì‚¬ìš©í•œ ì•¡ì…˜ ìƒì„±
- í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ (ì¸ìŠ¤í„´ìŠ¤í™” ì‹œ í¸í•˜ê²Œ ì¡°ì‘ ê°€ëŠ¥)
- í™˜ê²½ ìƒíƒœ ì‹œê°í™”
- VLM ì‘ë‹µ íŒŒì‹± ë° ì•¡ì…˜ ì‹¤í–‰
"""

from minigrid_customenv_emoji import MiniGridEmojiWrapper
from vlm_wrapper import ChatGPT4oVLMWrapper
from vlm_postprocessor import VLMResponsePostProcessor
import numpy as np
import cv2
from typing import Union, Tuple, Dict, Optional


class MiniGridVLMController:
    """
    VLMì„ ì‚¬ìš©í•˜ì—¬ MiniGrid í™˜ê²½ì„ ì œì–´í•˜ëŠ” í´ë˜ìŠ¤
    
    ì‚¬ìš© ì˜ˆì‹œ:
        # í™˜ê²½ ìƒì„±
        env = MiniGridEmojiWrapper(size=10, room_config={...})
        env.reset()
        
        # ì»¨íŠ¸ë¡¤ëŸ¬ ìƒì„±
        controller = MiniGridVLMController(
            env=env,
            model="gpt-4o",
            system_prompt="You are a robot...",
            user_prompt_template="Complete the mission: {mission}"
        )
        
        # VLMìœ¼ë¡œ ì•¡ì…˜ ìƒì„± ë° ì‹¤í–‰
        response = controller.generate_action()
        controller.execute_action(response['action'])
    """
    
    def __init__(
        self,
        env: MiniGridEmojiWrapper,
        model: str = "gpt-4o",
        temperature: float = 0.0,
        max_tokens: int = 1000,
        system_prompt: Optional[str] = None,
        user_prompt_template: Optional[str] = None,
        required_fields: Optional[list] = None
    ):
        """
        ì»¨íŠ¸ë¡¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            env: MiniGridEmojiWrapper í™˜ê²½ ì¸ìŠ¤í„´ìŠ¤
            model: VLM ëª¨ë¸ëª… (ê¸°ë³¸ê°’: "gpt-4o")
            temperature: ìƒì„± ì˜¨ë„ (ê¸°ë³¸ê°’: 0.0)
            max_tokens: ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸ê°’: 1000)
            system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            user_prompt_template: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (Noneì´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©)
            required_fields: VLM ì‘ë‹µ í•„ìˆ˜ í•„ë“œ ë¦¬ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: ["action", "environment_info"])
        """
        self.env = env
        
        self.vlm = ChatGPT4oVLMWrapper(
            model=model,
            temperature=temperature,
            max_tokens=max_tokens
        )
        
        self.postprocessor = VLMResponsePostProcessor(
            required_fields=required_fields or ["action", "environment_info"]
        )
        
        # í”„ë¡¬í”„íŠ¸ ì„¤ì •
        self.system_prompt = system_prompt or self._get_default_system_prompt()
        self.user_prompt_template = user_prompt_template or self._get_default_user_prompt_template()
    
    def _get_default_system_prompt(self) -> str:
        """ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        return """You are a robot operating on a grid map.

## Environment
Grid world with walls (black), blue pillar (impassable), purple table (impassable), robot (red arrow shows heading), and goal (green marker if present).

## Coordinate System
The top of the image is North (up), and the bottom is South (down).
The left is West (left), and the right is East (right).

## Robot Orientation
In the image, the red triangle represents the robot.
The robot's heading direction is shown by the triangle's apex (sharp tip).
However, you can move in ANY direction regardless of the robot's current heading.

## Action Space (Absolute Directions)
You can move directly in absolute directions:
- "up": Move North
- "down": Move South
- "left": Move West
- "right": Move East
- "pickup": Pick up object
- "drop": Drop object
- "toggle": Interact with objects

## Movement Rules
**CRITICAL**: All movements are in ABSOLUTE directions (North/South/East/West).
- "up" = move North (upward on the image)
- "down" = move South (downward on the image)
- "left" = move West (leftward on the image)
- "right" = move East (rightward on the image)
- The robot will automatically rotate to face the correct direction before moving
- You don't need to think about the robot's current heading - just specify the direction you want to go

## Response Format
Respond in JSON format:
```json
{
    "action": "<action_name_or_number>",
    "environment_info": "<description of current state with spatial relationships in absolute coordinates (North/South/East/West)>",
    "reasoning": "<explanation of why you chose this action>"
}
```

**Important**: 
- Valid JSON format required
- Actions must be from the list above
- Complete mission from user prompt
- Use absolute directions (up/down/left/right), not relative to robot heading
- Think in terms of the image: up=North, down=South, left=West, right=East
"""
    
    def _get_default_user_prompt_template(self) -> str:
        """ê¸°ë³¸ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë°˜í™˜"""
        return "Based on the current image, choose the next action to complete the mission: {mission}. Use absolute directions (up/down/left/right)."
    
    def set_system_prompt(self, prompt: str):
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •"""
        self.system_prompt = prompt
    
    def set_user_prompt_template(self, template: str):
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •"""
        self.user_prompt_template = template
    
    def get_user_prompt(self, mission: Optional[str] = None, **kwargs) -> str:
        """
        ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            mission: ë¯¸ì…˜ í…ìŠ¤íŠ¸ (Noneì´ë©´ í™˜ê²½ì˜ ë¯¸ì…˜ ì‚¬ìš©)
            **kwargs: í…œí”Œë¦¿ì— ì¶”ê°€í•  í‚¤ì›Œë“œ ì¸ì
        
        Returns:
            ìƒì„±ëœ ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
        """
        if mission is None:
            state = self.env.get_state()
            mission = state.get('mission', 'explore')
        
        return self.user_prompt_template.format(mission=mission, **kwargs)
    
    def generate_action(
        self,
        user_prompt: Optional[str] = None,
        mission: Optional[str] = None
    ) -> Dict:
        """
        VLMì„ ì‚¬ìš©í•˜ì—¬ ì•¡ì…˜ ìƒì„±
        
        Args:
            user_prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (Noneì´ë©´ í…œí”Œë¦¿ì—ì„œ ìƒì„±)
            mission: ë¯¸ì…˜ í…ìŠ¤íŠ¸ (user_promptê°€ Noneì¼ ë•Œë§Œ ì‚¬ìš©)
        
        Returns:
            íŒŒì‹±ëœ VLM ì‘ë‹µ ë”•ì…”ë„ˆë¦¬
        """
        image = self.env.get_image()
        
        if user_prompt is None:
            user_prompt = self.get_user_prompt(mission=mission)
        
        try:
            vlm_response_raw = self.vlm.generate(
                image=image,
                system_prompt=self.system_prompt,
                user_prompt=user_prompt
            )
        except Exception as e:
            raise RuntimeError(f"VLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        
        try:
            vlm_response = self.postprocessor.process(vlm_response_raw, strict=True)
            return vlm_response
        except ValueError as e:
            raise ValueError(f"VLM ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}\nì›ë³¸ ì‘ë‹µ: {vlm_response_raw[:200]}...")
    
    def execute_action(self, action: Union[int, str]) -> Tuple[Dict, float, bool, bool, Dict]:
        """
        ì•¡ì…˜ ì‹¤í–‰ (ì ˆëŒ€ ì¢Œí‘œ ì´ë™ ì‚¬ìš©)
        
        Args:
            action: ì•¡ì…˜ (ì •ìˆ˜ ì¸ë±ìŠ¤ ë˜ëŠ” ì•¡ì…˜ ì´ë¦„ ë¬¸ìì—´)
        
        Returns:
            observation, reward, terminated, truncated, info
        """
        return self.env.step_absolute(action)
    
    def step(
        self,
        user_prompt: Optional[str] = None,
        mission: Optional[str] = None
    ) -> Tuple[Dict, float, bool, bool, Dict, Dict]:
        """
        VLMìœ¼ë¡œ ì•¡ì…˜ ìƒì„± í›„ ì‹¤í–‰ (í•œ ë²ˆì— ì²˜ë¦¬)
        
        Args:
            user_prompt: ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (Noneì´ë©´ í…œí”Œë¦¿ì—ì„œ ìƒì„±)
            mission: ë¯¸ì…˜ í…ìŠ¤íŠ¸ (user_promptê°€ Noneì¼ ë•Œë§Œ ì‚¬ìš©)
        
        Returns:
            observation, reward, terminated, truncated, info, vlm_response
        """
        vlm_response = self.generate_action(user_prompt=user_prompt, mission=mission)
        action = vlm_response.get('action', 'up')
        
        obs, reward, terminated, truncated, info = self.execute_action(action)
        
        return obs, reward, terminated, truncated, info, vlm_response
    
    def visualize_state(self, window_name: str = "MiniGrid VLM Control", cell_size: int = 32):
        """
        í˜„ì¬ í™˜ê²½ ìƒíƒœë¥¼ OpenCVë¡œ ì‹œê°í™”
        
        Args:
            window_name: ì°½ ì´ë¦„
            cell_size: ì…€ í¬ê¸° (ì´ë¯¸ì§€ í™•ëŒ€ìš©)
        """
        image = self.env.get_image()
        
        if image is not None:
            try:
                img_bgr = cv2.cvtColor(image.copy(), cv2.COLOR_RGB2BGR)
                
                height, width = img_bgr.shape[:2]
                max_size = 800
                if height < max_size and width < max_size:
                    scale = min(max_size // height, max_size // width, 4)
                    if scale > 1:
                        new_width = width * scale
                        new_height = height * scale
                        img_bgr = cv2.resize(img_bgr, (new_width, new_height), interpolation=cv2.INTER_NEAREST)
                
                cv2.imshow(window_name, img_bgr)
                cv2.waitKey(1)
            except Exception as e:
                print(f"ì´ë¯¸ì§€ í‘œì‹œ ì˜¤ë¥˜: {e}")
    
    def visualize_grid_cli(self):
        """CLIì—ì„œ ê·¸ë¦¬ë“œë¥¼ í…ìŠ¤íŠ¸ë¡œ ì‹œê°í™”"""
        state = self.env.get_state()
        env = self.env.env
        size = self.env.size
        
        agent_pos = state['agent_pos']
        if isinstance(agent_pos, np.ndarray):
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        else:
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        
        agent_dir = state['agent_dir']
        direction_symbols = {0: '>', 1: 'v', 2: '<', 3: '^'}
        agent_symbol = direction_symbols.get(agent_dir, 'A')
        
        grid_chars = []
        for y in range(size):
            row = []
            for x in range(size):
                cell = env.grid.get(x, y)
                
                if x == agent_x and y == agent_y:
                    row.append(agent_symbol)
                elif cell is not None and cell.type == 'wall':
                    if hasattr(cell, 'color'):
                        color_map = {
                            'blue': 'ğŸŸ¦',
                            'purple': 'ğŸŸª',
                            'red': 'ğŸŸ¥',
                            'green': 'ğŸŸ©',
                            'yellow': 'ğŸŸ¨'
                        }
                        row.append(color_map.get(cell.color, 'â¬›'))
                    else:
                        row.append('â¬›')
                elif cell is not None and cell.type == 'goal':
                    row.append('ğŸŸ©')
                elif cell is not None:
                    if hasattr(cell, 'color'):
                        if cell.color == 'blue':
                            row.append('ğŸŸ¦')
                        elif cell.color == 'purple':
                            row.append('ğŸŸª')
                        else:
                            row.append('ğŸŸ¨')
                    else:
                        row.append('ğŸŸ¨')
                else:
                    row.append('â¬œï¸')
            grid_chars.append(row)
        
        print("\n" + "=" * 60)
        print("Current Grid State:")
        print("=" * 60)
        for y in range(size):
            print(''.join(grid_chars[y]))
        print("=" * 60)
        print(f"Agent Position: ({agent_x}, {agent_y}), Direction: {agent_dir} ({agent_symbol})")
        print("=" * 60 + "\n")
    
    def run_interactive(
        self,
        mission: Optional[str] = None,
        max_steps: int = 100,
        window_name: str = "MiniGrid VLM Control"
    ):
        """
        ëŒ€í™”í˜• ëª¨ë“œë¡œ ì‹¤í–‰ (ì‚¬ìš©ì ì…ë ¥ ë°›ì•„ì„œ ì‹¤í–‰)
        
        Args:
            mission: ë¯¸ì…˜ í…ìŠ¤íŠ¸
            max_steps: ìµœëŒ€ ìŠ¤í… ìˆ˜
            window_name: ì°½ ì´ë¦„
        """
        step = 0
        done = False
        
        print("=" * 60)
        print("MiniGrid VLM ìƒí˜¸ì‘ìš© ì‹œì‘")
        print("=" * 60)
        
        while not done and step < max_steps:
            step += 1
            print("\n" + "=" * 80)
            print(f"STEP {step}")
            print("=" * 80)
            
            state = self.env.get_state()
            print(f"ìœ„ì¹˜: {state['agent_pos']}, ë°©í–¥: {state['agent_dir']}")
            
            self.visualize_grid_cli()
            self.visualize_state(window_name)
            
            print("ëª…ë ¹ì„ ì…ë ¥í•˜ì„¸ìš” (Enter: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸):")
            user_prompt = input("> ").strip()
            if not user_prompt:
                user_prompt = None
            
            try:
                obs, reward, terminated, truncated, info, vlm_response = self.step(
                    user_prompt=user_prompt,
                    mission=mission
                )
                done = terminated or truncated
                
                action_str = vlm_response.get('action', 'N/A')
                print(f"íŒŒì‹±ëœ ì•¡ì…˜: {action_str}")
                print(f"Environment Info: {vlm_response.get('environment_info', 'N/A')}")
                print(f"Reasoning: {vlm_response.get('reasoning', 'N/A')}")
                print(f"ë³´ìƒ: {reward}, ì¢…ë£Œ: {done}")
                
            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                import traceback
                traceback.print_exc()
                break
            
            if done:
                print("\n" + "=" * 80)
                print("Goal ë„ì°©! ì¢…ë£Œ")
                print("=" * 80)
                break
        
        if step >= max_steps:
            print(f"\nìµœëŒ€ ìŠ¤í… ìˆ˜({max_steps})ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
        
        cv2.destroyAllWindows()
        print("\nì‹¤í—˜ ì™„ë£Œ.")


def create_scenario2_environment():
    """ì‹œë‚˜ë¦¬ì˜¤ 2 í™˜ê²½ ìƒì„± ì˜ˆì œ"""
    size = 10
    
    walls = []
    for i in range(size):
        walls.append((i, 0))
        walls.append((i, size-1))
        walls.append((0, i))
        walls.append((size-1, i))
    
    blue_pillar_positions = [(3, 4), (4, 4), (3, 5), (4, 5)]
    for pos in blue_pillar_positions:
        walls.append((pos[0], pos[1], 'blue'))
    
    table_positions = [(5, 1), (6, 1), (7, 1)]
    for pos in table_positions:
        walls.append((pos[0], pos[1], 'purple'))
    
    start_pos = (1, 8)
    goal_pos = (8, 1)
    
    room_config = {
        'start_pos': start_pos,
        'goal_pos': goal_pos,
        'walls': walls,
        'objects': []
    }
    
    return MiniGridEmojiWrapper(size=size, room_config=room_config)


def main():
    """ë©”ì¸ í•¨ìˆ˜ (ì˜ˆì œ)"""
    print("=" * 60)
    print("MiniGrid VLM ìƒí˜¸ì‘ìš© (ì ˆëŒ€ ì¢Œí‘œ ì´ë™ ë²„ì „)")
    print("=" * 60)
    
    env = create_scenario2_environment()
    env.reset()
    
    controller = MiniGridVLMController(env=env)
    
    mission = "íŒŒë€ ê¸°ë‘¥ìœ¼ë¡œ ê°€ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ëŒê³ , í…Œì´ë¸” ì˜†ì— ë©ˆì¶”ì‹œì˜¤"
    controller.run_interactive(mission=mission, max_steps=100)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

