######################################################
#                                                    #
#                      SCENARIO                      #
#                       RUNNER                       #
#                                                    #
######################################################


"""
Scenario Experiment Runner - Absolute Coordinate Version

This program implements the main class for running scenario experiments.
"""




######################################################
#                                                    #
#                      LIBRARIES                     #
#                                                    #
######################################################


import csv
import cv2
import json
import sys
import numpy as np
from PIL import Image
from pathlib import Path
from typing import Union, Optional, Tuple, Dict, Any  # Union is used in visualize_grid_cli
from datetime import datetime
from colorama import Fore, Style

from utils.miscellaneous.visualizer import Visualizer
from utils.vlm.vlm_processor import VLMProcessor
from utils.user_manager.user_interact import UserInteraction
import utils.prompt_manager.terminal_formatting_utils as tfu
from utils.prompt_manager.prompt_organizer import PromptOrganizer
from utils.prompt_manager.prompt_interp import system_prompt_interp
from utils.map_manager.emoji_map_loader import load_emoji_map_from_json

from utils.miscellaneous.global_variables import (
    DEFAULT_INITIAL_MISSION,
    DEFAULT_MISSION,
    VLM_MODEL,
    LOGPROBS_ENABLED,
    LOGPROBS_TOPK,
    MAP_FILE_NAME,
    DEBUG,
    USE_NEW_GROUNDING_SYSTEM,
    GROUNDING_VLM_MODEL,
    GROUNDING_VLM_TEMPERATURE,
    GROUNDING_VLM_MAX_TOKENS,
    GROUNDING_FILE_PATH,
    USE_VERBALIZED_ENTROPY,
    USE_GCP_KEY,
)

from utils.miscellaneous.episode_manager import EpisodeManager
from utils.miscellaneous.grounding_file_manager import GroundingFileManager




######################################################
#                                                    #
#                        CLASS                       #
#                                                    #
######################################################


class ScenarioExperiment:
    """
    Scenario 2 Experiment Main Class (Runner) - Absolute Coordinate Version
    """
    
    def __init__(self,
                 log_dir: Path = None,
                 json_map_path: str = None,
                 prompt_organizer: Optional[PromptOrganizer] = None,
                 use_logprobs: bool = None,
                 debug: bool = None
                ):
        """
        Args:
            log_dir: Log directory path
            json_map_path: JSON map file path (default: None, uses MAP_FILE_NAME from global_variables)
            prompt_organizer: Custom PromptOrganizer instance (default: None, uses default PromptOrganizer)
            use_logprobs: Enable logprobs (default: None, uses LOGPROBS_ENABLED from global_variables)
            debug: Enable debug output (default: None, uses DEBUG from global_variables)
        """
        
        self.wrapper = None
        # Use global MAP_FILE_NAME if json_map_path is not provided
        if json_map_path is None:
            json_map_path = f"config/{MAP_FILE_NAME}"
        self.json_map_path = json_map_path
        self.prompt_organizer = prompt_organizer if prompt_organizer is not None else PromptOrganizer()
        # logprobs / VLM ì„¤ì •
        self.vlm_model = VLM_MODEL
        # Use use_logprobs parameter if provided, otherwise use global LOGPROBS_ENABLED
        self.logprobs_enabled_cfg = use_logprobs if use_logprobs is not None else LOGPROBS_ENABLED
        self.logprobs_topk = LOGPROBS_TOPK
        # Use debug parameter if provided, otherwise use global DEBUG
        self.debug = debug if debug is not None else DEBUG
        self.logprobs_active = False  # ì‹¤ì œ í™œì„± ì—¬ë¶€ (ëª¨ë¸/ì„¤ì •ì— ë”°ë¼ ê²°ì •)
        self.logprobs_metadata = {}
        self.action_logprobs_info = {}
        # VLMProcessor ìƒì„± (ëª¨ë¸/ì„¤ì •ì— ë”°ë¼ logprobs í™œì„±í™” ì—¬ë¶€ ê²°ì •)
        self.vlm_processor = self._create_vlm_processor()
        self.visualizer = Visualizer()
        self.user_interaction = UserInteraction()
        
        if log_dir is None:
            map_name = Path(json_map_path).stem
            log_dir = Path("logs") / f"scenario2_absolute_{map_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.log_dir = log_dir
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        self.step = 0
        self.done = False
        self.state = None
        self.image = None
        
        # ìƒˆ Grounding ì‹œìŠ¤í…œ ê´€ë ¨ ì´ˆê¸°í™”
        self.use_new_grounding_system = USE_NEW_GROUNDING_SYSTEM
        self.episode_manager = None
        self.grounding_file_manager = None
        self.episode_id = None
        self.user_prompt = ""
        self.vlm_response_raw = ""
        self.vlm_response_parsed = {}
        self.action_index = 0  # Default value: move up
        self.action_name = "move up"
        self.reward = 0.0
        
        # Last action result tracking
        self.last_action_result = {
            "action": "",
            "success": True,
            "failure_reason": "",
            "position_changed": True
        }
        self.previous_position = None
        
        self.csv_file = None
        self.csv_writer = None
        self._init_csv_logging()
    
    def _create_vlm_processor(self) -> VLMProcessor:
        """
        ëª¨ë¸/ì„¤ì •ì— ë”°ë¼ logprobsë¥¼ í™œì„±í™”í•œ VLMProcessor ìƒì„±.
        logprobsëŠ” Vertex AI Gemini(-vertex/-logprobs) ëª¨ë¸ì—ì„œë§Œ ì‚¬ìš©.
        Gemini ì¸ì¦ ë°©ë²•(GCP key ë˜ëŠ” API key)ë„ global_variables ì„¤ì •ì— ë”°ë¼ ê²°ì •.
        """
        
        import os
        
        model_lower = (self.vlm_model or "").lower()
        logprobs_allowed = (
            model_lower.startswith("gemini")
            and ("-vertex" in model_lower or "-logprobs" in model_lower)
        )
        logprobs_value = self.logprobs_topk if (self.logprobs_enabled_cfg and logprobs_allowed) else None
        self.logprobs_active = logprobs_value is not None

        if self.logprobs_enabled_cfg and not logprobs_allowed:
            tfu.cprint(
                "[Info] logprobs ë¹„í™œì„±í™”: ëª¨ë¸ì´ Vertex AI Gemini(-vertex/-logprobs) í˜•íƒœê°€ ì•„ë‹™ë‹ˆë‹¤.",
                tfu.LIGHT_BLACK,
            )

        # Gemini ì¸ì¦ ë°©ë²• ê²°ì • (GCP key ë˜ëŠ” API key)
        credentials = None
        vertexai = False
        project_id = None
        location = None
        
        # Gemini ëª¨ë¸ì¸ ê²½ìš°ì—ë§Œ ì¸ì¦ ë°©ë²• í™•ì¸
        if model_lower.startswith("gemini"):
            # Vertex AI ëª¨ë¸ì¸ ê²½ìš°: í•­ìƒ GCP key ì‚¬ìš©
            if logprobs_allowed:
                vertexai = True
                # Vertex AIëŠ” project/locationì´ í•„ìš” (gemini_handlerê°€ envì—ì„œë„ ì½ìŒ)
                project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
                location = os.getenv("GOOGLE_CLOUD_LOCATION", "us-central1")
            else:
                # ì¼ë°˜ Gemini ëª¨ë¸ì¸ ê²½ìš°:
                # - USE_GCP_KEY=False: Google AI Studio key (api_key)ë¡œ ì¼ë°˜ Gemini API í˜¸ì¶œ
                # - USE_GCP_KEY=True : Vertex AI ê²½ë¡œë¡œ ê°•ì œ ì „í™˜í•˜ì—¬ GCP keyë¡œ í˜¸ì¶œ
                if USE_GCP_KEY:
                    vertexai = True
                    project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
                    location = os.getenv("GOOGLE_CLOUD_LOCATION", "us-central1")
                    if not project_id:
                        tfu.cprint(
                            "[Warning] USE_GCP_KEY=True ì´ì§€ë§Œ GOOGLE_CLOUD_PROJECTê°€ ì„¤ì •ë˜ì–´ ìžˆì§€ ì•ŠìŠµë‹ˆë‹¤. "
                            "Vertex AI ê²½ë¡œ í˜¸ì¶œì—ëŠ” projectê°€ í•„ìš”í•©ë‹ˆë‹¤.",
                            tfu.YELLOW,
                        )
                # USE_GCP_KEY=Falseì¸ ê²½ìš°: vertexai=False, credentials=None (api_key ì‚¬ìš©)

        return VLMProcessor(
            model=self.vlm_model,
            logprobs=logprobs_value,
            debug=self.debug,
            vertexai=vertexai,
            credentials=credentials,
            project_id=project_id,
            location=location,
        )

    def _evaluate_feedback(self, user_prompt: str) -> bool:
        """
        Feedback Evaluation (Internal Method)
        
        Args:
            user_prompt: ì‚¬ìš©ìž ìž…ë ¥ ë¬¸ìžì—´
        Returns:
            Feedback ì œê³µ ì—¬ë¶€
        """
        
        if not user_prompt or not isinstance(user_prompt, str):
            return False
        
        ## Change this one to the feedback keywords you want to use (list of strings)
        feedback_keywords = [
            "wrong",
            "feedback :"
        ]
        
        user_lower = user_prompt.lower()
        for keyword in feedback_keywords:
            if keyword in user_lower:
                return True
        
        return False
    
    def _parse_step_feedback(self, feedback_input: str) -> Tuple[Optional[Dict[str, Optional[str]]], bool]:
        """
        Step Feedback íŒŒì‹±
        
        Args:
            feedback_input: ì‚¬ìš©ìž ìž…ë ¥ ë¬¸ìžì—´
            
        Returns:
            (feedback_dict, is_termination_command)
            - feedback_dict: {"user_preference": ..., "spatial": ..., "procedural": ..., "general": ...} ë˜ëŠ” None
            - is_termination_command: ì¢…ë£Œ ëª…ë ¹ ì—¬ë¶€
        """
        if not feedback_input or not isinstance(feedback_input, str):
            return None, False
        
        feedback_input = feedback_input.strip()
        
        # ì¢…ë£Œ ëª…ë ¹ í™•ì¸
        from utils.miscellaneous.global_variables import EPISODE_TERMINATION_KEYWORDS
        if feedback_input.lower() in [kw.lower() for kw in EPISODE_TERMINATION_KEYWORDS]:
            return None, True
        
        # í˜•ì‹ íŒŒì‹±: {s/w/f} : (u: ..., s: ..., p: ..., g: ...)
        import re
        
        # ìƒíƒœ ì¶”ì¶œ (s/w/f)
        status_match = re.match(r'^([swfSWF])\s*:\s*\(', feedback_input)
        if not status_match:
            return None, False
        
        status_char = status_match.group(1).lower()
        
        # ê´„í˜¸ ì•ˆì˜ ë‚´ìš© ì¶”ì¶œ
        content_match = re.search(r'\((.+)\)', feedback_input)
        if not content_match:
            return None, False
        
        content = content_match.group(1)
        
        # ê° íƒ€ìž…ë³„ í”¼ë“œë°± ì¶”ì¶œ
        feedback_dict = {
            "user_preference": None,
            "spatial": None,
            "procedural": None,
            "general": None
        }
        
        # íƒ€ìž… ë§¤í•‘
        type_mapping = {
            'u': 'user_preference',
            's': 'spatial',
            'p': 'procedural',
            'g': 'general'
        }
        type_keys = list(type_mapping.keys())
        
        # ê° íƒ€ìž…ë³„ë¡œ ë‹¤ìŒ íƒ€ìž… êµ¬ë¶„ìžë‚˜ ëê¹Œì§€ ì¶”ì¶œ
        for key, feedback_type in type_mapping.items():
            # í˜„ìž¬ íƒ€ìž… êµ¬ë¶„ìž ì°¾ê¸°
            pattern = rf'{key}\s*:\s*'
            match = re.search(pattern, content, re.IGNORECASE)
            if match:
                start = match.end()
                # ë‹¤ìŒ íƒ€ìž… êµ¬ë¶„ìž ì°¾ê¸° (í˜„ìž¬ íƒ€ìž…ì´ ì•„ë‹Œ ë‹¤ë¥¸ íƒ€ìž…ë“¤)
                next_keys = [k for k in type_keys if k.lower() != key.lower()]
                next_pattern = '|'.join([rf'\s*{k}\s*:' for k in next_keys])
                end_match = re.search(next_pattern, content[start:], re.IGNORECASE)
                
                if end_match:
                    end = start + end_match.start()
                else:
                    end = len(content)
                
                # ì¶”ì¶œ í›„ ì•žë’¤ ê³µë°± ë° ë§ˆì§€ë§‰ ì‰¼í‘œ ì œê±°
                feedback_text = content[start:end].strip().rstrip(',')
                if feedback_text:
                    feedback_dict[feedback_type] = feedback_text
        
        return feedback_dict, False
    
    def _collect_step_feedback(self, step_id: int, instruction: str) -> tuple[Optional[Dict[str, Optional[str]]], bool]:
        """
        Step Feedback ìˆ˜ì§‘
        
        Args:
            step_id: Step ë²ˆí˜¸
            instruction: Instruction ë‚´ìš©
            
        Returns:
            (feedback_dict, is_termination_command)
        """
        tfu.cprint("\n" + "=" * 80, bold=True)
        tfu.cprint(f"[Step {step_id} Feedback]", bold=True, indent=8)
        tfu.cprint("=" * 80 + "\n", bold=True)
        
        tfu.cprint(f"Instruction: {instruction}", tfu.LIGHT_BLUE)
        tfu.cprint("Status changed image displayed above.\n", tfu.LIGHT_BLACK)
        
        # Feedback format and examples - visually enhanced
        tfu.cprint("â”€" * 80, tfu.LIGHT_WHITE)
        tfu.cprint("ðŸ“‹ Feedback Format & Grounding Stacking", tfu.LIGHT_WHITE, bold=True)
        tfu.cprint("â”€" * 80, tfu.LIGHT_WHITE)
        
        tfu.cprint("\n  Format:", tfu.LIGHT_CYAN, bold=True)
        tfu.cprint("    >> {s/f/w}:(u: (feedback), s: (feedback), p: (feedback), g: (feedback))", tfu.LIGHT_YELLOW)
        
        tfu.cprint("\n  Status Codes & Elements:", tfu.LIGHT_CYAN, bold=True)
        tfu.cprint("    " + "s (Success)".ljust(25) + ": Entering the target area", tfu.LIGHT_GREEN)
        tfu.cprint("      " + "â†’ Reasons for Success", tfu.LIGHT_BLACK)
        tfu.cprint("      " + "  Example: " + "[Reason]", tfu.LIGHT_YELLOW, bold=True, underline=True)
        tfu.cprint("    " + "f (Failure)".ljust(25) + ": Taking an abnormal path as judged by a human observer", tfu.LIGHT_RED)
        tfu.cprint("      " + "â†’ Reasons for Failure and Next Plan", tfu.LIGHT_BLACK)
        tfu.cprint("      " + "  Example: " + "[Reason]. [The PLAN to be carried out in the next episode].", tfu.LIGHT_YELLOW, bold=True, underline=True)
        tfu.cprint("    " + "w (Work in Progress)".ljust(25) + ": When simply moving to the target room", tfu.LIGHT_YELLOW)
        tfu.cprint("      " + "â†’ Feedback not required (Null)", tfu.LIGHT_BLACK)
        
        tfu.cprint("\n  Feedback Types:", tfu.LIGHT_CYAN, bold=True)
        tfu.cprint("    " + "u".ljust(5) + "= User Preference", tfu.LIGHT_BLUE)
        tfu.cprint("    " + "s".ljust(5) + "= Spatial", tfu.LIGHT_MAGENTA)
        tfu.cprint("    " + "p".ljust(5) + "= Procedural", tfu.LIGHT_CYAN)
        tfu.cprint("    " + "g".ljust(5) + "= General", tfu.LIGHT_WHITE)
        
        tfu.cprint("\n  Notes:", tfu.LIGHT_CYAN, bold=True)
        tfu.cprint("    â€¢ You only need to write the necessary elements (u, s, p, g)", tfu.LIGHT_BLACK, italic=True)
        tfu.cprint("    â€¢ Colon spacing is optional: 's:' or 's :' both work", tfu.LIGHT_BLACK, italic=True)
        
        tfu.cprint("\n  Examples:", tfu.LIGHT_CYAN, bold=True)
        tfu.cprint("    " + ">> s:(u: Spicy preference. Add Pepper., s: , p: )", tfu.LIGHT_BLACK)
        tfu.cprint("    " + ">> f:(u: , s: , g: Wall blocking movement, failed)", tfu.LIGHT_BLACK)
        tfu.cprint("    " + ">> w:", tfu.LIGHT_BLACK)
        
        tfu.cprint("\n" + "â”€" * 80, tfu.LIGHT_WHITE)
        tfu.cprint("ì¢…ë£Œí•˜ë ¤ë©´: end", tfu.LIGHT_YELLOW, bold=True)
        
        # ëˆˆì— ë„ëŠ” feedback ìž…ë ¥ í”„ë¡¬í”„íŠ¸
        tfu.cprint("\n" + "â•" * 80, tfu.LIGHT_CYAN, bold=True)
        tfu.cprint("ðŸ“ " + " " * 28 + "FEEDBACK ìž…ë ¥" + " " * 28, tfu.LIGHT_CYAN, bold=True)
        tfu.cprint("â•" * 80, tfu.LIGHT_CYAN, bold=True)
        tfu.cprint("\nEnter feedback:", tfu.LIGHT_CYAN, bold=True)
        
        # ìƒ‰ìƒì´ ì ìš©ëœ ìž…ë ¥ í”„ë¡¬í”„íŠ¸
        sys.stdout.write(f"{Fore.LIGHTCYAN_EX}{Style.BRIGHT}> {Style.RESET_ALL}")
        sys.stdout.flush()
        user_input = input().strip()
        
        if not user_input:
            return None, False
        
        # íŒŒì‹±
        feedback_dict, is_termination = self._parse_step_feedback(user_input)
        
        return feedback_dict, is_termination
    
    def _format_carrying_object(self, carrying_obj) -> str:
        """
        Format carrying object information for terminal display.
        Uses JSON map file to get the correct emoji character for emoji objects.
        Supports both single object and list of objects.
        
        Args:
            carrying_obj: The object(s) being carried by the agent (can be single object or list)
            
        Returns:
            Formatted string describing the carrying object(s)
        """
        if carrying_obj is None:
            return "None"
        
        # Handle list of objects
        if isinstance(carrying_obj, list):
            if len(carrying_obj) == 0:
                return "None"
            # Format all objects in the list
            formatted_objects = []
            for obj in carrying_obj:
                formatted_objects.append(self._format_single_carrying_object(obj))
            return f"[{', '.join(formatted_objects)}]"
        
        # Handle single object
        return self._format_single_carrying_object(carrying_obj)
    
    def _format_single_carrying_object(self, carrying_obj) -> str:
        """
        Format a single carrying object information for terminal display.
        
        Args:
            carrying_obj: A single object being carried by the agent
            
        Returns:
            Formatted string describing the carrying object
        """
        if carrying_obj is None:
            return "None"
        
        # Try to get emoji character from JSON map file
        emoji_char = None
        if hasattr(self, 'json_map_path') and self.json_map_path:
            try:
                import json
                with open(self.json_map_path, 'r', encoding='utf-8') as f:
                    map_data = json.load(f)
                    if 'map' in map_data and 'emoji_objects' in map_data['map']:
                        emoji_objects = map_data['map']['emoji_objects']
                        # Search for emoji_name in emoji_objects
                        for emoji_key, emoji_def in emoji_objects.items():
                            if emoji_def.get('emoji_name') == getattr(carrying_obj, 'emoji_name', None):
                                emoji_char = emoji_key
                                break
            except Exception:
                # If JSON loading fails, fall back to default mapping
                pass
        
        # Fallback emoji mapping for common objects (if JSON lookup failed)
        if emoji_char is None:
            emoji_map = {
                'box': 'ðŸ“¦',
                'apple': 'ðŸŽ',
                'key': 'ðŸ”‘',
                'ball': 'âš½',
                'chair': 'ðŸª‘',
                'tree': 'ðŸŒ²',
                'mushroom': 'ðŸ„',
                'flower': 'ðŸŒ¼',
                'cat': 'ðŸˆ',
                'grass': 'ðŸŒ¾',
                'rock': 'ðŸ—¿',
                'desktop': 'ðŸ–¥ï¸',
                'workstation': 'ðŸ“±',
                'brick': 'ðŸ§±'
            }
            if hasattr(carrying_obj, 'emoji_name'):
                emoji_char = emoji_map.get(carrying_obj.emoji_name, 'â“')
            else:
                emoji_char = 'â“'
        
        if hasattr(carrying_obj, 'type'):
            obj_type = carrying_obj.type
            
            # Handle emoji objects
            if obj_type == 'emoji' and hasattr(carrying_obj, 'emoji_name'):
                emoji_name = carrying_obj.emoji_name
                color = getattr(carrying_obj, 'color', 'N/A')
                return f"{emoji_char} {emoji_name} (color: {color})"
            
            # Handle standard MiniGrid objects
            elif obj_type == 'key':
                color = getattr(carrying_obj, 'color', 'N/A')
                return f"ðŸ”‘ Key (color: {color})"
            elif obj_type == 'ball':
                color = getattr(carrying_obj, 'color', 'N/A')
                return f"âš½ Ball (color: {color})"
            elif obj_type == 'box':
                color = getattr(carrying_obj, 'color', 'N/A')
                return f"ðŸ“¦ Box (color: {color})"
            else:
                # Generic object with color if available
                color = getattr(carrying_obj, 'color', None)
                if color:
                    return f"{obj_type} (color: {color})"
                else:
                    return f"{obj_type}"
        else:
            # Fallback: just return string representation
            return str(carrying_obj)
    
    def vlm_gen_action(self,
                       image: np.ndarray,
                       system_prompt: str,
                       user_prompt: str,
                       use_logprobs: bool = None,
                       grounding_file: Optional[Union[str, Path]] = None
                      ) -> dict:
        """
        VLM call for Action creation.
        use_logprobs=True ì´ê³  logprobsê°€ í™œì„± ìƒíƒœì¼ ë•Œë§Œ logprobs í˜¸ì¶œ.
        """
        use_lp = self.logprobs_active if use_logprobs is None else (use_logprobs and self.logprobs_active)

        tfu.cprint("\n[3] Sending Action creation request to VLM...")

        if use_lp and self.vlm_processor.logprobs:
            try:
                raw_response, logprobs_metadata = self.vlm_processor.requester_with_logprobs(
                    image=image,
                    system_prompt=system_prompt,
                    user_prompt=user_prompt,
                    grounding_file=grounding_file,
                    debug=self.debug
                )

                if not raw_response:
                    tfu.cprint("The VLM response is empty.")
                    return {}

                tfu.cprint("VLM response received")
                tfu.cprint("[4] Parsing response with logprobs...")
                parsed = self.vlm_processor.parser_action_with_logprobs(
                    raw_response,
                    logprobs_metadata,
                    action_field="action",
                    remove_logprobs=False
                )

                # logprobs ì •ë³´ ì €ìž¥ (ë¡œê¹…ìš©)
                self.logprobs_metadata = logprobs_metadata
                self.action_logprobs_info = parsed.get('action_logprobs_info', {})
                
                # Print logprobs info if debug is enabled
                if self.debug and self.action_logprobs_info:
                    self.vlm_processor.postprocessor_action.print_action_logprobs_info(self.action_logprobs_info)
                
                return parsed
            except Exception as e:
                tfu.cprint(f"[Warning] logprobs í˜¸ì¶œ ì‹¤íŒ¨, ì¼ë°˜ ëª¨ë“œë¡œ ìž¬ì‹œë„: {e}", tfu.LIGHT_RED)
                # fallthrough to non-logprobs

        # ì¼ë°˜ ëª¨ë“œ
        raw_response = self.vlm_processor.requester(
            image=image,
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            grounding_file=grounding_file,
            debug=self.debug
        )

        if not raw_response:
            tfu.cprint("The VLM response is empty.")
            return {}

        tfu.cprint("VLM response received")
        tfu.cprint("[4] Parsing response...")
        parsed = self.vlm_processor.parser_action(raw_response)
        # ì¼ë°˜ ëª¨ë“œì—ì„œëŠ” logprobs ì •ë³´ ì´ˆê¸°í™”
        self.logprobs_metadata = {}
        self.action_logprobs_info = {}
        return parsed
    
    def vlm_gen_feedback(self, system_prompt: str, user_feedback: str) -> str:
        """
        VLM call for feedback generation
        """
        
        tfu.cprint("\n[3-F] Sending Feedback Analysis Request to VLM...")
        
        feedback_system_prompt = self.prompt_organizer.get_feedback_system_prompt()
        
        file_name = "feedback_user_prompt.txt"
        
        feedback_user_prompt = system_prompt_interp(file_name,
                                                    strict=True,
                                                    system_prompt=system_prompt,
                                                    user_feedback=user_feedback
                                                   )
        
        raw_response = self.vlm_processor.requester(
            image=None,
            system_prompt=feedback_system_prompt,
            user_prompt=feedback_user_prompt,
            debug=self.debug
        )
        
        if not raw_response:
            tfu.cprint("[Warning] Feedback VLM response is empty!", tfu.LIGHT_RED)
            return ""
        
        tfu.cprint("Feedback VLM Response Received", tfu.LIGHT_GREEN, indent=8)
        tfu.cprint("\n[4-F] Parsing Feedback Response...\n", tfu.LIGHT_BLACK)
        parsed = self.vlm_processor.parser_feedback(raw_response)
        knowledge = parsed.get('knowledge', '')
        
        if knowledge:
            tfu.cprint(f"\n[4-F-1] Generated Knowledge: {knowledge}", tfu.LIGHT_BLACK)
            self.prompt_organizer.update_grounding(knowledge)
            tfu.cprint("\n[4-F-2] Grounding update complete", tfu.LIGHT_GREEN)
            tfu.cprint("\n" + "=" * 80 + "\n", bold=True)
            tfu.cprint("Updated Grounding Information:")
            tfu.cprint("-" * 80)
            tfu.cprint(knowledge + "\n", tfu.LIGHT_BLUE)
            tfu.cprint("\nComplete Grounding Information:", tfu.BLUE, True)
            tfu.cprint("-" * 80)
            if self.prompt_organizer.grounding:
                tfu.cprint(self.prompt_organizer.grounding, tfu.BLUE, True)
            else:
                tfu.cprint("(None)")
            tfu.cprint("\n" + "=" * 80, bold=True)
        
        return knowledge
    
    def _create_grounding_vlm_processor(self) -> VLMProcessor:
        """
        Grounding ìƒì„± ì „ìš© VLMProcessor ìƒì„±
        Gemini ì¸ì¦ ë°©ë²•(GCP key ë˜ëŠ” API key)ë„ global_variables ì„¤ì •ì— ë”°ë¼ ê²°ì •.
        
        Returns:
            VLMProcessor ì¸ìŠ¤í„´ìŠ¤
        """
        grounding_model = GROUNDING_VLM_MODEL if GROUNDING_VLM_MODEL else VLM_MODEL
        model_lower = (grounding_model or "").lower()
        
        # Gemini ì¸ì¦ ë°©ë²• ê²°ì • (GCP key ë˜ëŠ” API key)
        credentials = None
        vertexai = False
        project_id = None
        location = None
        
        # Gemini ëª¨ë¸ì¸ ê²½ìš°ì—ë§Œ ì¸ì¦ ë°©ë²• í™•ì¸
        if model_lower.startswith("gemini"):
            # Vertex AI ëª¨ë¸ì¸ ê²½ìš°: í•­ìƒ GCP key ì‚¬ìš©
            if "-vertex" in model_lower or "-logprobs" in model_lower:
                vertexai = True
                project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
                location = os.getenv("GOOGLE_CLOUD_LOCATION", "us-central1")
            else:
                # ì¼ë°˜ Gemini ëª¨ë¸ì¸ ê²½ìš°: USE_GCP_KEY=Trueë©´ Vertex AI ê²½ë¡œë¡œ ê°•ì œ ì „í™˜
                if USE_GCP_KEY:
                    vertexai = True
                    project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
                    location = os.getenv("GOOGLE_CLOUD_LOCATION", "us-central1")
        
        return VLMProcessor(
            model=grounding_model,
            temperature=GROUNDING_VLM_TEMPERATURE,
            max_tokens=GROUNDING_VLM_MAX_TOKENS,
            debug=self.debug,
            vertexai=vertexai,
            credentials=credentials,
            project_id=project_id,
            location=location,
        )
    
    def _generate_grounding_from_episode(self):
        """
        ì—í”¼ì†Œë“œ ì¢…ë£Œ ì‹œ ì¼ê´„ Grounding ìƒì„±
        """
        if not self.episode_manager or not self.grounding_file_manager:
            return
        
        tfu.cprint("\n" + "=" * 80, bold=True)
        tfu.cprint("[Grounding Generation]", bold=True)
        tfu.cprint("=" * 80 + "\n", bold=True)
        tfu.cprint("Generating grounding from episode feedbacks...", tfu.LIGHT_BLACK)
        
        # GroundingFileManagerì—ì„œ stacked_grounding ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (Status í¬í•¨)
        stacked_grounding = self.grounding_file_manager.get_stacked_grounding()
        
        # Grounding ìƒì„± ì‹œì—ëŠ” í•­ìƒ í˜„ìž¬ ì—í”¼ì†Œë“œ í”¼ë“œë°±ë§Œ ì‚¬ìš©
        # ì´ì „ Groundingì€ ë‹¤ìŒ ì—í”¼ì†Œë“œì˜ Action ìƒì„± ì‹œì—ë§Œ ì‚¬ìš©ë¨
        previous_grounding = ""
        tfu.cprint(f"[Grounding] Using only current episode feedbacks for grounding generation", tfu.LIGHT_CYAN)
        
        # í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        system_prompt = system_prompt_interp(
            file_name="grounding_generation_prompt.txt",
            strict=True
        )
        
        # User prompt ì¤€ë¹„ (stacked_groundingì—ì„œ ê°€ì ¸ì˜¤ê¸°, ì´ë¯¸ Status í¬í•¨ëœ í˜•ì‹)
        user_preference_feedbacks = "\n".join(stacked_grounding.get("user_preference", [])) or "None"
        spatial_feedbacks = "\n".join(stacked_grounding.get("spatial", [])) or "None"
        procedural_feedbacks = "\n".join(stacked_grounding.get("procedural", [])) or "None"
        general_feedbacks = "\n".join(stacked_grounding.get("general", [])) or "None"
        
        # Grounding ìƒì„± ì‹œì—ëŠ” í•­ìƒ í˜„ìž¬ ì—í”¼ì†Œë“œ í”¼ë“œë°±ë§Œ ì‚¬ìš©
        # ì´ì „ Groundingì€ ë‹¤ìŒ ì—í”¼ì†Œë“œì˜ Action ìƒì„± ì‹œì—ë§Œ ì‚¬ìš©ë¨
        previous_grounding_display = "None (Only current episode feedbacks will be used)"
        
        user_prompt = system_prompt_interp(
            file_name="grounding_generation_user_prompt.txt",
            strict=True,
            episode_id=self.episode_id,
            total_steps=self.episode_manager.episode_data["total_steps"],
            user_preference_feedbacks=user_preference_feedbacks,
            spatial_feedbacks=spatial_feedbacks,
            procedural_feedbacks=procedural_feedbacks,
            general_feedbacks=general_feedbacks,
            previous_grounding=previous_grounding_display
        )
        
        # ì´ˆê¸° ìƒíƒœ ì´ë¯¸ì§€ ê°€ì ¸ì˜¤ê¸°
        initial_image_path = self.episode_manager.get_initial_state_image_path()
        initial_image = None
        if initial_image_path and self.episode_manager:
            episode_dir = self.episode_manager.get_episode_dir()
            full_image_path = episode_dir / initial_image_path
            if full_image_path.exists():
                initial_image = np.array(Image.open(full_image_path))
        
        # VLM í˜¸ì¶œ
        grounding_processor = self._create_grounding_vlm_processor()
        
        tfu.cprint("\n[Sending Grounding Generation Request to VLM...]", tfu.LIGHT_BLACK)
        
        raw_response = grounding_processor.requester(
            image=initial_image,
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            debug=self.debug
        )
        
        if not raw_response:
            tfu.cprint("[Warning] Grounding VLM response is empty!", tfu.LIGHT_RED)
            return
        
        tfu.cprint("Grounding VLM Response Received", tfu.LIGHT_GREEN, indent=8)
        
        # íŒŒì‹±
        tfu.cprint("\n[Parsing Grounding Response...]\n", tfu.LIGHT_BLACK)
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            import json
            # JSON ë¸”ë¡ ì¶”ì¶œ
            json_match = None
            if "```json" in raw_response:
                import re
                json_match = re.search(r'```json\s*(.*?)\s*```', raw_response, re.DOTALL)
            elif "```" in raw_response:
                import re
                json_match = re.search(r'```\s*(.*?)\s*```', raw_response, re.DOTALL)
            else:
                json_match = re.search(r'\{.*\}', raw_response, re.DOTALL)
            
            if json_match:
                parsed = json.loads(json_match.group(1))
            else:
                parsed = json.loads(raw_response)
        except Exception as e:
            tfu.cprint(f"[Error] Failed to parse grounding response: {e}", tfu.RED, True)
            tfu.cprint(f"Raw response: {raw_response[:500]}...", tfu.LIGHT_RED)
            return
        
        # Final Grounding ì €ìž¥
        if parsed:
            # ìž…ë ¥ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìžì—´ë¡œ ì„¤ì • (ìž„ì˜ì˜ ë‚´ìš© ì±„ìš°ì§€ ì•ŠìŒ)
            for key in ["user_preference_grounding", "spatial_grounding", "procedural_grounding", "general_grounding_rules"]:
                if key in parsed and isinstance(parsed[key], dict):
                    content = parsed[key].get("content", "")
                    # "No specific", "None provided" ë“±ì˜ placeholder í…ìŠ¤íŠ¸ë¥¼ ë¹ˆ ë¬¸ìžì—´ë¡œ ë³€í™˜
                    if content and any(placeholder in content.lower() for placeholder in ["no specific", "none provided", "no ", "were provided"]):
                        parsed[key]["content"] = ""
            
            self.episode_manager.set_final_grounding(parsed)
            self.grounding_file_manager.save_final_grounding(parsed)
            tfu.cprint("\n[Grounding Generation Complete]", tfu.LIGHT_GREEN, True)
        else:
            tfu.cprint("[Warning] No grounding generated", tfu.LIGHT_RED)
    
    def _generate_reflexion(self):
        """
        Reflexion ìƒì„± (ì—í”¼ì†Œë“œ ì¢…ë£Œ ì‹œ)
        """
        if not self.episode_manager:
            return
        
        tfu.cprint("\n" + "=" * 80, bold=True)
        tfu.cprint("[Reflexion Generation]", bold=True)
        tfu.cprint("=" * 80 + "\n", bold=True)
        tfu.cprint("Generating reflexion from episode trajectory...", tfu.LIGHT_BLACK)
        
        # Episode ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        episode_data = self.episode_manager.episode_data
        all_steps = self.episode_manager.get_all_steps()
        final_grounding = episode_data.get("final_grounding", {})
        
        # Trajectory ìš”ì•½ ìƒì„±
        trajectory_str = "\n".join([
            f"Step {step['step_id']}: {step['instruction']} - {step['status']}"
            for step in all_steps
        ])
        
        # Feedbacks ìš”ì•½ (grounding_per_stepì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        all_steps = self.episode_manager.get_all_steps()
        feedbacks_str = "\n".join([
            f"Step {step['step_id']} ({step['status']}): {step.get('instruction', '')} - {', '.join([f'{k}: {v}' for k, v in step.get('feedback', {}).items() if v])}"
            for step in all_steps
            if step.get('feedback')
        ]) or "None"
        
        # Final Grounding ë¬¸ìžì—´í™”
        final_grounding_str = ""
        if final_grounding:
            for key, value in final_grounding.items():
                if isinstance(value, dict) and "content" in value:
                    final_grounding_str += f"{key}: {value['content']}\n"
        
        # í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        system_prompt = system_prompt_interp(
            file_name="reflexion_prompt.txt",
            strict=True
        )
        
        user_prompt = system_prompt_interp(
            file_name="reflexion_user_prompt.txt",
            strict=True,
            episode_id=self.episode_id,
            total_steps=episode_data["total_steps"],
            termination_reason=episode_data.get("termination_reason", "unknown"),
            episode_trajectory=trajectory_str,
            step_feedbacks=feedbacks_str,
            final_grounding=final_grounding_str or "None"
        )
        
        # VLM í˜¸ì¶œ
        tfu.cprint("\n[Sending Reflexion Generation Request to VLM...]", tfu.LIGHT_BLACK)
        
        raw_response = self.vlm_processor.requester(
            image=None,
            system_prompt=system_prompt,
            user_prompt=user_prompt,
            debug=self.debug
        )
        
        if not raw_response:
            tfu.cprint("[Warning] Reflexion VLM response is empty!", tfu.LIGHT_RED)
            return
        
        tfu.cprint("Reflexion VLM Response Received", tfu.LIGHT_GREEN, indent=8)
        
        # íŒŒì‹±
        tfu.cprint("\n[Parsing Reflexion Response...]\n", tfu.LIGHT_BLACK)
        
        try:
            import json
            import re
            # JSON ë¸”ë¡ ì¶”ì¶œ
            json_match = None
            if "```json" in raw_response:
                json_match = re.search(r'```json\s*(.*?)\s*```', raw_response, re.DOTALL)
            elif "```" in raw_response:
                json_match = re.search(r'```\s*(.*?)\s*```', raw_response, re.DOTALL)
            else:
                json_match = re.search(r'\{.*\}', raw_response, re.DOTALL)
            
            if json_match:
                parsed = json.loads(json_match.group(1))
            else:
                parsed = json.loads(raw_response)
            
            # í•„ìˆ˜ í•„ë“œ í™•ì¸
            reflexion = {
                "trajectory_summary": parsed.get("trajectory_summary", ""),
                "error_diagnosis": parsed.get("error_diagnosis", ""),
                "correction_plan": parsed.get("correction_plan", "")
            }
            
            self.episode_manager.set_reflexion(reflexion)
            tfu.cprint("\n[Reflexion Generation Complete]", tfu.LIGHT_GREEN, True)
            
        except Exception as e:
            tfu.cprint(f"[Error] Failed to parse reflexion response: {e}", tfu.RED, True)
            tfu.cprint(f"Raw response: {raw_response[:500]}...", tfu.LIGHT_RED)
    
    def _get_system_prompt_without_grounding(self, wrapper=None, last_action_result=None) -> str:
        """
        Generate system prompt without grounding content.
        Temporarily sets grounding to empty string, then restores original value.
        
        Args:
            wrapper: Environment wrapper (optional)
            last_action_result: Last action result dict (optional)
        
        Returns:
            System prompt string without grounding content
        """
        # Save original grounding
        original_grounding = self.prompt_organizer.grounding
        
        # Temporarily set grounding to empty
        self.prompt_organizer.grounding = ""
        
        try:
            # Get system prompt (will have empty grounding_content)
            # grounding_file_path=Noneì„ ì „ë‹¬í•˜ì—¬ grounding ì—†ì´ ìƒì„±
            system_prompt = self.prompt_organizer.get_system_prompt(wrapper, last_action_result, grounding_file_path=None)
        finally:
            # Restore original grounding
            self.prompt_organizer.grounding = original_grounding
        
        return system_prompt
    
    def _calculate_entropy_from_logprobs(self, action_logprobs_info: dict) -> Optional[float]:
        """
        Calculate entropy from action_logprobs_info.
        Uses the first action's entropy value.
        
        Args:
            action_logprobs_info: Dictionary from get_action_logprobs() containing:
                - 'action_entropies': List[float] - List of entropies for each action
        
        Returns:
            float: First action's entropy, or None if not available
        """
        if not action_logprobs_info:
            return None
        
        action_entropies = action_logprobs_info.get('action_entropies', [])
        if not action_entropies or len(action_entropies) == 0:
            return None
        
        # Use first action's entropy
        first_entropy = action_entropies[0]
        return first_entropy if first_entropy is not None else None
    
    def vlm_gen_action_H_X(self,
                           image: np.ndarray,
                           system_prompt: str,
                           user_prompt: str,
                           max_retries: int = 3,
                           retry_delay: float = 1.0
                          ) -> dict:
        """
        VLM call for H(X) calculation - without Language Instruction and Grounding.
        
        This method calls VLM with:
        - system_prompt: Grounding removed (empty string)
        - user_prompt: Empty string
        
        Args:
            image: Input image array
            system_prompt: Original system prompt (grounding will be removed)
            user_prompt: Original user prompt (will be set to empty string)
            max_retries: Maximum number of retry attempts (default: 3)
            retry_delay: Initial delay between retries in seconds (exponential backoff)
        
        Returns:
            Dictionary containing:
                - 'parsed': Parsed VLM response dict
                - 'logprobs_metadata': Logprobs metadata dict (if available)
                - 'action_logprobs_info': Action logprobs info dict (if available)
        """
        import time
        
        # Get system prompt without grounding
        system_prompt_no_grounding = self._get_system_prompt_without_grounding(
            self.wrapper, self.last_action_result
        )
        
        # Set user_prompt to empty string
        user_prompt_empty = ""
        
        tfu.cprint("\n[H(X)] Sending VLM request (no Language Instruction, no Grounding)...")
        
        if self.logprobs_active and self.vlm_processor.logprobs:
            last_exception = None
            for attempt in range(max_retries):
                try:
                    raw_response, logprobs_metadata = self.vlm_processor.requester_with_logprobs(
                        image=image,
                        system_prompt=system_prompt_no_grounding,
                        user_prompt=user_prompt_empty,
                        debug=self.debug
                    )
                    
                    if not raw_response:
                        tfu.cprint(f"[H(X)] VLM response is empty (attempt {attempt + 1}/{max_retries}).", tfu.LIGHT_RED)
                        if attempt < max_retries - 1:
                            delay = retry_delay * (2 ** attempt)  # Exponential backoff
                            tfu.cprint(f"[H(X)] Retrying in {delay:.1f}s...", tfu.LIGHT_YELLOW)
                            time.sleep(delay)
                            continue
                        return {
                            'parsed': {},
                            'logprobs_metadata': {},
                            'action_logprobs_info': {}
                        }
                    
                    tfu.cprint("[H(X)] VLM response received")
                    parsed = self.vlm_processor.parser_action_with_logprobs(
                        raw_response,
                        logprobs_metadata,
                        action_field="action",
                        remove_logprobs=False
                    )
                    
                    action_logprobs_info = parsed.get('action_logprobs_info', {})
                    
                    # Validate that we have valid data
                    if not action_logprobs_info or not action_logprobs_info.get('action_logprobs'):
                        tfu.cprint(f"[H(X)] Invalid action_logprobs_info (attempt {attempt + 1}/{max_retries}).", tfu.LIGHT_RED)
                        if attempt < max_retries - 1:
                            delay = retry_delay * (2 ** attempt)
                            tfu.cprint(f"[H(X)] Retrying in {delay:.1f}s...", tfu.LIGHT_YELLOW)
                            time.sleep(delay)
                            continue
                    
                    # Debug output
                    if self.debug:
                        action_chunk = parsed.get('action', [])
                        tfu.cprint(f"[H(X)] Action: {action_chunk}", tfu.LIGHT_CYAN)
                        if action_logprobs_info:
                            self.vlm_processor.postprocessor_action.print_action_logprobs_info(action_logprobs_info)
                    
                    return {
                        'parsed': parsed,
                        'logprobs_metadata': logprobs_metadata,
                        'action_logprobs_info': action_logprobs_info
                    }
                except Exception as e:
                    last_exception = e
                    tfu.cprint(f"[H(X)] Warning: logprobs call failed (attempt {attempt + 1}/{max_retries}): {e}", tfu.LIGHT_RED)
                    if attempt < max_retries - 1:
                        delay = retry_delay * (2 ** attempt)
                        tfu.cprint(f"[H(X)] Retrying in {delay:.1f}s...", tfu.LIGHT_YELLOW)
                        time.sleep(delay)
            
            tfu.cprint(f"[H(X)] All {max_retries} attempts failed. Last error: {last_exception}", tfu.LIGHT_RED, bold=True)
            return {
                'parsed': {},
                'logprobs_metadata': {},
                'action_logprobs_info': {}
            }
        else:
            tfu.cprint("[H(X)] Warning: logprobs not active, cannot calculate entropy", tfu.LIGHT_RED)
            return {
                'parsed': {},
                'logprobs_metadata': {},
                'action_logprobs_info': {}
            }
    
    def vlm_gen_action_H_X_given_S(self,
                                    image: np.ndarray,
                                    system_prompt: str,
                                    user_prompt: str,
                                    max_retries: int = 3,
                                    retry_delay: float = 1.0
                                   ) -> dict:
        """
        VLM call for H(X|S) calculation - without Language Instruction (Grounding included).
        
        This method calls VLM with:
        - system_prompt: Original system prompt (with grounding)
        - user_prompt: Empty string
        
        Args:
            image: Input image array
            system_prompt: System prompt with grounding
            user_prompt: Original user prompt (will be set to empty string)
            max_retries: Maximum number of retry attempts (default: 3)
            retry_delay: Initial delay between retries in seconds (exponential backoff)
        
        Returns:
            Dictionary containing:
                - 'parsed': Parsed VLM response dict
                - 'logprobs_metadata': Logprobs metadata dict (if available)
                - 'action_logprobs_info': Action logprobs info dict (if available)
        """
        import time
        
        # Use original system_prompt (with grounding)
        # Set user_prompt to empty string
        user_prompt_empty = ""
        
        tfu.cprint("\n[H(X|S)] Sending VLM request (no Language Instruction, with Grounding)...")
        
        if self.logprobs_active and self.vlm_processor.logprobs:
            last_exception = None
            for attempt in range(max_retries):
                try:
                    raw_response, logprobs_metadata = self.vlm_processor.requester_with_logprobs(
                        image=image,
                        system_prompt=system_prompt,
                        user_prompt=user_prompt_empty,
                        debug=self.debug
                    )
                    
                    if not raw_response:
                        tfu.cprint(f"[H(X|S)] VLM response is empty (attempt {attempt + 1}/{max_retries}).", tfu.LIGHT_RED)
                        if attempt < max_retries - 1:
                            delay = retry_delay * (2 ** attempt)
                            tfu.cprint(f"[H(X|S)] Retrying in {delay:.1f}s...", tfu.LIGHT_YELLOW)
                            time.sleep(delay)
                            continue
                        return {
                            'parsed': {},
                            'logprobs_metadata': {},
                            'action_logprobs_info': {}
                        }
                    
                    tfu.cprint("[H(X|S)] VLM response received")
                    parsed = self.vlm_processor.parser_action_with_logprobs(
                        raw_response,
                        logprobs_metadata,
                        action_field="action",
                        remove_logprobs=False
                    )
                    
                    action_logprobs_info = parsed.get('action_logprobs_info', {})
                    
                    # Validate that we have valid data
                    if not action_logprobs_info or not action_logprobs_info.get('action_logprobs'):
                        tfu.cprint(f"[H(X|S)] Invalid action_logprobs_info (attempt {attempt + 1}/{max_retries}).", tfu.LIGHT_RED)
                        if attempt < max_retries - 1:
                            delay = retry_delay * (2 ** attempt)
                            tfu.cprint(f"[H(X|S)] Retrying in {delay:.1f}s...", tfu.LIGHT_YELLOW)
                            time.sleep(delay)
                            continue
                    
                    # Debug output
                    if self.debug:
                        action_chunk = parsed.get('action', [])
                        tfu.cprint(f"[H(X|S)] Action: {action_chunk}", tfu.LIGHT_CYAN)
                        if action_logprobs_info:
                            self.vlm_processor.postprocessor_action.print_action_logprobs_info(action_logprobs_info)
                    
                    return {
                        'parsed': parsed,
                        'logprobs_metadata': logprobs_metadata,
                        'action_logprobs_info': action_logprobs_info
                    }
                except Exception as e:
                    last_exception = e
                    tfu.cprint(f"[H(X|S)] Warning: logprobs call failed (attempt {attempt + 1}/{max_retries}): {e}", tfu.LIGHT_RED)
                    if attempt < max_retries - 1:
                        delay = retry_delay * (2 ** attempt)
                        tfu.cprint(f"[H(X|S)] Retrying in {delay:.1f}s...", tfu.LIGHT_YELLOW)
                        time.sleep(delay)
            
            tfu.cprint(f"[H(X|S)] All {max_retries} attempts failed. Last error: {last_exception}", tfu.LIGHT_RED, bold=True)
            return {
                'parsed': {},
                'logprobs_metadata': {},
                'action_logprobs_info': {}
            }
        else:
            tfu.cprint("[H(X|S)] Warning: logprobs not active, cannot calculate entropy", tfu.LIGHT_RED)
            return {
                'parsed': {},
                'logprobs_metadata': {},
                'action_logprobs_info': {}
            }
    
    def vlm_gen_action_H_X_given_LS(self,
                                     image: np.ndarray,
                                     system_prompt: str,
                                     user_prompt: str,
                                     max_retries: int = 3,
                                     retry_delay: float = 1.0
                                    ) -> dict:
        """
        VLM call for H(X|L,S) calculation - with both Language Instruction and Grounding.
        
        This method wraps the existing vlm_gen_action() method to provide consistent
        return format with logprobs information.
        
        Args:
            image: Input image array
            system_prompt: System prompt with grounding
            user_prompt: User prompt with language instruction
            max_retries: Maximum number of retry attempts (default: 3)
            retry_delay: Initial delay between retries in seconds (exponential backoff)
        
        Returns:
            Dictionary containing:
                - 'parsed': Parsed VLM response dict
                - 'logprobs_metadata': Logprobs metadata dict (if available)
                - 'action_logprobs_info': Action logprobs info dict (if available)
        """
        import time
        
        tfu.cprint("\n[H(X|L,S)] Sending VLM request (with Language Instruction and Grounding)...")
        
        last_exception = None
        for attempt in range(max_retries):
            try:
                # Use existing vlm_gen_action method
                parsed = self.vlm_gen_action(
                    image=image,
                    system_prompt=system_prompt,
                    user_prompt=user_prompt,
                    use_logprobs=self.logprobs_active
                )
                
                # Extract logprobs information if available
                logprobs_metadata = getattr(self, 'logprobs_metadata', {})
                action_logprobs_info = getattr(self, 'action_logprobs_info', {})
                
                # Check if we got valid response
                if not parsed or not parsed.get('action'):
                    tfu.cprint(f"[H(X|L,S)] Invalid response (attempt {attempt + 1}/{max_retries}).", tfu.LIGHT_RED)
                    if attempt < max_retries - 1:
                        delay = retry_delay * (2 ** attempt)
                        tfu.cprint(f"[H(X|L,S)] Retrying in {delay:.1f}s...", tfu.LIGHT_YELLOW)
                        time.sleep(delay)
                        continue
                
                # Validate action_logprobs_info
                if not action_logprobs_info or not action_logprobs_info.get('action_logprobs'):
                    tfu.cprint(f"[H(X|L,S)] Invalid action_logprobs_info (attempt {attempt + 1}/{max_retries}).", tfu.LIGHT_RED)
                    if attempt < max_retries - 1:
                        delay = retry_delay * (2 ** attempt)
                        tfu.cprint(f"[H(X|L,S)] Retrying in {delay:.1f}s...", tfu.LIGHT_YELLOW)
                        time.sleep(delay)
                        continue
                
                # Debug output
                if self.debug:
                    action_chunk = parsed.get('action', [])
                    tfu.cprint(f"[H(X|L,S)] Action: {action_chunk}", tfu.LIGHT_CYAN)
                    if action_logprobs_info:
                        self.vlm_processor.postprocessor_action.print_action_logprobs_info(action_logprobs_info)
                
                return {
                    'parsed': parsed,
                    'logprobs_metadata': logprobs_metadata,
                    'action_logprobs_info': action_logprobs_info
                }
            except Exception as e:
                last_exception = e
                tfu.cprint(f"[H(X|L,S)] Warning: VLM call failed (attempt {attempt + 1}/{max_retries}): {e}", tfu.LIGHT_RED)
                if attempt < max_retries - 1:
                    delay = retry_delay * (2 ** attempt)
                    tfu.cprint(f"[H(X|L,S)] Retrying in {delay:.1f}s...", tfu.LIGHT_YELLOW)
                    time.sleep(delay)
        
        tfu.cprint(f"[H(X|L,S)] All {max_retries} attempts failed. Last error: {last_exception}", tfu.LIGHT_RED, bold=True)
        return {
            'parsed': {},
            'logprobs_metadata': {},
            'action_logprobs_info': {}
        }
    
    def _init_csv_logging(self):
        """
        CSV Logging Initialization
        """
        
        csv_path = self.log_dir / "experiment_log.csv"
        file_exists = csv_path.exists()
        
        self.csv_file = open(csv_path, 'a', newline='', encoding='utf-8')
        # CSVì— íŠ¹ìˆ˜ë¬¸ìž(ì¤„ë°”ê¿ˆ, ì‰¼í‘œ ë“±)ê°€ í¬í•¨ëœ ê²½ìš°ë¥¼ ìœ„í•´ QUOTE_ALL ì‚¬ìš©
        self.csv_writer = csv.writer(self.csv_file, quoting=csv.QUOTE_ALL)
        
        if not file_exists:
            self.csv_writer.writerow([
                "step", "timestamp", "agent_x", "agent_y", "agent_dir",
                "action_index", "action_name", "user_prompt",
                "vlm_action_chunk", "vlm_reasoning", "vlm_grounding",
                "memory_spatial_description", "memory_task_goal", "memory_task_status", "memory_task_blocked_reason", "memory_previous_action",
                "last_action_result_action", "last_action_result_success", "last_action_result_failure_reason", "last_action_result_position_changed",
                "reward", "done", "image_path", "vlm_action_logprobs_info",
                "carrying_object", "is_pickup", "is_drop",
                "entropy_H_X", "entropy_H_X_given_S", "entropy_H_X_given_LS", "trust_T"
            ])
    
    def _log_step(self):
        """
        Current step logging
        """
        
        timestamp = datetime.now().isoformat()
        
        agent_pos = self.state['agent_pos']
        if isinstance(agent_pos, np.ndarray):
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        else:
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        
        image_path = f"step_{self.step:04d}.png"
        
        # Memory Parsing
        memory = self.vlm_response_parsed.get('memory', {})
        if isinstance(memory, str):
            try:
                memory = json.loads(memory)
            except Exception:
                memory = {"spatial_description": "", "task_process": {"goal": "", "status": ""}, "previous_action": ""}
        elif not isinstance(memory, dict):
            memory = {"spatial_description": "", "task_process": {"goal": "", "status": ""}, "previous_action": ""}
        
        # task_process parsing
        task_process = memory.get('task_process', {})
        if not isinstance(task_process, dict):
            task_process = {"goal": "", "status": "", "blocked_reason": ""}
        
        action_chunk = self.vlm_response_parsed.get('action', [])
        if isinstance(action_chunk, str):
            try:
                action_chunk = json.loads(action_chunk)
            except Exception:
                action_chunk = [action_chunk] if action_chunk else []
        if not isinstance(action_chunk, list):
            action_chunk = [str(action_chunk)]
        
        # Get last_action_result
        last_action_result = self.last_action_result if hasattr(self, 'last_action_result') else {
            "action": "",
            "success": True,
            "failure_reason": "",
            "position_changed": True
        }
        
        # Get carrying object information
        carrying_object = "None"
        env = self.wrapper.env
        if hasattr(env, 'carrying'):
            if isinstance(env.carrying, list):
                if len(env.carrying) > 0:
                    carrying_object = self._format_carrying_object(env.carrying)
            elif env.carrying is not None:
                carrying_object = self._format_carrying_object(env.carrying)
        
        # Check if action is pickup or drop
        is_pickup = (self.action_name.lower() in ['pickup', 'pick up'] or self.action_index == 4)
        is_drop = (self.action_name.lower() in ['drop'] or self.action_index == 5)
        
        # CSVì— ê¸°ë¡í•  ê°’ë“¤ì„ ì¤€ë¹„ (ì—¬ëŸ¬ ì¤„, ì½¤ë§ˆ ë“±ì„ í¬í•¨í•œ ë¬¸ìžì—´ë„ ì•ˆì „í•˜ê²Œ ì²˜ë¦¬)
        # QUOTE_ALLì„ ì‚¬ìš©í•˜ë¯€ë¡œ ëª¨ë“  í•„ë“œê°€ ìžë™ìœ¼ë¡œ ë”°ì˜´í‘œë¡œ ê°ì‹¸ì§
        # í•˜ì§€ë§Œ json.dumps()ë¡œ ë³€í™˜ëœ ë¬¸ìžì—´ì€ ì´ë¯¸ ì´ìŠ¤ì¼€ì´í”„ë˜ì–´ ìžˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        
        # Entropyì™€ Trust ê°’ (Noneì´ì–´ë„ ë¹ˆ ë¬¸ìžì—´ë¡œ ê¸°ë¡)
        entropy_H_X_val = ""
        entropy_H_X_given_S_val = ""
        entropy_H_X_given_LS_val = ""
        trust_T_val = ""
        
        if hasattr(self, 'entropy_H_X') and self.entropy_H_X is not None:
            import math
            if not math.isnan(self.entropy_H_X):
                entropy_H_X_val = str(self.entropy_H_X)
        
        if hasattr(self, 'entropy_H_X_given_S') and self.entropy_H_X_given_S is not None:
            import math
            if not math.isnan(self.entropy_H_X_given_S):
                entropy_H_X_given_S_val = str(self.entropy_H_X_given_S)
        
        if hasattr(self, 'entropy_H_X_given_LS') and self.entropy_H_X_given_LS is not None:
            import math
            if not math.isnan(self.entropy_H_X_given_LS):
                entropy_H_X_given_LS_val = str(self.entropy_H_X_given_LS)
        
        if hasattr(self, 'trust_T') and self.trust_T is not None:
            import math
            if not (isinstance(self.trust_T, float) and math.isnan(self.trust_T)):
                trust_T_val = str(self.trust_T)
        
        self.csv_writer.writerow([
            self.step,
            timestamp,
            agent_x,
            agent_y,
            int(self.state['agent_dir']),
            self.action_index,
            self.action_name,
            self.user_prompt,  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            json.dumps(action_chunk, ensure_ascii=False),  # JSON ë¬¸ìžì—´ì€ ì´ë¯¸ ì´ìŠ¤ì¼€ì´í”„ë¨
            self.vlm_response_parsed.get('reasoning', ''),  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            self.vlm_response_parsed.get('grounding', ''),  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            memory.get('spatial_description', ''),  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            task_process.get('goal', ''),  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            task_process.get('status', ''),  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            task_process.get('blocked_reason', ''),  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            memory.get('previous_action', ''),  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            last_action_result.get('action', ''),  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            bool(last_action_result.get('success', True)),
            last_action_result.get('failure_reason', ''),  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            bool(last_action_result.get('position_changed', True)),
            float(self.reward),
            bool(self.done),
            image_path,
            json.dumps(self.action_logprobs_info, ensure_ascii=False) if self.action_logprobs_info else "",  # JSON ë¬¸ìžì—´ì€ ì´ë¯¸ ì´ìŠ¤ì¼€ì´í”„ë¨
            carrying_object,  # QUOTE_ALLì´ ìžë™ìœ¼ë¡œ ì²˜ë¦¬
            bool(is_pickup),
            bool(is_drop),
            entropy_H_X_val,
            entropy_H_X_given_S_val,
            entropy_H_X_given_LS_val,
            trust_T_val
        ])
        self.csv_file.flush()
        
        json_path = self.log_dir / "experiment_log.json"
        
        # Get carrying object information for JSON log
        carrying_object_json = None
        env = self.wrapper.env
        if hasattr(env, 'carrying'):
            if isinstance(env.carrying, list):
                if len(env.carrying) > 0:
                    carrying_object_json = self._format_carrying_object(env.carrying)
            elif env.carrying is not None:
                carrying_object_json = self._format_carrying_object(env.carrying)
        
        # Check if action is pickup or drop for JSON log
        is_pickup_json = (self.action_name.lower() in ['pickup', 'pick up'] or self.action_index == 4)
        is_drop_json = (self.action_name.lower() in ['drop'] or self.action_index == 5)
        
        # ìƒˆ Grounding ì‹œìŠ¤í…œ: í˜„ìž¬ stepì˜ feedback ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        step_feedback_info = None
        if self.use_new_grounding_system and self.episode_manager:
            # í˜„ìž¬ step_idì™€ ì¼ì¹˜í•˜ëŠ” step ì°¾ê¸°
            all_steps = self.episode_manager.get_all_steps()
            current_step_data = None
            for step_data in all_steps:
                if step_data.get("step_id") == self.step:
                    current_step_data = step_data
                    break
            
            if current_step_data:
                step_feedback_info = {
                    "feedback": current_step_data.get("feedback", {}),
                    "status": current_step_data.get("status", ""),
                    "instruction": current_step_data.get("instruction", "")
                }
        
        json_data = {
            "step": self.step,
            "timestamp": timestamp,
            "state": {
                "agent_pos": [agent_x, agent_y],
                "agent_dir": int(self.state['agent_dir']),
                "mission": str(self.state.get('mission', ''))
            },
            "action": {
                "index": self.action_index,
                "name": self.action_name
            },
            "user_prompt": self.user_prompt,
            "vlm_response": self.vlm_response_parsed,
            "memory": memory,
            "grounding": self.prompt_organizer.grounding,
            "last_action_result": last_action_result,
            "reward": float(self.reward),
            "done": bool(self.done),
            "image_path": image_path,
            "action_logprobs_info": self.action_logprobs_info if self.action_logprobs_info else None,
            "carrying_object": carrying_object_json,
            "is_pickup": bool(is_pickup_json),
            "is_drop": bool(is_drop_json)
        }
        
        # Optional fields ì¶”ê°€ (ìžˆì„ ìˆ˜ë„, ì—†ì„ ìˆ˜ë„ ìžˆìŒ)
        if self.vlm_response_parsed.get('reasoning'):
            json_data["reasoning"] = self.vlm_response_parsed.get('reasoning')
        
        if hasattr(self, 'logprobs_metadata') and self.logprobs_metadata:
            json_data["logprobs_metadata"] = self.logprobs_metadata
        
        # Entropyì™€ Trust ê°’ì€ í•­ìƒ í¬í•¨ (Noneì´ì–´ë„)
        if hasattr(self, 'entropy_H_X'):
            json_data["entropy_H_X"] = self.entropy_H_X
        else:
            json_data["entropy_H_X"] = None
        
        if hasattr(self, 'entropy_H_X_given_S'):
            json_data["entropy_H_X_given_S"] = self.entropy_H_X_given_S
        else:
            json_data["entropy_H_X_given_S"] = None
        
        if hasattr(self, 'entropy_H_X_given_LS'):
            json_data["entropy_H_X_given_LS"] = self.entropy_H_X_given_LS
        else:
            json_data["entropy_H_X_given_LS"] = None
        
        if hasattr(self, 'trust_T'):
            json_data["trust_T"] = self.trust_T
        else:
            json_data["trust_T"] = None
        
        # ìƒˆ Grounding ì‹œìŠ¤í…œ: step feedback ì •ë³´ ì¶”ê°€
        if step_feedback_info:
            json_data["step_feedback"] = step_feedback_info
        
        all_data = []
        if json_path.exists():
            with open(json_path, 'r', encoding='utf-8') as f:
                try:
                    all_data = json.load(f)
                    if not isinstance(all_data, list):
                        all_data = [all_data]
                except json.JSONDecodeError:
                    all_data = []
        
        all_data.append(json_data)
        
        # Convert non-serializable types before saving
        from utils.miscellaneous.episode_manager import convert_numpy_types
        all_data_serializable = convert_numpy_types(all_data)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(all_data_serializable, f, indent=2, ensure_ascii=False)
        
        image_path_full = self.log_dir / image_path
        img_pil = Image.fromarray(self.image)
        img_pil.save(image_path_full)
    
    def initialize(self):
        """
        Reset experiment
        """
        
        tfu.cprint("\n\n" + "=" * 80 + "\n", bold=True)
        tfu.cprint("Scenario 2: VLM Control Experiment (Absolute Coordinate Movement Version)", bold=True)
        tfu.cprint("\n" + "=" * 80 + "\n", bold=True)
        
        # ìƒˆ Grounding ì‹œìŠ¤í…œ ì‚¬ìš© ì‹œ Episode ë²ˆí˜¸ ìž…ë ¥
        if self.use_new_grounding_system:
            tfu.cprint("\n[Episode Setup]", bold=True)
            tfu.cprint("Enter Episode number:", tfu.LIGHT_WHITE)
            episode_input = input("> ").strip()
            
            try:
                self.episode_id = int(episode_input)
            except ValueError:
                tfu.cprint(f"[Warning] Invalid episode number '{episode_input}'. Using episode 1.", tfu.LIGHT_RED)
                self.episode_id = 1
            
            # EpisodeManager ë° GroundingFileManager ì´ˆê¸°í™”
            self.episode_manager = EpisodeManager(self.episode_id, self.log_dir)
            self.grounding_file_manager = GroundingFileManager(
                self.episode_manager.get_episode_dir(),
                self.episode_id
            )
            tfu.cprint(f"Episode {self.episode_id} initialized", tfu.LIGHT_GREEN)
            tfu.cprint(f"Episode directory: {self.episode_manager.get_episode_dir()}", tfu.LIGHT_BLACK, italic=True)
        
        tfu.cprint(f"\nMission: {DEFAULT_MISSION}", tfu.LIGHT_BLACK, italic=True)
        tfu.cprint("\nAction Space: Direct movement possible up/down/left/right (absolute coordinates)", tfu.LIGHT_BLACK, italic=True)
        tfu.cprint(f"\nLog directory: {self.log_dir}", tfu.LIGHT_BLACK, italic=True)
        
        tfu.cprint("\n[1] Creating environment...")
        tfu.cprint(f"Map file: {self.json_map_path}", tfu.LIGHT_BLACK, italic=True, indent=4)
        self.wrapper = load_emoji_map_from_json(self.json_map_path)
        self.wrapper.reset()
        
        self.state = self.wrapper.get_state()
        tfu.cprint(f"Agent Start Position: {self.state['agent_pos']}", tfu.LIGHT_BLACK, italic=True, indent=4)
        tfu.cprint(f"Agent Direction: {self.state['agent_dir']}", tfu.LIGHT_BLACK, italic=True, indent=4)
        
        # Save initial position
        initial_pos = tuple(self.state['agent_pos'])
        if isinstance(initial_pos, np.ndarray):
            initial_pos = (int(initial_pos[0]), int(initial_pos[1]))
        self.previous_position = initial_pos
        
        # Initial last_action_result setting
        self.last_action_result = {
            "action": "",
            "success": True,
            "failure_reason": "",
            "position_changed": True
        }
        
        # ìƒˆ Grounding ì‹œìŠ¤í…œ: ì´ˆê¸° ìƒíƒœ ì´ë¯¸ì§€ ì €ìž¥
        if self.use_new_grounding_system and self.episode_manager:
            initial_image = self.wrapper.get_image()
            self.episode_manager.save_initial_state_image(initial_image)
        
        # Action Spatial Information Output
        action_space = self.wrapper.get_absolute_action_space()
        tfu.cprint(f"\nAbsolute Direction Action Space:", tfu.LIGHT_BLACK, italic=True, indent=4)
        tfu.cprint(f"  - Available actions: {action_space['actions']}", tfu.LIGHT_BLACK, italic=True, indent=4)
        
        tfu.cprint("\n[2] VLM initialization complete!", tfu.LIGHT_GREEN, True)
        tfu.cprint("\nExperiment Start...\n", tfu.LIGHT_BLACK, italic=True)
    
    def run_step(self, init_step: bool = False):
        """
        Execute one step
        """
        
        self.step += 1
        tfu.cprint("\n" + "=" * 80 + "\n", bold=True)
        tfu.cprint(f"STEP {self.step}", bold=True, indent=8)
        tfu.cprint("\n" + "=" * 80 + "\n", bold=True)
        
        self.image = self.wrapper.get_image()
        self.state = self.wrapper.get_state()
        heading = self.wrapper.get_heading()
        heading_desc = self.wrapper.get_heading_description()
        tfu.cprint(f"Location: {self.state['agent_pos']}, Direction: {self.state['agent_dir']} ({heading})")
        tfu.cprint(f"Current Heading: {heading_desc}")
        
        self.visualizer.visualize_grid_cli(self.wrapper, self.state)
        self.visualizer.display_image(self.image)
        
        if init_step:
            default_prompt = f"{DEFAULT_INITIAL_MISSION}"
        else:
            default_prompt = f"{DEFAULT_MISSION}"
        
        # Use PromptOrganizer (supports file paths, templates, etc.)
        self.user_prompt = self.prompt_organizer.get_user_prompt(default_prompt, init_step=init_step)
        
        tfu.cprint("\n" + "=" * 80, bold=True)
        tfu.cprint(f"{self.user_prompt}", tfu.YELLOW, True)
        tfu.cprint("=" * 80 + "\n", bold=True)
        
        if self.user_prompt is None:
            tfu.cprint("[Warning] No user prompt provided. Using empty prompt.", tfu.LIGHT_RED)
            self.user_prompt = default_prompt
        
        # Feedback Evaluation - use raw user input, not template-processed prompt
        # This avoids false positives from template text (e.g., "don't" in task_prompt.txt)
        raw_user_input = getattr(self.prompt_organizer, '_raw_user_input', '')
        has_feedback = self._evaluate_feedback(raw_user_input)
        
        if has_feedback:
            # Feedback processing: If it starts with â€œfeedback : â€
            if self.user_prompt.lower().startswith("feedback :"):
                feedback_text = self.user_prompt[10:].strip()  # Remove â€œfeedback : â€
            else:
                feedback_text = self.user_prompt
            
            # Feedback Generation VLM Call
            system_prompt = self.prompt_organizer.get_system_prompt(self.wrapper)
            self.vlm_gen_feedback(system_prompt, feedback_text)
            
            # Skip proceeding to create a general action after processing feedback.
            tfu.cprint("\n[4-1] Feedback processing complete! Proceeding to the next step.", tfu.LIGHT_GREEN, True)
            return True
        
        # Grounding íŒŒì¼ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸° (ìƒˆ Grounding ì‹œìŠ¤í…œ ì‚¬ìš© ì‹œ)
        # ì—¬ëŸ¬ íŒŒì¼ ì§€ì›: ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìžì—´
        grounding_file_path = None
        if self.use_new_grounding_system and GROUNDING_FILE_PATH:
            # ì—¬ëŸ¬ íŒŒì¼ ì§€ì›: ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìžì—´ ì²˜ë¦¬
            if isinstance(GROUNDING_FILE_PATH, str):
                # ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¬¸ìžì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if ',' in GROUNDING_FILE_PATH:
                    file_paths = [p.strip() for p in GROUNDING_FILE_PATH.split(',')]
                else:
                    file_paths = [GROUNDING_FILE_PATH]
            elif isinstance(GROUNDING_FILE_PATH, list):
                file_paths = GROUNDING_FILE_PATH
            else:
                file_paths = []
            
            # ê° íŒŒì¼ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ê³  ì¡´ìž¬ ì—¬ë¶€ í™•ì¸
            resolved_paths = []
            for file_path in file_paths:
                file_path_str = str(file_path).strip()
                potential_path = None
                tried_paths = []
                
                # ì ˆëŒ€ ê²½ë¡œì¸ ê²½ìš°
                if Path(file_path_str).is_absolute():
                    potential_path = Path(file_path_str)
                    tried_paths.append(str(potential_path))
                # logs/grounding/grounding_latest.txt í˜•ì‹ì¸ ê²½ìš° (ìƒëŒ€ ê²½ë¡œ)
                elif file_path_str.startswith("logs/"):
                    # 1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ (src/utils/miscellaneous -> project root)
                    project_root = Path(__file__).parent.parent.parent
                    potential_path = project_root / file_path_str
                    tried_paths.append(str(potential_path))
                    
                    # 2. src/ ê¸°ì¤€ìœ¼ë¡œë„ ì‹œë„
                    if not potential_path.exists():
                        src_root = Path(__file__).parent.parent.parent / "src"
                        potential_path = src_root / file_path_str
                        tried_paths.append(str(potential_path))
                    
                    # 3. í˜„ìž¬ log_dir ê¸°ì¤€ìœ¼ë¡œë„ ì‹œë„
                    if not potential_path.exists() and hasattr(self, 'log_dir'):
                        potential_path = self.log_dir.parent / file_path_str
                        tried_paths.append(str(potential_path))
                else:
                    # 1. í˜„ìž¬ log_dir ê¸°ì¤€ìœ¼ë¡œ ì°¾ê¸°
                    if hasattr(self, 'log_dir'):
                        potential_path = self.log_dir.parent / file_path_str
                        tried_paths.append(str(potential_path))
                    
                    # 2. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œë„ ì‹œë„
                    if (not potential_path or not potential_path.exists()):
                        project_root = Path(__file__).parent.parent.parent
                        potential_path = project_root / file_path_str
                        tried_paths.append(str(potential_path))
                    
                    # 3. src/ ê¸°ì¤€ìœ¼ë¡œë„ ì‹œë„
                    if not potential_path.exists():
                        src_root = Path(__file__).parent.parent.parent / "src"
                        potential_path = src_root / file_path_str
                        tried_paths.append(str(potential_path))
                
                if potential_path and potential_path.exists():
                    resolved_paths.append(str(potential_path.resolve()))
                    tfu.cprint(f"[Grounding] âœ“ Loaded: {potential_path.resolve()}", tfu.LIGHT_GREEN)
                else:
                    tfu.cprint(f"[Grounding] âœ— File not found: {file_path_str}", tfu.LIGHT_RED)
                    tfu.cprint(f"  Tried paths: {', '.join(tried_paths[:3])}", tfu.LIGHT_BLACK)
            
            # ì—¬ëŸ¬ íŒŒì¼ì´ ìžˆìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ì „ë‹¬ (vlm_wrapperì—ì„œ ì—¬ëŸ¬ íŒŒì¼ ì²˜ë¦¬)
            if resolved_paths:
                if len(resolved_paths) == 1:
                    grounding_file_path = resolved_paths[0]
                    tfu.cprint(f"[Grounding] Using single file: {grounding_file_path}", tfu.LIGHT_CYAN)
                else:
                    grounding_file_path = resolved_paths
                    tfu.cprint(f"[Grounding] Using {len(resolved_paths)} files (will be merged):", tfu.LIGHT_CYAN)
                    for i, path in enumerate(resolved_paths, 1):
                        tfu.cprint(f"  {i}. {path}", tfu.LIGHT_BLACK)
            else:
                tfu.cprint(f"[Grounding] No valid grounding files found", tfu.LIGHT_YELLOW)
                grounding_file_path = None
        
        # Create a General Action
        # System Prompt ìƒì„± ì‹œ grounding_file_path ì „ë‹¬ (USE_NEW_GROUNDING_SYSTEM=Trueì¼ ë•Œ System Promptì— í¬í•¨ë¨)
        system_prompt = self.prompt_organizer.get_system_prompt_by_mode(
            self.wrapper, 
            self.last_action_result,
            use_verbalized=USE_VERBALIZED_ENTROPY,
            grounding_file_path=grounding_file_path
        )
        
        self.vlm_response_parsed = self.vlm_gen_action(
            image=self.image,
            system_prompt=system_prompt,
            user_prompt=self.user_prompt,
            use_logprobs=self.logprobs_active,
            grounding_file=None  # System Promptì— ì´ë¯¸ í¬í•¨ë˜ì—ˆìœ¼ë¯€ë¡œ user_promptì— ì¶”ê°€í•˜ì§€ ì•ŠìŒ
        )
        
        if not self.vlm_response_parsed:
            return False
        
        # Extract only the first action from the action chunk
        action_chunk = self.vlm_response_parsed.get('action', [])
        if isinstance(action_chunk, str):
            try:
                action_chunk = json.loads(action_chunk)
            except Exception:
                action_chunk = [action_chunk] if action_chunk else []
        if not isinstance(action_chunk, list):
            action_chunk = [action_chunk]
        
        if len(action_chunk) == 0:
            action_str = '0'  # Default value: move up
        else:
            first_action = action_chunk[0]
            # Handle dict format for directional pickup: {"pickup": "north"}
            if isinstance(first_action, dict):
                action_str = first_action
            else:
                action_str = str(first_action)
        
        # Memory Parsing
        memory = self.vlm_response_parsed.get('memory', {})
        if isinstance(memory, str):
            try:
                memory = json.loads(memory)
            except Exception:
                memory = {}
        if not isinstance(memory, dict):
            memory = {}
        
        # task_process parsing
        task_process = memory.get('task_process', {})
        if not isinstance(task_process, dict):
            task_process = {"goal": "", "status": "", "blocked_reason": ""}
        
        # Parsing last_action_result (in VLM response)
        vlm_last_action_result = memory.get('last_action_result', {})
        if not isinstance(vlm_last_action_result, dict):
            vlm_last_action_result = {}
        
        # Memory Update
        if isinstance(memory, dict):
            self.prompt_organizer.previous_action = memory.get('previous_action', action_str)
            self.prompt_organizer.task_process = {
                "goal": task_process.get('goal', ''),
                "status": task_process.get('status', ''),
                "blocked_reason": task_process.get('blocked_reason', '')
            }
            
            # When VLM is set to blocked status, it is reflected.
            if task_process.get('status') == 'blocked':
                blocked_reason = task_process.get('blocked_reason', '')
                if blocked_reason:
                    tfu.cprint(f"\n[Memory] Task marked as blocked: {blocked_reason}")
        
        # Grounding Update (If from a response)
        grounding_update = self.vlm_response_parsed.get('grounding', '')
        grounding_updated = False
        if grounding_update and grounding_update.strip():
            self.prompt_organizer.update_grounding(grounding_update)
            grounding_updated = True
        
        # CLI output: Action, Reasoning, Memory, Grounding
        tfu.cprint("\n" + "=" * 80)
        tfu.cprint("[VLM Response Information]")
        tfu.cprint("=" * 80)
        
        # Action Chunk Output
        tfu.cprint("\n[Action Chunk]")
        tfu.cprint("-" * 80)
        if len(action_chunk) > 0:
            for i, action in enumerate(action_chunk, 1):
                marker = "â†’ Execution" if i == 1 else "  Prediction"
                tfu.cprint(f"{marker} [{i}] {action}", indent=4)
        else:
            tfu.cprint("(No action)", indent=4)
        
        # Reasoning Output
        reasoning = self.vlm_response_parsed.get('reasoning', '')
        tfu.cprint("\n[Reasoning...]")
        tfu.cprint("-" * 80)
        if reasoning:
            tfu.cprint(f"{reasoning}", indent=4)
        else:
            tfu.cprint("(None)", indent=4)
        
        # Memory Output
        tfu.cprint("\n[Memory]")
        tfu.cprint("-" * 80)
        spatial_desc = memory.get('spatial_description', '')
        task_goal = task_process.get('goal', '')
        task_status = task_process.get('status', '')
        prev_action = memory.get('previous_action', '')
        
        tfu.cprint("Spatial Description:", indent=4)
        if spatial_desc:
            tfu.cprint(f"{spatial_desc}", indent=8)
        else:
            tfu.cprint("(None)", indent=8)
        
        tfu.cprint("Task Process:", indent=4)
        if task_goal or task_status:
            tfu.cprint(f"Goal: {task_goal if task_goal else '(None)'}", indent=8)
            tfu.cprint(f"Status: {task_status if task_status else '(None)'}", indent=8)
        else:
            tfu.cprint("(None)", indent=8)
        
        tfu.cprint("Previous Action:", indent=4)
        if prev_action:
            tfu.cprint(f"{prev_action}", indent=8)
        else:
            tfu.cprint("(None)", indent=8)
        
        # Grounding Output (Only if updated)
        if grounding_updated:
            tfu.cprint("\n[Grounding Update]")
            tfu.cprint("-" * 80)
            tfu.cprint(f"{grounding_update}", indent=4)
        
        tfu.cprint("=" * 80)
        
        tfu.cprint("\n[5] Action in progress...")
        
        # Save Current Location (Before Action Execution)
        current_pos_before = tuple(self.state['agent_pos'])
        if isinstance(current_pos_before, np.ndarray):
            current_pos_before = (int(current_pos_before[0]), int(current_pos_before[1]))
        
        try:
            parsed_action = self.wrapper.parse_absolute_action(action_str)
            
            # Handle dict format for directional pickup: {"pickup": "north"}
            if isinstance(parsed_action, dict) and "pickup" in parsed_action:
                self.action_index = 4  # pickup action index
                direction = parsed_action["pickup"]
                self.action_name = f"pickup:{direction}"
            else:
                self.action_index = parsed_action
                action_space = self.wrapper.get_absolute_action_space()
                self.action_name = action_space['action_mapping'].get(self.action_index, f"action_{self.action_index}")
            tfu.cprint(f"Action to execute: {self.action_name} (Index: {self.action_index})")
            
            # Since use_absolute_movement=True, step() handles absolute movement.
            # Pass parsed_action if it's a dict (for directional pickup), otherwise use action_index
            action_to_execute = parsed_action if isinstance(parsed_action, dict) else self.action_index
            _, self.reward, terminated, truncated, _ = self.wrapper.step(action_to_execute)
            self.done = terminated or truncated
            
            # Confirm location after action execution
            new_state = self.wrapper.get_state()
            current_pos_after = tuple(new_state['agent_pos'])
            if isinstance(current_pos_after, np.ndarray):
                current_pos_after = (int(current_pos_after[0]), int(current_pos_after[1]))
            
            # Confirming position changes
            position_changed = (current_pos_before != current_pos_after)
            
            # Check if this is a movement action (0=up, 1=down, 2=left, 3=right)
            is_movement_action = (self.action_index in [0, 1, 2, 3])
            
            # Action Result Determination
            if is_movement_action:
                # For movement actions: success if position changed
                action_success = position_changed or self.reward > 0
                failure_reason = ""
                if not action_success:
                    # Reasoning about Failure Causes (Based on Visible Information in the Image)
                    if not position_changed:
                        failure_reason = "blocked_by_obstacle"
                    else:
                        failure_reason = "unknown"
            else:
                # For non-movement actions (pickup, drop, toggle): don't check reward
                # These actions don't change position, so we don't check position_changed or reward
                action_success = True  # Always consider as executed (not failed due to obstacle)
                failure_reason = ""
            
            # Check pickup failure: if pickup action was executed but nothing was picked up
            if self.action_index == 4:  # pickup action
                env = self.wrapper.env
                carrying_count = 0
                if hasattr(env, 'carrying'):
                    if isinstance(env.carrying, list):
                        carrying_count = len(env.carrying)
                    elif env.carrying is not None:
                        carrying_count = 1
                # Note: We can't easily detect if pickup failed since we always allow multiple pickups
                # This check is less useful now, but kept for compatibility
            
            # Last action result update
            self.last_action_result = {
                "action": self.action_name,
                "success": action_success,
                "failure_reason": failure_reason,
                "position_changed": position_changed
            }
            
            tfu.cprint(f"Reward: {self.reward}, End: {self.done}")
            tfu.cprint(f"Action Result: {'Success' if action_success else 'Failure'} (Position Change: {'Yes' if position_changed else 'No'})")
            if not action_success:
                print(f"Reasons for Failure: {failure_reason}")
            
            # Display carrying object information
            env = self.wrapper.env
            if hasattr(env, 'carrying'):
                if isinstance(env.carrying, list):
                    if len(env.carrying) > 0:
                        carrying_info = self._format_carrying_object(env.carrying)
                        tfu.cprint(f"Carrying Objects ({len(env.carrying)}): {carrying_info}", color=tfu.CYAN, bold=True)
                    else:
                        tfu.cprint("Carrying Objects: None", color=tfu.LIGHT_BLACK)
                elif env.carrying is not None:
                    carrying_info = self._format_carrying_object(env.carrying)
                    tfu.cprint(f"Carrying Object: {carrying_info}", color=tfu.CYAN, bold=True)
                else:
                    tfu.cprint("Carrying Object: None", color=tfu.LIGHT_BLACK)
            else:
                tfu.cprint("Carrying Object: None", color=tfu.LIGHT_BLACK)
                
        except Exception as e:
            tfu.cprint(f"Action execution failed: {e}")
            import traceback
            traceback.print_exc()
            self.action_index = 0
            self.action_name = "move up"
            try:
                _, self.reward, terminated, truncated, _ = self.wrapper.step(0)
                self.done = terminated or truncated
            except:
                pass
            
            # Update last_action_result even when an exception occurs
            self.last_action_result = {
                "action": self.action_name,
                "success": False,
                "failure_reason": "exception",
                "position_changed": False
            }
            
            # Display carrying object information even on exception
            env = self.wrapper.env
            if hasattr(env, 'carrying'):
                if isinstance(env.carrying, list):
                    if len(env.carrying) > 0:
                        carrying_info = self._format_carrying_object(env.carrying)
                        tfu.cprint(f"Carrying Objects ({len(env.carrying)}): {carrying_info}", color=tfu.CYAN, bold=True)
                    else:
                        tfu.cprint("Carrying Objects: None", color=tfu.LIGHT_BLACK)
                elif env.carrying is not None:
                    carrying_info = self._format_carrying_object(env.carrying)
                    tfu.cprint(f"Carrying Object: {carrying_info}", color=tfu.CYAN, bold=True)
                else:
                    tfu.cprint("Carrying Object: None", color=tfu.LIGHT_BLACK)
            else:
                tfu.cprint("Carrying Object: None", color=tfu.LIGHT_BLACK)
        
        # Previous action update (action actually executed)
        self.prompt_organizer.previous_action = self.action_name
        
        # new_state has already been retrieved above, so it is reused.
        if 'new_state' not in locals():
            new_state = self.wrapper.get_state()
        self.state = new_state
        self.visualizer.visualize_grid_cli(self.wrapper, new_state)
        updated_image = self.wrapper.get_image()
        self.image = updated_image
        self.visualizer.display_image(updated_image)
        
        # ìƒˆ Grounding ì‹œìŠ¤í…œ: Step Feedback ìˆ˜ì§‘
        feedback_dict = None
        is_termination = False
        
        if self.use_new_grounding_system:
            if self.episode_manager is None:
                tfu.cprint(f"\n[Warning] episode_manager is None. Skipping step feedback collection.", tfu.LIGHT_RED)
            else:
                # Instruction ì¶”ì¶œ (user_promptì—ì„œ)
                instruction = self.user_prompt if self.user_prompt else "Continue mission"
                
                # Status ê²°ì •
                if self.last_action_result.get("success", True):
                    status = "SUCCESS"
                else:
                    status = "FAILURE"
                
                # Step Feedback ìˆ˜ì§‘
                feedback_dict, is_termination = self._collect_step_feedback(
                    step_id=self.step,
                    instruction=instruction
                )
                
                # ì¢…ë£Œ ëª…ë ¹ í™•ì¸
                if is_termination:
                    tfu.cprint("\n[Episode Termination] User requested episode end.", tfu.LIGHT_YELLOW, True)
                    self.done = True
                    if self.episode_manager:
                        self.episode_manager.set_termination_reason("user_command")
                
                # Feedbackì´ ìžˆìœ¼ë©´ ì €ìž¥
                if feedback_dict:
                    # EpisodeManagerì— Step ì¶”ê°€
                    action_info = {
                        "index": int(self.action_index),
                        "name": str(self.action_name)
                    }
                    # Convert numpy types to Python native types
                    agent_pos = self.state['agent_pos']
                    if isinstance(agent_pos, np.ndarray):
                        agent_pos = [int(x) for x in agent_pos.tolist()]
                    else:
                        agent_pos = [int(x) for x in list(agent_pos)]
                    state_info = {
                        "agent_pos": agent_pos,
                        "agent_dir": int(self.state['agent_dir'])
                    }
                    image_path = f"images/step_{self.step:04d}.png"
                    
                    self.episode_manager.add_step(
                        step_id=self.step,
                        instruction=instruction,
                        status=status,
                        feedback=feedback_dict,
                        action=action_info,
                        state=state_info,
                        image_path=image_path
                    )
                    
                    # GroundingFileManagerì— Step feedback ì¶”ê°€
                    if self.grounding_file_manager:
                        self.grounding_file_manager.append_step_feedback(
                            step_id=self.step,
                            instruction=instruction,
                            status=status,
                            feedback=feedback_dict
                        )
                    
                    # ì´ë¯¸ì§€ ì €ìž¥ (Episode í´ë” ë‚´)
                    if self.episode_manager:
                        episode_images_dir = self.episode_manager.get_episode_dir() / "images"
                        image_path_full = episode_images_dir / f"step_{self.step:04d}.png"
                        img_pil = Image.fromarray(updated_image)
                        img_pil.save(image_path_full)
        
        self._log_step()
        
        return True
    
    def run(self):
        """
        Main Loop Execution
        """
        
        self.initialize()
        
        if self.step == 0:
            init_step = True
        else:
            raise ValueError("Initially, step isn't 0!")
        
        while not self.done:
            if not self.run_step(init_step):
                break
            
            if self.done:
                tfu.cprint("\n" + "=" * 80)
                tfu.cprint("Goal scored! Game ended.")
                tfu.cprint("=" * 80)
                if self.use_new_grounding_system and self.episode_manager:
                    self.episode_manager.set_termination_reason("done")
                break
            
            if self.step >= 100:
                tfu.cprint("\nThe maximum number of steps (100) has been reached..")
                if self.use_new_grounding_system and self.episode_manager:
                    self.episode_manager.set_termination_reason("max_steps")
                break
            
            if self.step >= 1:
                init_step = False
            else:
                raise ValueError("[Error] Step is still 0!")
    
    def cleanup(self):
        """
        Resource Cleanup
        """
        
        # ìƒˆ Grounding ì‹œìŠ¤í…œ: ì—í”¼ì†Œë“œ ì¢…ë£Œ ì‹œ ì²˜ë¦¬
        if self.use_new_grounding_system and self.episode_manager:
            # Grounding ìƒì„± (ì¼ê´„ ì²˜ë¦¬)
            self._generate_grounding_from_episode()
            
            # Reflexion ìƒì„±
            self._generate_reflexion()
            
            # Episode ì €ìž¥
            self.episode_manager.save()
        
        self.visualizer.cleanup()
        if self.wrapper:
            self.wrapper.close()
        if self.csv_file:
            self.csv_file.close()
        tfu.cprint(f"\nExperiment complete. Logs are {self.log_dir}. It has been saved.")



