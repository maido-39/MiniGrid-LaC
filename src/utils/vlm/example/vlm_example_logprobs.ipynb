{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Credentials path: ../../trans-century-405100-c8827a8ffbf4.json\n",
            "Project ID: trans-century-405100\n",
            "Location: us-central1\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import importlib\n",
        "\n",
        "# Add src directory to path for imports\n",
        "script_dir = Path().resolve()\n",
        "src_dir = script_dir.parent.parent.parent.parent / \"src\"\n",
        "if str(src_dir) not in sys.path:\n",
        "    sys.path.insert(0, str(src_dir))\n",
        "\n",
        "# 모듈 리로드 (변경사항 반영)\n",
        "modules_to_reload = [\n",
        "    'utils.vlm.vlm_processor',\n",
        "    'utils.vlm.vlm_postprocessor',\n",
        "    'utils.vlm.vlm_wrapper',\n",
        "    'utils.vlm.handlers.gemini_handler'\n",
        "]\n",
        "\n",
        "for module_name in modules_to_reload:\n",
        "    if module_name in sys.modules:\n",
        "        importlib.reload(sys.modules[module_name])\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Import VLM components\n",
        "from utils.vlm.vlm_wrapper import VLMWrapper\n",
        "from utils.vlm.vlm_postprocessor import VLMResponsePostProcessor\n",
        "\n",
        "# .env 파일에서 환경 변수를 불러오도록 구현\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# .env 파일이 상위경로(또는 프로젝트 루트)에 있다고 가정\n",
        "load_dotenv(dotenv_path=\"../../../../.env\")  # .env 파일 경로를 프로젝트 구조에 맞게 수정\n",
        "\n",
        "credentials_path = os.environ.get(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
        "project_id = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
        "location = os.environ.get(\"GOOGLE_CLOUD_LOCATION\", \"us-central1\")\n",
        "\n",
        "print(f\"Credentials path: {credentials_path}\")\n",
        "print(f\"Project ID: {project_id}\")\n",
        "print(f\"Location: {location}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example 2: Extract logprobs for action field in JSON response\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Example 2: Extract logprobs for action field in JSON response\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if not credentials_path or not project_id:\n",
        "    print(\"[SKIP] Vertex AI credentials not configured.\")\n",
        "else:\n",
        "    try:\n",
        "        # Initialize wrapper\n",
        "        wrapper = VLMWrapper(\n",
        "            model=\"gemini-2.5-flash-vertex\",\n",
        "            logprobs=5,\n",
        "            credentials=credentials_path,\n",
        "            project_id=project_id,\n",
        "            location=location,\n",
        "            temperature=0.0,\n",
        "            max_tokens=2000\n",
        "        )\n",
        "        \n",
        "        # System prompt for robot control\n",
        "        system_prompt = \"\"\"You are a robot controller. \n",
        "Respond with JSON format containing:\n",
        "- action: The action to take (e.g., \"move up\", \"pickup\", \"drop\")\n",
        "- reasoning: Brief explanation of why this action was chosen\n",
        "\"\"\"\n",
        "        \n",
        "        user_prompt = \"\"\"Based on the current situation, what action should the robot take?\n",
        "Respond in JSON format:\n",
        "{\n",
        "  \"action\": \"move up\",\n",
        "  \"reasoning\": \"The goal is to the north\"\n",
        "}\n",
        "\"\"\"\n",
        "        \n",
        "        print(\"\\n[1] Generating response with logprobs...\")\n",
        "        response, logprobs_metadata = wrapper.generate_with_logprobs(\n",
        "            system_prompt=system_prompt,\n",
        "            user_prompt=user_prompt,\n",
        "            debug=False\n",
        "        )\n",
        "        \n",
        "        print(f\"\\n[2] Response:\\n{response}\")\n",
        "        \n",
        "        # Process with postprocessor\n",
        "        print(\"\\n[3] Processing with postprocessor...\")\n",
        "        processor = VLMResponsePostProcessor(\n",
        "            required_fields=[\"action\", \"reasoning\"]\n",
        "        )\n",
        "        \n",
        "        # Option A: Get clean JSON without logprobs\n",
        "        print(\"\\n[4] Option A: Clean JSON (without logprobs)\")\n",
        "        parsed_clean = processor.process_without_logprobs(\n",
        "            response,\n",
        "            logprobs_metadata\n",
        "        )\n",
        "        print(f\"  Action: {parsed_clean.get('action')}\")\n",
        "        print(f\"  Reasoning: {parsed_clean.get('reasoning')}\")\n",
        "        \n",
        "        # Option B: Get JSON with action logprobs wrapped\n",
        "        print(\"\\n[5] Option B: JSON with action logprobs wrapped\")\n",
        "        parsed_with_logprobs = processor.process_with_action_logprobs(\n",
        "            response,\n",
        "            logprobs_metadata,\n",
        "            action_field=\"action\"\n",
        "        )\n",
        "        print(f\"  Action: {parsed_with_logprobs.get('action')}\")\n",
        "        print(f\"  Reasoning: {parsed_with_logprobs.get('reasoning')}\")\n",
        "        \n",
        "        # Display action logprobs\n",
        "        if 'action_logprobs' in parsed_with_logprobs:\n",
        "            action_logprobs = parsed_with_logprobs['action_logprobs']\n",
        "            print(f\"\\n[6] Action Logprobs:\")\n",
        "            print(f\"  Action tokens: {action_logprobs.get('action_tokens', [])}\")\n",
        "            print(f\"  Number of action tokens: {len(action_logprobs.get('action_tokens', []))}\")\n",
        "            if action_logprobs.get('action_entropies'):\n",
        "                avg_entropy = np.mean(action_logprobs['action_entropies'])\n",
        "                print(f\"  Average entropy for action: {avg_entropy:.4f} bits\")\n",
        "        \n",
        "        # Display remaining logprobs\n",
        "        if 'remaining_logprobs' in parsed_with_logprobs:\n",
        "            remaining = parsed_with_logprobs['remaining_logprobs']\n",
        "            print(f\"\\n[7] Remaining Logprobs:\")\n",
        "            print(f\"  Number of remaining tokens: {len(remaining.get('tokens', []))}\")\n",
        "            if remaining.get('entropies'):\n",
        "                avg_entropy = np.mean(remaining['entropies'])\n",
        "                print(f\"  Average entropy for remaining: {avg_entropy:.4f} bits\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example 4: Using VLMProcessor with logprobs\n",
        "\n",
        "This example shows how to:\n",
        "- Use VLMProcessor with logprobs support\n",
        "- Request and parse responses with logprobs\n",
        "- Extract action-specific logprobs using VLMProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Example 4: Using VLMProcessor with logprobs\n",
            "================================================================================\n",
            "\n",
            "[1] Requesting with logprobs...\n",
            "\n",
            "[2] Response:\n",
            "```json\n",
            "{\n",
            "  \"action\": [\"up\", \"left\", \"right\"],\n",
            "  \"reasoning\": \"The provided image appears to be entirely static or noise, offering no discernible features or context to inform a specific action. Therefore, a set of exploratory movements (up, left, right) is chosen as a default.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# Example 4: Using VLMProcessor with logprobs\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Example 4: Using VLMProcessor with logprobs\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "from utils.vlm.vlm_processor import VLMProcessor\n",
        "\n",
        "# Initialize processor with logprobs\n",
        "processor = VLMProcessor(\n",
        "    model=\"gemini-2.5-flash-vertex\",\n",
        "    logprobs=5,\n",
        "    credentials=credentials_path,\n",
        "    project_id=project_id,\n",
        "    location=location,\n",
        "    temperature=0.0,\n",
        "    max_tokens=2000,\n",
        "    debug=False\n",
        ")\n",
        "\n",
        "# Create dummy image (or use real image)\n",
        "dummy_image = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)\n",
        "\n",
        "system_prompt = \"\"\"You are a robot controller. \n",
        "Respond with JSON format containing:\n",
        "- action: You must choose 3 component list, each component should be exactly one from [\"up\", \"down\", \"left\", or \"right\"]. (e.g., [\"up\"])\n",
        "- format should be like this: \"action\": [\"<action1>\", \"<action2>\", \"<action3>\"]\n",
        "- reasoning: Brief explanation of why select action components\n",
        "\"\"\"\n",
        "\n",
        "user_prompt = \"\"\"What action should the robot take? Respond in JSON format.\"\"\"\n",
        "\n",
        "print(\"\\n[1] Requesting with logprobs...\")\n",
        "response, logprobs_metadata = processor.requester_with_logprobs(\n",
        "    image=dummy_image,\n",
        "    system_prompt=system_prompt,\n",
        "    user_prompt=user_prompt,\n",
        "    debug=False\n",
        ")\n",
        "\n",
        "print(f\"\\n[2] Response:\\n{response}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[3] Parsing with action logprobs...\n",
            "\n",
            "[4] Parsed result:\n",
            "  Action: ['up', 'left', 'right']\n",
            "  Reasoning: The provided image appears to be entirely static or noise, offering no discernible features or context to inform a specific action. Therefore, a set of exploratory movements (up, left, right) is chosen as a default.\n",
            "\n",
            "[5] Action logprobs info:\n",
            "  Positions: []\n",
            "  Count: 3\n",
            "  - Action 1 token: 'up' (pos 10)\n",
            "    entropy: 0.0132\n",
            "    top logprobs (first 3): ['up:-0.0011', 'left:-7.0816', 'down:-8.8559']\n",
            "  - Action 2 token: 'left' (pos 13)\n",
            "    entropy: 0.0141\n",
            "    top logprobs (first 3): ['left:-0.0012', 'down:-7.2783', 'right:-7.7593']\n",
            "  - Action 3 token: 'right' (pos 16)\n",
            "    entropy: 0.0009\n",
            "    top logprobs (first 3): ['right:-0.0001', 'down:-9.8019', 'left:-14.5727']\n",
            "  Entropies list: [np.float64(0.0132), np.float64(0.0141), np.float64(0.0009)]\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n[3] Parsing with action logprobs...\")\n",
        "parsed = processor.parser_action_with_logprobs(\n",
        "    response,\n",
        "    logprobs_metadata,\n",
        "    action_field=\"action\",\n",
        "    remove_logprobs=False\n",
        ")\n",
        "\n",
        "print(f\"\\n[4] Parsed result:\")\n",
        "print(f\"  Action: {parsed.get('action')}\")\n",
        "print(f\"  Reasoning: {parsed.get('reasoning')}\")\n",
        "\n",
        "# action_logprobs_info는 {'action_positions', 'action_logprobs', 'action_entropies'} 형태\n",
        "info = parsed.get('action_logprobs_info', {})\n",
        "action_positions = info.get('action_positions', [])\n",
        "action_logprobs_list = info.get('action_logprobs', [])\n",
        "action_entropies = info.get('action_entropies', [])\n",
        "\n",
        "print(f\"\\n[5] Action logprobs info:\")\n",
        "print(f\"  Positions: {action_positions}\")\n",
        "print(f\"  Count: {len(action_logprobs_list)}\")\n",
        "\n",
        "for idx, entry in enumerate(action_logprobs_list):\n",
        "    token_str, top_logs, entropy, pos = entry\n",
        "    print(f\"  - Action {idx+1} token: '{token_str}' (pos {pos})\")\n",
        "    if entropy is not None:\n",
        "        print(f\"    entropy: {entropy:.4f}\")\n",
        "    if top_logs:\n",
        "        print(f\"    top logprobs (first 3): {top_logs[:3]}\")\n",
        "\n",
        "if action_entropies:\n",
        "    print(f\"  Entropies list: {[round(e,4) if e is not None else None for e in action_entropies]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['up',\n",
              "  ['up:-0.0011',\n",
              "   'left:-7.0816',\n",
              "   'down:-8.8559',\n",
              "   'right:-9.4103',\n",
              "   'forward:-11.9427'],\n",
              "  np.float64(0.013176400540552765),\n",
              "  10],\n",
              " ['left',\n",
              "  ['left:-0.0012',\n",
              "   'down:-7.2783',\n",
              "   'right:-7.7593',\n",
              "   'up:-10.5662',\n",
              "   'turn:-13.6821'],\n",
              "  np.float64(0.014091295248416316),\n",
              "  13],\n",
              " ['right',\n",
              "  ['right:-0.0001',\n",
              "   'down:-9.8019',\n",
              "   'left:-14.5727',\n",
              "   'forward:-15.4860',\n",
              "   'up:-15.7652'],\n",
              "  np.float64(0.0008809247111316944),\n",
              "  16]]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parsed['action_logprobs_info']['action_logprobs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "minigrid",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
