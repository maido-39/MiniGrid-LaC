"""
ì‹œë‚˜ë¦¬ì˜¤ 2 ì‹¤í—˜ í™˜ê²½ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ (VLM ì œì–´ ë²„ì „ - í´ë˜ìŠ¤ ê¸°ë°˜)

ì‹œë‚˜ë¦¬ì˜¤ 2: íŒŒë€ ê¸°ë‘¥ìœ¼ë¡œ ê°€ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ëŒê³ , í…Œì´ë¸” ì˜†ì— ë©ˆì¶”ì‹œì˜¤

í™˜ê²½ êµ¬ì„±:
- ë²½: ê²€ì€ìƒ‰ (ì™¸ë²½)
- íŒŒë€ ê¸°ë‘¥: íŒŒë€ìƒ‰ 2x2 Grid (í†µê³¼ë¶ˆê°€, ìƒ‰ìƒì´ ìˆëŠ” ë²½)
- í…Œì´ë¸”: ë³´ë¼ìƒ‰ 1x3 Grid (í†µê³¼ë¶ˆê°€, ìƒ‰ìƒì´ ìˆëŠ” ë²½)
- ì‹œì‘ì : (1, 8)
- ì¢…ë£Œì : (8, 1)

ë ˆì´ì•„ì›ƒ (10x10):
â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸ğŸŸªğŸŸªğŸŸªğŸŸ©â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›â¬œï¸â¬œï¸ğŸŸ¦ğŸŸ¦â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬› 
â¬›â¬œï¸â¬œï¸ğŸŸ¦ğŸŸ¦â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬œï¸â¬›
â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›â¬›

ì‚¬ìš©ë²•:
    python scenario2_test.py
"""

from minigrid import register_minigrid_envs
from custom_environment import CustomRoomWrapper
from vlm_wrapper import ChatGPT4oVLMWrapper
from vlm_postprocessor import VLMResponsePostProcessor
import numpy as np
import cv2
import json
import csv
from datetime import datetime
from pathlib import Path
from PIL import Image

# MiniGrid í™˜ê²½ ë“±ë¡
register_minigrid_envs()

# VLM ì„¤ì •
VLM_MODEL = "gpt-4o"
VLM_TEMPERATURE = 0.0
VLM_MAX_TOKENS = 1000


class PromptOrganizer:
    """í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.grounding = ""
        self.previous_action = ""
        self.current_subtask = ""
    
    def get_system_prompt(self) -> str:
        """ì „ì²´ System Prompt ìƒì„±"""
        base = "You are a robot operating on a grid map.\n\n"
        
        # Grounding ì„¹ì…˜
        grounding_section = ""
        if self.grounding:
            grounding_section = f"""## Grounding Knowledge (Lessons Learned from Mistakes)
{self.grounding}

**Important**: This section contains knowledge learned from previous mistakes. Always refer to this section to avoid repeating the same mistakes.

"""
        
        # Memory ì„¹ì…˜
        memory_section = ""
        if self.previous_action or self.current_subtask:
            memory_section = f"""## Permanent Memory (Current Progress Summary)
- Previous Action: {self.previous_action if self.previous_action else "None"}
- Current Subtask: {self.current_subtask if self.current_subtask else "Not specified"}

**Important**: This memory contains information about the previous action and current subtask. Use this to maintain consistency in your actions.

"""
        
        # Environment Info (ì „ì²´ System Prompt ë‚´ìš©)
        env_info = """## Environment
Grid world with walls (black), blue pillar (impassable), purple table (impassable), robot (red arrow shows heading), and goal (green marker if present).

## Robot Orientation
In the image, the red triangle represents the robot.
The robot's heading direction is defined as the direction pointed by the triangle's apex (sharp tip).
The top of the image is North, and the bottom is South.
The left is West, and the right is East.

## Action Space
- "turn left": Rotate 90Â° counterclockwise
- "turn right": Rotate 90Â° clockwise
- "move forward": Move one cell forward in heading direction
- "pickup": Pick up object in front
- "drop": Drop carried object
- "toggle": Interact with objects (e.g., open doors)

## Movement Rules
**CRITICAL**: All movements are RELATIVE to robot's current heading direction.
- "forward" = move one cell in facing direction
- "turn left/right" = rotate 90Â° from current heading
- Think in relative movements, NOT absolute coordinates

## Response Format
Respond in JSON format:
```json
{
    "action": ["<action1>", "<action2>", "<action3>"],
    "reasoning": "<explanation of why you chose this action>",
    "grounding": "<grounding knowledge update if feedback detected, otherwise empty>",
    "memory": {
        "spatial_description": "<description of current state with spatial relationships relative to robot heading orientation>",
        "current_subtask": "<current subtask from the user prompt task breakdown>",
        "previous_action": "<this action will be recorded here for next step consistency>"
    }
}
```

**Important**: 
- You MUST provide exactly 3 actions in the "action" array as a sequential action chunk
- Only the first action will be executed, but all 3 actions should form a coherent sequence
- The "previous_action" in memory should be set to the first action you choose
- For consistency, refer to the "previous_action" in memory when planning your next action
- Valid JSON format required
- Actions must be from the action space list above
- Complete mission from user prompt
- Use relative movements based on heading, not coordinates
"""
        
        return base + memory_section + grounding_section + env_info
    
    def get_feedback_system_prompt(self) -> str:
        """Feedback ìƒì„±ìš© System Prompt"""
        return """You are a feedback analyzer for a robot navigation system.

Your task is to analyze feedback and generate concise knowledge to improve the robot's behavior.

## Context
You will receive:
- The full system prompt used for action generation
- The previous action that was taken
- The current user feedback

## Your Task
Analyze the feedback in the context of the system prompt and previous action.
Generate concise knowledge (1-2 sentences) that explains:
1. What went wrong
2. How to avoid this mistake in the future

## Response Format
Respond in JSON format:
```json
{
    "knowledge": "<concise knowledge (1-2 sentences) explaining what went wrong and how to avoid it>"
}
```

**Important**:
- Keep the knowledge brief and actionable (1-2 sentences max)
- Focus on specific, actionable guidance
- The knowledge will be added to the grounding section for future reference
"""
    
    def update_grounding(self, new_grounding: str):
        """Grounding ì§€ì‹ ëˆ„ì  ì—…ë°ì´íŠ¸"""
        if new_grounding and new_grounding.strip():
            if self.grounding:
                self.grounding = f"{self.grounding}\n\n{new_grounding.strip()}"
            else:
                self.grounding = new_grounding.strip()
    
    def get_user_prompt(self, default_prompt: str = None) -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ì…ë ¥ ë°›ê¸°"""
        if default_prompt:
            print(f"Task Hint: {default_prompt}")
        print("ëª…ë ¹ì„ ì…ë ¥í•˜ì„¸ìš” (Enter: ê¸°ë³¸ í”„ë¡¬í”„íŠ¸):")
        user_input = input("> ").strip()
        
        if not user_input:
            if default_prompt:
                return f"Task: {default_prompt}\n\nBased on the current image, choose the next action to complete this task."
            return "Based on the current image, choose the next action to complete the mission: Go to the blue pillar, turn right, then stop next to the table."
        
        return user_input


class VLMProcessor:
    """VLM ìš”ì²­ ë° íŒŒì‹± ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, model: str = VLM_MODEL, temperature: float = VLM_TEMPERATURE, max_tokens: int = VLM_MAX_TOKENS):
        self.vlm = ChatGPT4oVLMWrapper(
            model=model,
            temperature=temperature,
            max_tokens=max_tokens
        )
        self.postprocessor_action = VLMResponsePostProcessor(required_fields=["action", "reasoning", "grounding", "memory"])
        self.postprocessor_feedback = VLMResponsePostProcessor(required_fields=["knowledge"])
    
    def requester(self, image: np.ndarray, system_prompt: str, user_prompt: str) -> str:
        """VLMì— ìš”ì²­ ì „ì†¡ (ê¸°ë³¸ ë©”ì„œë“œ)"""
        try:
            response = self.vlm.generate(
                image=image,
                system_prompt=system_prompt,
                user_prompt=user_prompt
            )
            return response
        except Exception as e:
            print(f"VLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return ""
    
    def parser_action(self, raw_response: str) -> dict:
        """Action ìƒì„± ì‘ë‹µ íŒŒì‹±"""
        try:
            parsed = self.postprocessor_action.process(raw_response, strict=True)
            return parsed
        except ValueError as e:
            print(f"ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {
                "action": ["2"],
                "reasoning": "Parsing failed",
                "grounding": "",
                "memory": {
                    "spatial_description": "",
                    "current_subtask": "",
                    "previous_action": ""
                }
            }
    
    def parser_feedback(self, raw_response: str) -> dict:
        """Feedback ìƒì„± ì‘ë‹µ íŒŒì‹±"""
        try:
            parsed = self.postprocessor_feedback.process(raw_response, strict=True)
            return parsed
        except ValueError as e:
            print(f"Feedback ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return {"knowledge": ""}


class Visualizer:
    """ì‹œê°í™” í´ë˜ìŠ¤"""
    
    def __init__(self, window_name: str = "Scenario 2: VLM Control"):
        self.window_name = window_name
    
    def visualize_grid_cli(self, wrapper: CustomRoomWrapper, state: dict):
        """CLIì—ì„œ ê·¸ë¦¬ë“œë¥¼ í…ìŠ¤íŠ¸ë¡œ ì‹œê°í™”"""
        env = wrapper.env
        size = wrapper.size
        
        agent_pos = state['agent_pos']
        if isinstance(agent_pos, np.ndarray):
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        else:
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        
        agent_dir = state['agent_dir']
        direction_symbols = {0: '>', 1: 'v', 2: '<', 3: '^'}
        agent_symbol = direction_symbols.get(agent_dir, 'A')
        
        grid_chars = []
        for y in range(size):
            row = []
            for x in range(size):
                cell = env.grid.get(x, y)
                
                if x == agent_x and y == agent_y:
                    row.append(agent_symbol)
                elif cell is not None and cell.type == 'wall':
                    if hasattr(cell, 'color'):
                        if cell.color == 'blue':
                            row.append('ğŸŸ¦')
                        elif cell.color == 'purple':
                            row.append('ğŸŸª')
                        elif cell.color == 'red':
                            row.append('ğŸŸ¥')
                        elif cell.color == 'green':
                            row.append('ğŸŸ©')
                        elif cell.color == 'yellow':
                            row.append('ğŸŸ¨')
                        else:
                            row.append('â¬›')
                    else:
                        row.append('â¬›')
                elif cell is not None and cell.type == 'goal':
                    row.append('ğŸŸ©')
                elif cell is not None:
                    if hasattr(cell, 'color'):
                        if cell.color == 'blue':
                            row.append('ğŸŸ¦')
                        elif cell.color == 'purple':
                            row.append('ğŸŸª')
                        else:
                            row.append('ğŸŸ¨')
                    else:
                        row.append('ğŸŸ¨')
                else:
                    row.append('â¬œï¸')
            grid_chars.append(row)
        
        print("\n" + "=" * 60)
        print("Current Grid State:")
        print("=" * 60)
        for y in range(size):
            print(''.join(grid_chars[y]))
        print("=" * 60)
        print(f"Agent Position: ({agent_x}, {agent_y}), Direction: {agent_dir} ({agent_symbol})")
        print("=" * 60 + "\n")

    def display_image(self, img: np.ndarray):
        """OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í‘œì‹œ"""
        if img is not None:
            try:
                img_bgr = cv2.cvtColor(img.copy(), cv2.COLOR_RGB2BGR)
                
                height, width = img_bgr.shape[:2]
                max_size = 800
                if height < max_size and width < max_size:
                    scale = min(max_size // height, max_size // width, 4)
                    if scale > 1:
                        new_width = width * scale
                        new_height = height * scale
                        img_bgr = cv2.resize(img_bgr, (new_width, new_height), interpolation=cv2.INTER_NEAREST)
                
                cv2.imshow(self.window_name, img_bgr)
                cv2.waitKey(1)
            except Exception as e:
                print(f"ì´ë¯¸ì§€ í‘œì‹œ ì˜¤ë¥˜: {e}")
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        cv2.destroyAllWindows()


class UserInteraction:
    """ì‚¬ìš©ì ìƒí˜¸ì‘ìš© í´ë˜ìŠ¤"""
    
    def get_input(self, prompt: str = "> ") -> str:
        """ì‚¬ìš©ì ì…ë ¥ ë°›ê¸°"""
        return input(prompt).strip()


def create_scenario2_environment() -> CustomRoomWrapper:
    """ì‹œë‚˜ë¦¬ì˜¤ 2 í™˜ê²½ ìƒì„±"""
    size = 10
    
    walls = []
    for i in range(size):
        walls.append((i, 0))
        walls.append((i, size-1))
        walls.append((0, i))
        walls.append((size-1, i))
    
    blue_pillar_positions = [(3, 4), (4, 4), (3, 5), (4, 5)]
    for pos in blue_pillar_positions:
        walls.append((pos[0], pos[1], 'blue'))
    
    table_positions = [(5, 1), (6, 1), (7, 1)]
    for pos in table_positions:
        walls.append((pos[0], pos[1], 'purple'))
    
    start_pos = (1, 8)
    goal_pos = (8, 1)
    
    room_config = {
        'start_pos': start_pos,
        'goal_pos': goal_pos,
        'walls': walls,
        'objects': []
    }
    
    return CustomRoomWrapper(size=size, room_config=room_config)


class Scenario2Experiment:
    """ì‹œë‚˜ë¦¬ì˜¤ 2 ì‹¤í—˜ ë©”ì¸ í´ë˜ìŠ¤ (Runner)"""
    
    def __init__(self, log_dir: Path = None):
        self.wrapper = None
        self.prompt_organizer = PromptOrganizer()
        self.vlm_processor = VLMProcessor()
        self.visualizer = Visualizer()
        self.user_interaction = UserInteraction()
        
        if log_dir is None:
            log_dir = Path("logs") / f"scenario2_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.log_dir = log_dir
        self.log_dir.mkdir(parents=True, exist_ok=True)
        
        self.step = 0
        self.done = False
        self.state = None
        self.image = None
        self.user_prompt = ""
        self.vlm_response_raw = ""
        self.vlm_response_parsed = {}
        self.action_index = 2
        self.action_name = "move forward"
        self.reward = 0.0
        
        self.csv_file = None
        self.csv_writer = None
        self._init_csv_logging()
    
    def _evaluate_feedback(self, user_prompt: str) -> bool:
        """í”¼ë“œë°± í‰ê°€ (ë‚´ë¶€ ë©”ì„œë“œ)"""
        feedback_keywords = [
            "wrong", "incorrect", "that's wrong", "no", "not that", "don't", 
            "shouldn't", "error", "mistake", "why did you", "why didn't you",
            "what are you doing", "where are you going", "not feasible", 
            "cannot", "should not",
            "feedback :"
        ]
        
        user_lower = user_prompt.lower()
        for keyword in feedback_keywords:
            if keyword in user_lower:
                return True
        
        return False
    
    def vlm_gen_action(self, image: np.ndarray, system_prompt: str, user_prompt: str) -> dict:
        """Action ìƒì„±ìš© VLM í˜¸ì¶œ"""
        print("\n[3] VLMì— Action ìƒì„± ìš”ì²­ ì „ì†¡ ì¤‘...")
        raw_response = self.vlm_processor.requester(
            image=image,
            system_prompt=system_prompt,
            user_prompt=user_prompt
        )
        
        if not raw_response:
            print("VLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return {}
        
        print("VLM ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
        print("[4] ì‘ë‹µ íŒŒì‹± ì¤‘...")
        parsed = self.vlm_processor.parser_action(raw_response)
        return parsed
    
    def vlm_gen_feedback(self, system_prompt: str, user_feedback: str) -> str:
        """Feedback ìƒì„±ìš© VLM í˜¸ì¶œ"""
        print("\n[3-F] VLMì— Feedback ë¶„ì„ ìš”ì²­ ì „ì†¡ ì¤‘...")
        
        feedback_system_prompt = self.prompt_organizer.get_feedback_system_prompt()
        
        feedback_user_prompt = f"""## System Prompt Used
{system_prompt}

## User Feedback
feedback : {user_feedback}

Please analyze the feedback and generate concise knowledge to improve future actions.
"""
        
        raw_response = self.vlm_processor.requester(
            image=None,
            system_prompt=feedback_system_prompt,
            user_prompt=feedback_user_prompt
        )
        
        if not raw_response:
            print("Feedback VLM ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return ""
        
        print("Feedback VLM ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ")
        print("[4-F] Feedback ì‘ë‹µ íŒŒì‹± ì¤‘...")
        parsed = self.vlm_processor.parser_feedback(raw_response)
        knowledge = parsed.get('knowledge', '')
        
        if knowledge:
            print(f"\n[4-F-1] ìƒì„±ëœ Knowledge: {knowledge}")
            self.prompt_organizer.update_grounding(knowledge)
            print("\n[4-F-2] Grounding ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            print("=" * 80)
            print("ì—…ë°ì´íŠ¸ëœ Grounding ë‚´ìš©:")
            print("-" * 80)
            print(knowledge)
            print("-" * 80)
            print("\nì „ì²´ Grounding ì •ë³´:")
            print("=" * 80)
            if self.prompt_organizer.grounding:
                print(self.prompt_organizer.grounding)
            else:
                print("(ì—†ìŒ)")
            print("=" * 80)
        
        return knowledge
    
    def _init_csv_logging(self):
        """CSV ë¡œê¹… ì´ˆê¸°í™”"""
        csv_path = self.log_dir / "experiment_log.csv"
        file_exists = csv_path.exists()
        
        self.csv_file = open(csv_path, 'a', newline='', encoding='utf-8')
        self.csv_writer = csv.writer(self.csv_file)
        
        if not file_exists:
            self.csv_writer.writerow([
                "step", "timestamp", "agent_x", "agent_y", "agent_dir",
                "action_index", "action_name", "user_prompt",
                "vlm_action_chunk", "vlm_reasoning", "vlm_grounding",
                "memory_spatial_description", "memory_current_subtask", "memory_previous_action",
                "reward", "done", "image_path"
            ])
    
    def _log_step(self):
        """í˜„ì¬ ìŠ¤í… ë¡œê¹…"""
        timestamp = datetime.now().isoformat()
        
        agent_pos = self.state['agent_pos']
        if isinstance(agent_pos, np.ndarray):
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        else:
            agent_x, agent_y = int(agent_pos[0]), int(agent_pos[1])
        
        image_path = f"step_{self.step:04d}.png"
        
        # Memory íŒŒì‹±
        memory = self.vlm_response_parsed.get('memory', {})
        if isinstance(memory, str):
            try:
                memory = json.loads(memory)
            except Exception:
                memory = {"spatial_description": "", "current_subtask": "", "previous_action": ""}
        elif not isinstance(memory, dict):
            memory = {"spatial_description": "", "current_subtask": "", "previous_action": ""}
        
        action_chunk = self.vlm_response_parsed.get('action', [])
        if isinstance(action_chunk, str):
            try:
                action_chunk = json.loads(action_chunk)
            except Exception:
                action_chunk = [action_chunk] if action_chunk else []
        if not isinstance(action_chunk, list):
            action_chunk = [str(action_chunk)]
        
        self.csv_writer.writerow([
            self.step,
            timestamp,
            agent_x,
            agent_y,
            int(self.state['agent_dir']),
            self.action_index,
            self.action_name,
            self.user_prompt,
            json.dumps(action_chunk, ensure_ascii=False),
            self.vlm_response_parsed.get('reasoning', ''),
            self.vlm_response_parsed.get('grounding', ''),
            memory.get('spatial_description', ''),
            memory.get('current_subtask', ''),
            memory.get('previous_action', ''),
            float(self.reward),
            bool(self.done),
            image_path
        ])
        self.csv_file.flush()
        
        json_path = self.log_dir / "experiment_log.json"
        json_data = {
            "step": self.step,
            "timestamp": timestamp,
            "state": {
                "agent_pos": [agent_x, agent_y],
                "agent_dir": int(self.state['agent_dir']),
                "mission": str(self.state.get('mission', ''))
            },
            "action": {
                "index": self.action_index,
                "name": self.action_name
            },
            "user_prompt": self.user_prompt,
            "vlm_response": self.vlm_response_parsed,
            "memory": memory,
            "grounding": self.prompt_organizer.grounding,
            "reward": float(self.reward),
            "done": bool(self.done),
            "image_path": image_path
        }
        
        all_data = []
        if json_path.exists():
            with open(json_path, 'r', encoding='utf-8') as f:
                try:
                    all_data = json.load(f)
                    if not isinstance(all_data, list):
                        all_data = [all_data]
                except json.JSONDecodeError:
                    all_data = []
        
        all_data.append(json_data)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(all_data, f, indent=2, ensure_ascii=False)
        
        image_path_full = self.log_dir / image_path
        img_pil = Image.fromarray(self.image)
        img_pil.save(image_path_full)
    
    def initialize(self):
        """ì‹¤í—˜ ì´ˆê¸°í™”"""
        print("=" * 60)
        print("ì‹œë‚˜ë¦¬ì˜¤ 2: VLM ì œì–´ ì‹¤í—˜")
        print("=" * 60)
        print("\ní™˜ê²½ êµ¬ì„±:")
        print("  - íŒŒë€ ê¸°ë‘¥: 2x2 Grid (ìƒ‰ìƒì´ ìˆëŠ” ë²½)")
        print("  - í…Œì´ë¸”: ë³´ë¼ìƒ‰ 1x3 Grid (ìƒ‰ìƒì´ ìˆëŠ” ë²½)")
        print("  - ì‹œì‘ì : (1, 8)")
        print("  - ì¢…ë£Œì : (8, 1)")
        print("\nMission: íŒŒë€ ê¸°ë‘¥ìœ¼ë¡œ ê°€ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ëŒê³ , í…Œì´ë¸” ì˜†ì— ë©ˆì¶”ì‹œì˜¤")
        print(f"\në¡œê·¸ ë””ë ‰í† ë¦¬: {self.log_dir}")
        
        print("\n[1] í™˜ê²½ ìƒì„± ì¤‘...")
        self.wrapper = create_scenario2_environment()
        self.wrapper.reset()
        
        self.state = self.wrapper.get_state()
        print(f"ì—ì´ì „íŠ¸ ì‹œì‘ ìœ„ì¹˜: {self.state['agent_pos']}")
        print(f"ì—ì´ì „íŠ¸ ë°©í–¥: {self.state['agent_dir']}")
        
        print("\n[2] VLM ì´ˆê¸°í™” ì™„ë£Œ")
        print("\n" + "=" * 60)
        print("ì‹¤í—˜ ì‹œì‘")
        print("=" * 60)
    
    def run_step(self):
        """í•œ ìŠ¤í… ì‹¤í–‰"""
        self.step += 1
        print("\n" + "=" * 80)
        print(f"STEP {self.step}")
        print("=" * 80)
        
        self.image = self.wrapper.get_image()
        self.state = self.wrapper.get_state()
        print(f"ìœ„ì¹˜: {self.state['agent_pos']}, ë°©í–¥: {self.state['agent_dir']}")
        
        self.visualizer.visualize_grid_cli(self.wrapper, self.state)
        self.visualizer.display_image(self.image)
        
        default_prompt = "Mission: Go to the blue pillar, turn right, then stop next to the table."
        self.user_prompt = self.prompt_organizer.get_user_prompt(default_prompt)
        
        # Feedback í‰ê°€
        has_feedback = self._evaluate_feedback(self.user_prompt)
        
        if has_feedback:
            # Feedback ì²˜ë¦¬: "feedback : "ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
            if self.user_prompt.lower().startswith("feedback :"):
                feedback_text = self.user_prompt[10:].strip()  # "feedback : " ì œê±°
            else:
                feedback_text = self.user_prompt
            
            # Feedback ìƒì„± VLM í˜¸ì¶œ
            system_prompt = self.prompt_organizer.get_system_prompt()
            self.vlm_gen_feedback(system_prompt, feedback_text)
            
            # Feedback ì²˜ë¦¬ í›„ ì¼ë°˜ action ìƒì„±ìœ¼ë¡œ ì§„í–‰í•˜ì§€ ì•Šê³  ìŠ¤í‚µ
            print("\n[4-1] í”¼ë“œë°± ì²˜ë¦¬ ì™„ë£Œ. ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            return True
        
        # ì¼ë°˜ Action ìƒì„±
        system_prompt = self.prompt_organizer.get_system_prompt()
        self.vlm_response_parsed = self.vlm_gen_action(
            image=self.image,
            system_prompt=system_prompt,
            user_prompt=self.user_prompt
        )
        
        if not self.vlm_response_parsed:
            return False
        
        # Action chunkì—ì„œ ì²« ë²ˆì§¸ ì•¡ì…˜ë§Œ ì¶”ì¶œ
        action_chunk = self.vlm_response_parsed.get('action', [])
        if isinstance(action_chunk, str):
            try:
                action_chunk = json.loads(action_chunk)
            except Exception:
                action_chunk = [action_chunk] if action_chunk else []
        if not isinstance(action_chunk, list):
            action_chunk = [str(action_chunk)]
        
        if len(action_chunk) == 0:
            action_str = '2'
        else:
            action_str = str(action_chunk[0])
        
        # Memory íŒŒì‹±
        memory = self.vlm_response_parsed.get('memory', {})
        if isinstance(memory, str):
            try:
                memory = json.loads(memory)
            except Exception:
                memory = {}
        if not isinstance(memory, dict):
            memory = {}
        
        # Memory ì—…ë°ì´íŠ¸
        if isinstance(memory, dict):
            self.prompt_organizer.previous_action = memory.get('previous_action', action_str)
            self.prompt_organizer.current_subtask = memory.get('current_subtask', '')
        
        # Grounding ì—…ë°ì´íŠ¸ (ì‘ë‹µì—ì„œ ì˜¨ ê²½ìš°)
        grounding_update = self.vlm_response_parsed.get('grounding', '')
        grounding_updated = False
        if grounding_update and grounding_update.strip():
            self.prompt_organizer.update_grounding(grounding_update)
            grounding_updated = True
        
        # CLI ì¶œë ¥: Action, Reasoning, Memory, Grounding
        print("\n" + "=" * 80)
        print("[VLM ì‘ë‹µ ì •ë³´]")
        print("=" * 80)
        
        # Action Chunk ì¶œë ¥
        print("\n[Action Chunk]")
        print("-" * 80)
        if len(action_chunk) > 0:
            for i, action in enumerate(action_chunk, 1):
                marker = "â†’ ì‹¤í–‰" if i == 1 else "  ì˜ˆì¸¡"
                print(f"  {marker} [{i}] {action}")
        else:
            print("  (ì•¡ì…˜ ì—†ìŒ)")
        
        # Reasoning ì¶œë ¥
        reasoning = self.vlm_response_parsed.get('reasoning', '')
        print("\n[Reasoning]")
        print("-" * 80)
        if reasoning:
            print(f"  {reasoning}")
        else:
            print("  (ì—†ìŒ)")
        
        # Memory ì¶œë ¥
        print("\n[Memory]")
        print("-" * 80)
        spatial_desc = memory.get('spatial_description', '')
        current_subtask = memory.get('current_subtask', '')
        prev_action = memory.get('previous_action', '')
        
        print("  Spatial Description:")
        if spatial_desc:
            print(f"    {spatial_desc}")
        else:
            print("    (ì—†ìŒ)")
        
        print("  Current Subtask:")
        if current_subtask:
            print(f"    {current_subtask}")
        else:
            print("    (ì—†ìŒ)")
        
        print("  Previous Action:")
        if prev_action:
            print(f"    {prev_action}")
        else:
            print("    (ì—†ìŒ)")
        
        # Grounding ì¶œë ¥ (ì—…ë°ì´íŠ¸ëœ ê²½ìš°ë§Œ)
        if grounding_updated:
            print("\n[Grounding Update]")
            print("-" * 80)
            print(f"  {grounding_update}")
        
        print("=" * 80)
        
        print("\n[5] ì•¡ì…˜ ì‹¤í–‰ ì¤‘...")
        try:
            self.action_index = self.wrapper.parse_action(action_str)
            self.action_name = self.wrapper.ACTION_NAMES.get(self.action_index, f"action_{self.action_index}")
            print(f"ì‹¤í–‰í•  ì•¡ì…˜: {self.action_name} (ì¸ë±ìŠ¤: {self.action_index})")
            
            _, self.reward, terminated, truncated, _ = self.wrapper.step(self.action_index)
            self.done = terminated or truncated
            
            print(f"ë³´ìƒ: {self.reward}, ì¢…ë£Œ: {self.done}")
        except Exception as e:
            print(f"ì•¡ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            self.action_index = 2
            self.action_name = "move forward"
            _, self.reward, terminated, truncated, _ = self.wrapper.step(2)
            self.done = terminated or truncated
        
        # Previous action ì—…ë°ì´íŠ¸ (ì‹¤ì œ ì‹¤í–‰ëœ ì•¡ì…˜)
        self.prompt_organizer.previous_action = self.action_name
        
        new_state = self.wrapper.get_state()
        self.visualizer.visualize_grid_cli(self.wrapper, new_state)
        updated_image = self.wrapper.get_image()
        self.visualizer.display_image(updated_image)
        
        self._log_step()
        
        return True
    
    def run(self):
        """ë©”ì¸ ë£¨í”„ ì‹¤í–‰"""
        self.initialize()
        
        while not self.done:
            if not self.run_step():
                break
            
            if self.done:
                print("\n" + "=" * 80)
                print("Goal ë„ì°©! ì¢…ë£Œ")
                print("=" * 80)
                break
            
            if self.step >= 100:
                print("\nìµœëŒ€ ìŠ¤í… ìˆ˜(100)ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
                break
    
        self.cleanup()
    
    def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        self.visualizer.cleanup()
        if self.wrapper:
            self.wrapper.close()
        if self.csv_file:
            self.csv_file.close()
        print(f"\nì‹¤í—˜ ì™„ë£Œ. ë¡œê·¸ëŠ” {self.log_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        experiment = Scenario2Experiment()
        experiment.run()
    except KeyboardInterrupt:
        print("\n\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
